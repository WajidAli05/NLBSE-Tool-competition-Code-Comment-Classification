{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sHWJIUgTy7qd","outputId":"e3156f6a-ff85-4daa-a4a0-49c30097fb40","executionInfo":{"status":"ok","timestamp":1733076239659,"user_tz":480,"elapsed":50359,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sentence-transformers 3.2.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.17.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n","sentence-transformers 3.2.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.17.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"]}],"source":["!pip -q install transformers==4.17\n","!pip -q install optuna\n","!pip install datasets"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"P2E2HOAZzM-8","executionInfo":{"status":"ok","timestamp":1733076259733,"user_tz":480,"elapsed":20138,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[],"source":["from transformers import Trainer, TrainingArguments, AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n","from datasets import load_dataset\n","import torch\n","import pandas as pd\n","import nltk\n","import re\n","import ast\n","import numpy as np\n","from torch.utils.data import Dataset\n","from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_fscore_support, accuracy_score\n","from sklearn.model_selection import train_test_split\n","import torch.nn as nn\n","import optuna\n","import time"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":519},"id":"_b1pJXwqzbkx","outputId":"522cf029-43fb-4ff8-fb3b-ae17767b439f","executionInfo":{"status":"ok","timestamp":1733076263888,"user_tz":480,"elapsed":4274,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["   index                      class  \\\n","0      0  BlAnchorRelativeToElement   \n","1      2     BlArrowheadSimpleArrow   \n","2      3     BlArrowheadSimpleArrow   \n","3      4     BlArrowheadSimpleArrow   \n","4      8        BlArrowheadTriangle   \n","\n","                                    comment_sentence  partition  \\\n","0  relative anchor takes an arbitrary element as ...          0   \n","1                i am a simple arrow like arrowhead.          0   \n","2  both my size and arrow length depend on the cu...          0   \n","3  it is possible hovewer to customize a length f...          0   \n","4                      i am a triangular arrow head.          0   \n","\n","                                               combo                 labels  \n","0  relative anchor takes an arbitrary element as ...  [0, 0, 1, 0, 0, 0, 0]  \n","1  i am a simple arrow like arrowhead. | BlArrowh...  [0, 0, 0, 0, 1, 0, 0]  \n","2  both my size and arrow length depend on the cu...  [0, 0, 0, 0, 1, 0, 0]  \n","3  it is possible hovewer to customize a length f...  [0, 0, 0, 0, 0, 1, 0]  \n","4  i am a triangular arrow head. | BlArrowheadTri...  [0, 0, 0, 0, 1, 0, 0]  "],"text/html":["\n","  <div id=\"df-e9267065-4543-41bb-801a-bc1014c8f169\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>class</th>\n","      <th>comment_sentence</th>\n","      <th>partition</th>\n","      <th>combo</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>BlAnchorRelativeToElement</td>\n","      <td>relative anchor takes an arbitrary element as ...</td>\n","      <td>0</td>\n","      <td>relative anchor takes an arbitrary element as ...</td>\n","      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>BlArrowheadSimpleArrow</td>\n","      <td>i am a simple arrow like arrowhead.</td>\n","      <td>0</td>\n","      <td>i am a simple arrow like arrowhead. | BlArrowh...</td>\n","      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>BlArrowheadSimpleArrow</td>\n","      <td>both my size and arrow length depend on the cu...</td>\n","      <td>0</td>\n","      <td>both my size and arrow length depend on the cu...</td>\n","      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>BlArrowheadSimpleArrow</td>\n","      <td>it is possible hovewer to customize a length f...</td>\n","      <td>0</td>\n","      <td>it is possible hovewer to customize a length f...</td>\n","      <td>[0, 0, 0, 0, 0, 1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8</td>\n","      <td>BlArrowheadTriangle</td>\n","      <td>i am a triangular arrow head.</td>\n","      <td>0</td>\n","      <td>i am a triangular arrow head. | BlArrowheadTri...</td>\n","      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9267065-4543-41bb-801a-bc1014c8f169')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e9267065-4543-41bb-801a-bc1014c8f169 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e9267065-4543-41bb-801a-bc1014c8f169');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2cadad8e-99e1-4743-974c-5ecf34893138\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2cadad8e-99e1-4743-974c-5ecf34893138')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2cadad8e-99e1-4743-974c-5ecf34893138 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(test_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          8,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"BlAnchorRelativeToElement\",\n          \"BlArrowheadSimpleArrow\",\n          \"BlArrowheadTriangle\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comment_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"i am a simple arrow like arrowhead.\",\n          \"i am a triangular arrow head.\",\n          \"both my size and arrow length depend on the curve width.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"partition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"combo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"i am a simple arrow like arrowhead. | BlArrowheadSimpleArrow\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["   index                   class  \\\n","0      1     BlArrowheadExamples   \n","1      5  BlArrowheadSimpleArrow   \n","2      6  BlArrowheadSimpleArrow   \n","3      7  BlArrowheadSimpleArrow   \n","4      9     BlArrowheadTriangle   \n","\n","                                    comment_sentence  partition  \\\n","0  i contain examples of different types of blarr...          1   \n","1  users can also customise nose angle that tells...          1   \n","2  the with of the outer arrows can be specified ...          1   \n","3  i support both background and border paint and...          1   \n","4  my size depends on the width of a curve and he...          1   \n","\n","                                               combo                 labels  \n","0  i contain examples of different types of blarr...  [0, 0, 1, 1, 0, 0, 0]  \n","1  users can also customise nose angle that tells...  [0, 1, 0, 0, 0, 0, 0]  \n","2  the with of the outer arrows can be specified ...  [0, 0, 1, 0, 0, 0, 0]  \n","3  i support both background and border paint and...  [0, 0, 1, 0, 0, 0, 0]  \n","4  my size depends on the width of a curve and he...  [0, 0, 1, 0, 0, 0, 0]  "],"text/html":["\n","  <div id=\"df-274baa63-084e-4d43-8d23-700c601fa06a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>class</th>\n","      <th>comment_sentence</th>\n","      <th>partition</th>\n","      <th>combo</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>BlArrowheadExamples</td>\n","      <td>i contain examples of different types of blarr...</td>\n","      <td>1</td>\n","      <td>i contain examples of different types of blarr...</td>\n","      <td>[0, 0, 1, 1, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>BlArrowheadSimpleArrow</td>\n","      <td>users can also customise nose angle that tells...</td>\n","      <td>1</td>\n","      <td>users can also customise nose angle that tells...</td>\n","      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>6</td>\n","      <td>BlArrowheadSimpleArrow</td>\n","      <td>the with of the outer arrows can be specified ...</td>\n","      <td>1</td>\n","      <td>the with of the outer arrows can be specified ...</td>\n","      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7</td>\n","      <td>BlArrowheadSimpleArrow</td>\n","      <td>i support both background and border paint and...</td>\n","      <td>1</td>\n","      <td>i support both background and border paint and...</td>\n","      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9</td>\n","      <td>BlArrowheadTriangle</td>\n","      <td>my size depends on the width of a curve and he...</td>\n","      <td>1</td>\n","      <td>my size depends on the width of a curve and he...</td>\n","      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-274baa63-084e-4d43-8d23-700c601fa06a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-274baa63-084e-4d43-8d23-700c601fa06a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-274baa63-084e-4d43-8d23-700c601fa06a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-47c59f6a-ebe5-484e-8cc0-f48a3f846229\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47c59f6a-ebe5-484e-8cc0-f48a3f846229')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-47c59f6a-ebe5-484e-8cc0-f48a3f846229 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(test_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 9,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5,\n          9,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"BlArrowheadExamples\",\n          \"BlArrowheadSimpleArrow\",\n          \"BlArrowheadTriangle\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comment_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"users can also customise nose angle that tells how wide should the arrow lines be spread.\",\n          \"my size depends on the width of a curve and hence can not be manually specified.\",\n          \"the with of the outer arrows can be specified by changing border width of a simple arrow arrowhead.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"partition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"combo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"users can also customise nose angle that tells how wide should the arrow lines be spread. | BlArrowheadSimpleArrow\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}],"source":["splits = {'pharo_train': 'data/pharo_train-00000-of-00001.parquet', 'pharo_test': 'data/pharo_test-00000-of-00001.parquet'}\n","train_df = pd.read_parquet(\"hf://datasets/NLBSE/nlbse25-code-comment-classification/\" + splits[\"pharo_train\"])\n","test_df = pd.read_parquet(\"hf://datasets/NLBSE/nlbse25-code-comment-classification/\" + splits[\"pharo_test\"])\n","\n","display(train_df.head())\n","display(test_df.head())"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":465},"id":"9x93EZXwzo-f","outputId":"5979fc1d-5fd1-43d8-82ba-fb88001f94eb","executionInfo":{"status":"ok","timestamp":1733076263889,"user_tz":480,"elapsed":280,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-df4392ae2e99>:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n","  train_str_df = train_df[[\"class\", \"comment_sentence\", \"combo\"]].applymap(\n","<ipython-input-4-df4392ae2e99>:12: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n","  test_str_df = test_df[[\"class\", \"comment_sentence\", \"combo\"]].applymap(\n"]},{"output_type":"display_data","data":{"text/plain":["   index                      class  \\\n","0      0  blanchorrelativetoelement   \n","1      2     blarrowheadsimplearrow   \n","2      3     blarrowheadsimplearrow   \n","3      4     blarrowheadsimplearrow   \n","4      8        blarrowheadtriangle   \n","\n","                                    comment_sentence  partition  \\\n","0  relative anchor takes an arbitrary element as ...          0   \n","1                i am a simple arrow like arrowhead.          0   \n","2  both my size and arrow length depend on the cu...          0   \n","3  it is possible hovewer to customize a length f...          0   \n","4                      i am a triangular arrow head.          0   \n","\n","                                               combo                 labels  \n","0  relative anchor takes an arbitrary element as ...  [0, 0, 1, 0, 0, 0, 0]  \n","1  i am a simple arrow like arrowhead | blarrowhe...  [0, 0, 0, 0, 1, 0, 0]  \n","2  both my size and arrow length depend on the cu...  [0, 0, 0, 0, 1, 0, 0]  \n","3  it is possible hovewer to customize a length f...  [0, 0, 0, 0, 0, 1, 0]  \n","4  i am a triangular arrow head | blarrowheadtria...  [0, 0, 0, 0, 1, 0, 0]  "],"text/html":["\n","  <div id=\"df-dcacace4-40ef-4764-bdbc-2f84c726e4f4\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>class</th>\n","      <th>comment_sentence</th>\n","      <th>partition</th>\n","      <th>combo</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>blanchorrelativetoelement</td>\n","      <td>relative anchor takes an arbitrary element as ...</td>\n","      <td>0</td>\n","      <td>relative anchor takes an arbitrary element as ...</td>\n","      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>blarrowheadsimplearrow</td>\n","      <td>i am a simple arrow like arrowhead.</td>\n","      <td>0</td>\n","      <td>i am a simple arrow like arrowhead | blarrowhe...</td>\n","      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>blarrowheadsimplearrow</td>\n","      <td>both my size and arrow length depend on the cu...</td>\n","      <td>0</td>\n","      <td>both my size and arrow length depend on the cu...</td>\n","      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>blarrowheadsimplearrow</td>\n","      <td>it is possible hovewer to customize a length f...</td>\n","      <td>0</td>\n","      <td>it is possible hovewer to customize a length f...</td>\n","      <td>[0, 0, 0, 0, 0, 1, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8</td>\n","      <td>blarrowheadtriangle</td>\n","      <td>i am a triangular arrow head.</td>\n","      <td>0</td>\n","      <td>i am a triangular arrow head | blarrowheadtria...</td>\n","      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dcacace4-40ef-4764-bdbc-2f84c726e4f4')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-dcacace4-40ef-4764-bdbc-2f84c726e4f4 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-dcacace4-40ef-4764-bdbc-2f84c726e4f4');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-cc10bfa2-d5c3-40a9-9799-e0e55e89608a\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc10bfa2-d5c3-40a9-9799-e0e55e89608a')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-cc10bfa2-d5c3-40a9-9799-e0e55e89608a button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(test_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          8,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"blanchorrelativetoelement\",\n          \"blarrowheadsimplearrow\",\n          \"blarrowheadtriangle\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comment_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"i am a simple arrow like arrowhead.\",\n          \"i am a triangular arrow head.\",\n          \"both my size and arrow length depend on the curve width.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"partition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"combo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"i am a simple arrow like arrowhead | blarrowheadsimplearrow\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["   index                   class  \\\n","0      1     blarrowheadexamples   \n","1      5  blarrowheadsimplearrow   \n","2      6  blarrowheadsimplearrow   \n","3      7  blarrowheadsimplearrow   \n","4      9     blarrowheadtriangle   \n","\n","                                    comment_sentence  partition  \\\n","0  i contain examples of different types of blarr...          1   \n","1  users can also customise nose angle that tells...          1   \n","2  the with of the outer arrows can be specified ...          1   \n","3  i support both background and border paint and...          1   \n","4  my size depends on the width of a curve and he...          1   \n","\n","                                               combo                 labels  \n","0  i contain examples of different types of blarr...  [0, 0, 1, 1, 0, 0, 0]  \n","1  users can also customise nose angle that tells...  [0, 1, 0, 0, 0, 0, 0]  \n","2  the with of the outer arrows can be specified ...  [0, 0, 1, 0, 0, 0, 0]  \n","3  i support both background and border paint and...  [0, 0, 1, 0, 0, 0, 0]  \n","4  my size depends on the width of a curve and he...  [0, 0, 1, 0, 0, 0, 0]  "],"text/html":["\n","  <div id=\"df-813a5cd9-69ee-41c5-84a9-d81c0016add3\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>class</th>\n","      <th>comment_sentence</th>\n","      <th>partition</th>\n","      <th>combo</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>blarrowheadexamples</td>\n","      <td>i contain examples of different types of blarr...</td>\n","      <td>1</td>\n","      <td>i contain examples of different types of blarr...</td>\n","      <td>[0, 0, 1, 1, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>blarrowheadsimplearrow</td>\n","      <td>users can also customise nose angle that tells...</td>\n","      <td>1</td>\n","      <td>users can also customise nose angle that tells...</td>\n","      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>6</td>\n","      <td>blarrowheadsimplearrow</td>\n","      <td>the with of the outer arrows can be specified ...</td>\n","      <td>1</td>\n","      <td>the with of the outer arrows can be specified ...</td>\n","      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7</td>\n","      <td>blarrowheadsimplearrow</td>\n","      <td>i support both background and border paint and...</td>\n","      <td>1</td>\n","      <td>i support both background and border paint and...</td>\n","      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9</td>\n","      <td>blarrowheadtriangle</td>\n","      <td>my size depends on the width of a curve and he...</td>\n","      <td>1</td>\n","      <td>my size depends on the width of a curve and he...</td>\n","      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-813a5cd9-69ee-41c5-84a9-d81c0016add3')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-813a5cd9-69ee-41c5-84a9-d81c0016add3 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-813a5cd9-69ee-41c5-84a9-d81c0016add3');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-7dd5cca3-776d-4c67-80b8-8bb6284aeb30\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7dd5cca3-776d-4c67-80b8-8bb6284aeb30')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-7dd5cca3-776d-4c67-80b8-8bb6284aeb30 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(test_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 9,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5,\n          9,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"blarrowheadexamples\",\n          \"blarrowheadsimplearrow\",\n          \"blarrowheadtriangle\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comment_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"users can also customise nose angle that tells how wide should the arrow lines be spread.\",\n          \"my size depends on the width of a curve and hence can not be manually specified.\",\n          \"the with of the outer arrows can be specified by changing border width of a simple arrow arrowhead.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"partition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"combo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"users can also customise nose angle that tells how wide should the arrow lines be spread | blarrowheadsimplearrow\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}],"source":["def remove_punctuation_except_pipe(text):\n","    return re.sub(r\"[^\\w\\s\\|]\", \"\", text)\n","\n","# Apply the function to the 'combo' column\n","train_df['combo'] = train_df['combo'].apply(remove_punctuation_except_pipe)\n","test_df['combo'] = test_df['combo'].apply(remove_punctuation_except_pipe)\n","\n","# Convert data to lowercase\n","train_str_df = train_df[[\"class\", \"comment_sentence\", \"combo\"]].applymap(\n","    lambda x: x.lower() if isinstance(x, str) else str(x)\n",")\n","test_str_df = test_df[[\"class\", \"comment_sentence\", \"combo\"]].applymap(\n","    lambda x: x.lower() if isinstance(x, str) else str(x)\n",")\n","\n","train_df[[\"class\", \"comment_sentence\", \"combo\"]] = train_str_df[[\"class\", \"comment_sentence\", \"combo\"]]\n","test_df[[\"class\", \"comment_sentence\", \"combo\"]] = test_str_df[[\"class\", \"comment_sentence\", \"combo\"]]\n","\n","display(train_df.head())\n","display(test_df.head())"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"20n8nIz2zr-2","executionInfo":{"status":"ok","timestamp":1733076263892,"user_tz":480,"elapsed":223,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[],"source":["X = list(train_df['combo'])\n","y = list(train_df['labels'])\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":272,"referenced_widgets":["b82b0e8a1eb0463198043cea88273161","8013c29158ca4eaf95307a27e702b1fc","9a29f095074040f08c712c13f61a7ede","6747442b0ba1464ca0e6960b0e8adc04","98e51bc301b249bbbadbde10b0dd81f4","7aad82966c774937b8b2870b171079a4","48bf4c9eb7fb4330a8be3f6e4f8d0aae","976ff798dbf5498ebc8e0be6e9623893","eef4781e64b24eba8149c9be5a5b463e","50a687f9bfb3480aa31442a242ef9b9b","60f4b959dd0d4196be48a91d7d155b03","6a92e56b34ba4e40a1bb9b393fb43bcc","3c271d0869a04cc98b435000914dda71","420aadfa4d494c499d34dc7f7dbb77f5","39c37137b837475bb53cd53e02ae583d","4239d58e790e491da1b09611bd885116","e4873b7238c44e2b9d7e18d279efbdd1","c81767e8afe64075af1c38f6e0ca74f4","e60905acac704f0a8db6fc8914c68898","3c1e3d60bec147e5bdf3043517624354","97788bc2891d490eb6ddcda626a71b58","f2a2cabfe49f44ca9cf68ba38d378010","d1ff95018bd34bec8b8132121200b51d","861cbe93fc6f4a3390cf007a8f7d4544","321d5d304073466296009736d31ff3c6","7844851374b14f298aa5ac8563b33999","88d01bfed2864b9c9d794b017e2a3f70","c255f02fa54f400ba7e0d099b45a301e","c93c5169701547d8911ecaae6f68e15f","948300ae1c684c84a0b4a1572b50ec87","bd3f439b83dd404390ddbe326fb915d8","7dd0660174e3435a959a1bbe1c29cb06","c3ddce7aeb674c46ad22b37abc2d2b08"]},"id":"4lJ7iGgPzwDz","outputId":"07845b19-d70d-4f52-d738-dbaeff92cdc0","executionInfo":{"status":"ok","timestamp":1733076275083,"user_tz":480,"elapsed":11409,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/409 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b82b0e8a1eb0463198043cea88273161"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a92e56b34ba4e40a1bb9b393fb43bcc"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/59.8M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1ff95018bd34bec8b8132121200b51d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:1439: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(resolved_archive_file, map_location=\"cpu\")\n","Some weights of the model checkpoint at huawei-noah/TinyBERT_General_4L_312D were not used when initializing BertForSequenceClassification: ['fit_denses.4.bias', 'cls.predictions.transform.LayerNorm.weight', 'fit_denses.1.weight', 'fit_denses.0.weight', 'fit_denses.0.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'fit_denses.4.weight', 'fit_denses.3.weight', 'fit_denses.3.bias', 'fit_denses.1.bias', 'cls.seq_relationship.weight', 'fit_denses.2.weight', 'fit_denses.2.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained('huawei-noah/TinyBERT_General_4L_312D')\n","model = AutoModelForSequenceClassification.from_pretrained('huawei-noah/TinyBERT_General_4L_312D', num_labels=7)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"BLFFkwfl0j2W","executionInfo":{"status":"ok","timestamp":1733076275095,"user_tz":480,"elapsed":120,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[],"source":["class TextClassificationDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, device=\"cpu\"):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.device = device\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, index):\n","        text = self.texts[index]\n","        label = self.labels[index]\n","\n","        encoded_text = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=256,\n","            padding='max_length',\n","            truncation=True,\n","            return_token_type_ids=False,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","        )\n","\n","        input_ids = encoded_text['input_ids'].squeeze().to(self.device)\n","        attention_mask = encoded_text['attention_mask'].squeeze().to(self.device)\n","        label = torch.tensor(label, dtype=torch.float).to(self.device)\n","\n","        return {\n","            'input_ids': input_ids,\n","            'attention_mask': attention_mask,\n","            'labels': label\n","        }\n","\n","train_dataset = TextClassificationDataset(X_train, y_train, tokenizer)\n","eval_dataset = TextClassificationDataset(X_val, y_val, tokenizer)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"aO311Hhf0rKO","executionInfo":{"status":"ok","timestamp":1733076275099,"user_tz":480,"elapsed":122,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[],"source":["class OneHotTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        labels = inputs.get(\"labels\")\n","        model_inputs = {k: v for k, v in inputs.items() if k != \"labels\"}\n","        outputs = model(**model_inputs)\n","        logits = outputs.get(\"logits\")\n","\n","        if logits is None:\n","            raise ValueError(\"Logits are missing from the model output.\")\n","\n","        loss_fct = nn.BCEWithLogitsLoss()\n","        loss = loss_fct(logits, labels.float())\n","\n","        return (loss, outputs) if return_outputs else loss\n","\n","\n","# class OneHotTrainer(Trainer):\n","#     def compute_loss(self, model, inputs, return_outputs=False):\n","#         labels = inputs.get(\"labels\")\n","#         # Remove 'labels' from inputs before passing to model\n","#         model_inputs = {k: v for k, v in inputs.items() if k != \"labels\"}\n","#         outputs = model(**model_inputs)  # Pass only the required inputs to the model\n","#         logits = outputs.get(\"logits\")\n","\n","#         if logits is None:\n","#             # Handle the case where logits are missing, e.g., raise an exception or return a default loss\n","#             raise ValueError(\"Logits are missing from the model output.\")  # Or return a default loss\n","\n","#         # Use BCEWithLogitsLoss for multi-label classification\n","#         loss_fct = nn.BCEWithLogitsLoss()\n","#         loss = loss_fct(logits, labels.float())\n","\n","#         return (loss, outputs) if return_outputs else loss"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"-pVPFv7O0ut3","executionInfo":{"status":"ok","timestamp":1733076275099,"user_tz":480,"elapsed":119,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[],"source":["def compute_metrics(pred):\n","    logits = pred.predictions\n","    preds = (logits > 0).astype(int)\n","    labels = pred.label_ids\n","\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=1)\n","    accuracy = accuracy_score(labels, preds)\n","\n","    return {\n","        'accuracy': accuracy,\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1\n","    }\n","\n","\n","# def compute_metrics(pred):\n","#     logits = pred.predictions\n","#     preds = (logits > 0).astype(int)\n","\n","#     labels = pred.label_ids\n","\n","#     precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n","#     accuracy = (preds == labels).mean()\n","\n","#     return {\n","#         'accuracy': accuracy,\n","#         'precision': precision,\n","#         'recall': recall,\n","#         'f1': f1\n","#     }\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"nOK9HTwq9wuM","executionInfo":{"status":"ok","timestamp":1733076275100,"user_tz":480,"elapsed":117,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[],"source":["def objective(trial):\n","    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","    batch_size = trial.suggest_categorical(\"batch_size\", [4, 8, 16])\n","    num_train_epochs = trial.suggest_int(\"num_train_epochs\", 3, 20)\n","    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","\n","    # training_args = TrainingArguments(\n","    #     output_dir=\"./results\",\n","    #     num_train_epochs=num_train_epochs,\n","    #     per_device_train_batch_size=batch_size,\n","    #     per_device_eval_batch_size=batch_size * 2,\n","    #     warmup_steps=10,\n","    #     weight_decay=weight_decay,\n","    #     evaluation_strategy=\"epoch\",\n","    #     learning_rate=learning_rate,\n","    #     gradient_accumulation_steps=2,\n","    #     report_to=\"none\",\n","    # )\n","\n","    training_args = TrainingArguments(\n","        output_dir=\"./results\",\n","        num_train_epochs=num_train_epochs,\n","        per_device_train_batch_size=batch_size,\n","        per_device_eval_batch_size=batch_size * 2,\n","        warmup_steps=10,\n","        weight_decay=weight_decay,\n","        evaluation_strategy=\"epoch\",\n","        logging_dir=\"./logs\",  # Directory for logging\n","        logging_steps=10,  # Log every 10 steps\n","        save_steps=500,\n","        learning_rate=learning_rate,\n","        gradient_accumulation_steps=2,\n","        report_to=\"none\",  # Avoid reporting to third-party loggers like WandB\n","        logging_first_step=True,  # Log the first step\n","    )\n","\n","    trainer = OneHotTrainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=train_dataset,\n","        eval_dataset=eval_dataset,\n","        compute_metrics=compute_metrics,\n","    )\n","    print(\"Starting training...\")\n","    trainer.train()\n","    eval_results = trainer.evaluate()\n","\n","    return eval_results[\"eval_f1\"]"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"-12Jc6Vq-FNz","outputId":"7b714dcd-bbfd-49d0-bedc-9c429d9e550a","executionInfo":{"status":"ok","timestamp":1733078048276,"user_tz":480,"elapsed":1773279,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-12-01 18:04:34,139] A new study created in memory with name: no-name-0222862b-c32e-4dfb-a499-62fb1b4aa9e0\n","<ipython-input-10-747f1883d862>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-747f1883d862>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1038\n","  Num Epochs = 9\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 585\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='585' max='585' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [585/585 00:50, Epoch 9/9]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.652100</td>\n","      <td>0.641178</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.599000</td>\n","      <td>0.592053</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.564600</td>\n","      <td>0.555377</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.530600</td>\n","      <td>0.527685</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.511300</td>\n","      <td>0.507684</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.497900</td>\n","      <td>0.493723</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.485500</td>\n","      <td>0.484699</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.488900</td>\n","      <td>0.479627</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.481100</td>\n","      <td>0.477988</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [17/17 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-01 18:05:33,215] Trial 0 finished with value: 0.0 and parameters: {'learning_rate': 7.093939338868338e-06, 'batch_size': 8, 'num_train_epochs': 9, 'weight_decay': 0.0003358565639343298}. Best is trial 0 with value: 0.0.\n","<ipython-input-10-747f1883d862>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-747f1883d862>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1038\n","  Num Epochs = 19\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 1235\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1235' max='1235' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1235/1235 01:48, Epoch 19/19]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.476800</td>\n","      <td>0.474215</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.473000</td>\n","      <td>0.470406</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.470900</td>\n","      <td>0.466978</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.462600</td>\n","      <td>0.463869</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.460600</td>\n","      <td>0.461080</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.461300</td>\n","      <td>0.458546</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.455000</td>\n","      <td>0.456289</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.464300</td>\n","      <td>0.454270</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.455200</td>\n","      <td>0.452488</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.447500</td>\n","      <td>0.450904</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.453900</td>\n","      <td>0.449518</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.453000</td>\n","      <td>0.448308</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.448200</td>\n","      <td>0.447294</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.457500</td>\n","      <td>0.446426</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.442200</td>\n","      <td>0.445745</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.442800</td>\n","      <td>0.445207</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.430500</td>\n","      <td>0.444829</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.451800</td>\n","      <td>0.444600</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.438200</td>\n","      <td>0.444522</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [17/17 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-01 18:07:21,962] Trial 1 finished with value: 0.0 and parameters: {'learning_rate': 1.0113102156589775e-06, 'batch_size': 8, 'num_train_epochs': 19, 'weight_decay': 0.000507405452985511}. Best is trial 0 with value: 0.0.\n","<ipython-input-10-747f1883d862>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-747f1883d862>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1038\n","  Num Epochs = 9\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 288\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='288' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [288/288 00:46, Epoch 8/9]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.440900</td>\n","      <td>0.432539</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.421600</td>\n","      <td>0.422561</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.403500</td>\n","      <td>0.416264</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.416200</td>\n","      <td>0.411966</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.403500</td>\n","      <td>0.409049</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.410300</td>\n","      <td>0.406640</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.403300</td>\n","      <td>0.404886</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.394300</td>\n","      <td>0.403769</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.406700</td>\n","      <td>0.403313</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [9/9 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-01 18:08:08,716] Trial 2 finished with value: 0.0 and parameters: {'learning_rate': 1.0804450118916024e-05, 'batch_size': 16, 'num_train_epochs': 9, 'weight_decay': 0.00014752758003352815}. Best is trial 0 with value: 0.0.\n","<ipython-input-10-747f1883d862>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-747f1883d862>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1038\n","  Num Epochs = 17\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 2210\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2210' max='2210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2210/2210 01:54, Epoch 17/17]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.381900</td>\n","      <td>0.381332</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.383300</td>\n","      <td>0.363894</td>\n","      <td>0.315385</td>\n","      <td>0.918045</td>\n","      <td>0.280936</td>\n","      <td>0.289835</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.337200</td>\n","      <td>0.346843</td>\n","      <td>0.376923</td>\n","      <td>0.906105</td>\n","      <td>0.337793</td>\n","      <td>0.310551</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.333000</td>\n","      <td>0.329490</td>\n","      <td>0.350000</td>\n","      <td>0.799104</td>\n","      <td>0.311037</td>\n","      <td>0.326804</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.298600</td>\n","      <td>0.318381</td>\n","      <td>0.369231</td>\n","      <td>0.857418</td>\n","      <td>0.351171</td>\n","      <td>0.370112</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.284100</td>\n","      <td>0.311673</td>\n","      <td>0.388462</td>\n","      <td>0.759866</td>\n","      <td>0.347826</td>\n","      <td>0.325018</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.299500</td>\n","      <td>0.304813</td>\n","      <td>0.330769</td>\n","      <td>0.857525</td>\n","      <td>0.304348</td>\n","      <td>0.341803</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.274400</td>\n","      <td>0.297182</td>\n","      <td>0.392308</td>\n","      <td>0.847531</td>\n","      <td>0.431438</td>\n","      <td>0.460272</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.245900</td>\n","      <td>0.290343</td>\n","      <td>0.373077</td>\n","      <td>0.873819</td>\n","      <td>0.371237</td>\n","      <td>0.406462</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.255800</td>\n","      <td>0.288410</td>\n","      <td>0.403846</td>\n","      <td>0.839915</td>\n","      <td>0.428094</td>\n","      <td>0.452166</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.237300</td>\n","      <td>0.283700</td>\n","      <td>0.426923</td>\n","      <td>0.847410</td>\n","      <td>0.441472</td>\n","      <td>0.461179</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.262800</td>\n","      <td>0.283759</td>\n","      <td>0.423077</td>\n","      <td>0.715493</td>\n","      <td>0.431438</td>\n","      <td>0.444430</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.252400</td>\n","      <td>0.279939</td>\n","      <td>0.461538</td>\n","      <td>0.811161</td>\n","      <td>0.478261</td>\n","      <td>0.515275</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.261600</td>\n","      <td>0.278235</td>\n","      <td>0.461538</td>\n","      <td>0.834410</td>\n","      <td>0.468227</td>\n","      <td>0.522358</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.229200</td>\n","      <td>0.276873</td>\n","      <td>0.442308</td>\n","      <td>0.792463</td>\n","      <td>0.451505</td>\n","      <td>0.482902</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.267900</td>\n","      <td>0.277318</td>\n","      <td>0.469231</td>\n","      <td>0.808406</td>\n","      <td>0.484950</td>\n","      <td>0.518008</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.264600</td>\n","      <td>0.276385</td>\n","      <td>0.484615</td>\n","      <td>0.824021</td>\n","      <td>0.494983</td>\n","      <td>0.532968</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1500\n","Configuration saved in ./results/checkpoint-1500/config.json\n","Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-2000\n","Configuration saved in ./results/checkpoint-2000/config.json\n","Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [33/33 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-01 18:10:04,025] Trial 3 finished with value: 0.5329681729216156 and parameters: {'learning_rate': 1.5915973006854297e-05, 'batch_size': 4, 'num_train_epochs': 17, 'weight_decay': 0.0008834529956927268}. Best is trial 3 with value: 0.5329681729216156.\n","<ipython-input-10-747f1883d862>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-747f1883d862>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1038\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 1300\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1300' max='1300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1300/1300 01:53, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.229700</td>\n","      <td>0.277528</td>\n","      <td>0.461538</td>\n","      <td>0.824646</td>\n","      <td>0.505017</td>\n","      <td>0.547040</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.254000</td>\n","      <td>0.276397</td>\n","      <td>0.476923</td>\n","      <td>0.812384</td>\n","      <td>0.488294</td>\n","      <td>0.521210</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.230100</td>\n","      <td>0.275172</td>\n","      <td>0.488462</td>\n","      <td>0.818239</td>\n","      <td>0.498328</td>\n","      <td>0.533683</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.233700</td>\n","      <td>0.274606</td>\n","      <td>0.488462</td>\n","      <td>0.817028</td>\n","      <td>0.498328</td>\n","      <td>0.534083</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.220000</td>\n","      <td>0.274784</td>\n","      <td>0.480769</td>\n","      <td>0.819553</td>\n","      <td>0.518395</td>\n","      <td>0.551207</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.229400</td>\n","      <td>0.274660</td>\n","      <td>0.480769</td>\n","      <td>0.816525</td>\n","      <td>0.508361</td>\n","      <td>0.542541</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.215400</td>\n","      <td>0.274436</td>\n","      <td>0.488462</td>\n","      <td>0.819850</td>\n","      <td>0.515050</td>\n","      <td>0.549668</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.234400</td>\n","      <td>0.274397</td>\n","      <td>0.492308</td>\n","      <td>0.808798</td>\n","      <td>0.501672</td>\n","      <td>0.533615</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.236900</td>\n","      <td>0.274298</td>\n","      <td>0.476923</td>\n","      <td>0.818803</td>\n","      <td>0.515050</td>\n","      <td>0.551544</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.224300</td>\n","      <td>0.273471</td>\n","      <td>0.484615</td>\n","      <td>0.816310</td>\n","      <td>0.521739</td>\n","      <td>0.553327</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.232700</td>\n","      <td>0.273563</td>\n","      <td>0.492308</td>\n","      <td>0.819098</td>\n","      <td>0.525084</td>\n","      <td>0.555345</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.238500</td>\n","      <td>0.272866</td>\n","      <td>0.488462</td>\n","      <td>0.813822</td>\n","      <td>0.515050</td>\n","      <td>0.546078</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.233900</td>\n","      <td>0.272959</td>\n","      <td>0.480769</td>\n","      <td>0.821405</td>\n","      <td>0.518395</td>\n","      <td>0.554960</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.250900</td>\n","      <td>0.272568</td>\n","      <td>0.496154</td>\n","      <td>0.821246</td>\n","      <td>0.515050</td>\n","      <td>0.548255</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.221500</td>\n","      <td>0.272642</td>\n","      <td>0.488462</td>\n","      <td>0.814574</td>\n","      <td>0.518395</td>\n","      <td>0.548423</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.237000</td>\n","      <td>0.272414</td>\n","      <td>0.488462</td>\n","      <td>0.810745</td>\n","      <td>0.515050</td>\n","      <td>0.545039</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.197700</td>\n","      <td>0.272450</td>\n","      <td>0.496154</td>\n","      <td>0.819843</td>\n","      <td>0.528428</td>\n","      <td>0.558018</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.244500</td>\n","      <td>0.272365</td>\n","      <td>0.488462</td>\n","      <td>0.810745</td>\n","      <td>0.515050</td>\n","      <td>0.545039</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.224600</td>\n","      <td>0.272379</td>\n","      <td>0.484615</td>\n","      <td>0.810345</td>\n","      <td>0.511706</td>\n","      <td>0.543186</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.232000</td>\n","      <td>0.272381</td>\n","      <td>0.488462</td>\n","      <td>0.810745</td>\n","      <td>0.515050</td>\n","      <td>0.545039</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [17/17 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-01 18:11:57,694] Trial 4 finished with value: 0.5450388344937757 and parameters: {'learning_rate': 1.6191123578201777e-06, 'batch_size': 8, 'num_train_epochs': 20, 'weight_decay': 0.000760990665756832}. Best is trial 4 with value: 0.5450388344937757.\n","<ipython-input-10-747f1883d862>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-747f1883d862>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1038\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 1300\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1300' max='1300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1300/1300 01:53, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.219900</td>\n","      <td>0.275173</td>\n","      <td>0.473077</td>\n","      <td>0.807944</td>\n","      <td>0.518395</td>\n","      <td>0.551362</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.244300</td>\n","      <td>0.271477</td>\n","      <td>0.496154</td>\n","      <td>0.814366</td>\n","      <td>0.508361</td>\n","      <td>0.538411</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.218500</td>\n","      <td>0.270424</td>\n","      <td>0.500000</td>\n","      <td>0.815841</td>\n","      <td>0.531773</td>\n","      <td>0.558363</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.223400</td>\n","      <td>0.270254</td>\n","      <td>0.515385</td>\n","      <td>0.825084</td>\n","      <td>0.538462</td>\n","      <td>0.564225</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.206100</td>\n","      <td>0.270673</td>\n","      <td>0.496154</td>\n","      <td>0.799014</td>\n","      <td>0.541806</td>\n","      <td>0.560168</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.218300</td>\n","      <td>0.269718</td>\n","      <td>0.496154</td>\n","      <td>0.812247</td>\n","      <td>0.531773</td>\n","      <td>0.559660</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.200900</td>\n","      <td>0.269915</td>\n","      <td>0.500000</td>\n","      <td>0.826559</td>\n","      <td>0.538462</td>\n","      <td>0.570939</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.220300</td>\n","      <td>0.270095</td>\n","      <td>0.511538</td>\n","      <td>0.806859</td>\n","      <td>0.551839</td>\n","      <td>0.568619</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.222200</td>\n","      <td>0.270390</td>\n","      <td>0.500000</td>\n","      <td>0.809600</td>\n","      <td>0.551839</td>\n","      <td>0.572141</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.210700</td>\n","      <td>0.267598</td>\n","      <td>0.507692</td>\n","      <td>0.811516</td>\n","      <td>0.558528</td>\n","      <td>0.576394</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.218100</td>\n","      <td>0.269419</td>\n","      <td>0.500000</td>\n","      <td>0.800192</td>\n","      <td>0.551839</td>\n","      <td>0.566959</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.223100</td>\n","      <td>0.266587</td>\n","      <td>0.515385</td>\n","      <td>0.817072</td>\n","      <td>0.558528</td>\n","      <td>0.577945</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.218900</td>\n","      <td>0.267406</td>\n","      <td>0.515385</td>\n","      <td>0.812120</td>\n","      <td>0.551839</td>\n","      <td>0.571012</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.235700</td>\n","      <td>0.266663</td>\n","      <td>0.515385</td>\n","      <td>0.812470</td>\n","      <td>0.548495</td>\n","      <td>0.567454</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.205600</td>\n","      <td>0.266804</td>\n","      <td>0.523077</td>\n","      <td>0.811856</td>\n","      <td>0.555184</td>\n","      <td>0.571899</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.222100</td>\n","      <td>0.266258</td>\n","      <td>0.519231</td>\n","      <td>0.809292</td>\n","      <td>0.555184</td>\n","      <td>0.570474</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.181800</td>\n","      <td>0.266261</td>\n","      <td>0.515385</td>\n","      <td>0.808519</td>\n","      <td>0.555184</td>\n","      <td>0.571219</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.227100</td>\n","      <td>0.266032</td>\n","      <td>0.519231</td>\n","      <td>0.818200</td>\n","      <td>0.551839</td>\n","      <td>0.571887</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.208100</td>\n","      <td>0.266110</td>\n","      <td>0.515385</td>\n","      <td>0.807819</td>\n","      <td>0.551839</td>\n","      <td>0.568948</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.215500</td>\n","      <td>0.266102</td>\n","      <td>0.523077</td>\n","      <td>0.812396</td>\n","      <td>0.555184</td>\n","      <td>0.571461</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [17/17 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-01 18:13:51,540] Trial 5 finished with value: 0.5714605329143311 and parameters: {'learning_rate': 3.6178623442958105e-06, 'batch_size': 8, 'num_train_epochs': 20, 'weight_decay': 0.003871277838422589}. Best is trial 5 with value: 0.5714605329143311.\n","<ipython-input-10-747f1883d862>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-747f1883d862>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1038\n","  Num Epochs = 19\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 608\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='608' max='608' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [608/608 01:38, Epoch 18/19]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.216700</td>\n","      <td>0.273509</td>\n","      <td>0.496154</td>\n","      <td>0.817331</td>\n","      <td>0.525084</td>\n","      <td>0.551149</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.200200</td>\n","      <td>0.272210</td>\n","      <td>0.496154</td>\n","      <td>0.828446</td>\n","      <td>0.545151</td>\n","      <td>0.576816</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.188600</td>\n","      <td>0.261063</td>\n","      <td>0.519231</td>\n","      <td>0.808224</td>\n","      <td>0.565217</td>\n","      <td>0.577620</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.208400</td>\n","      <td>0.273278</td>\n","      <td>0.534615</td>\n","      <td>0.779821</td>\n","      <td>0.538462</td>\n","      <td>0.534784</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.186000</td>\n","      <td>0.260548</td>\n","      <td>0.542308</td>\n","      <td>0.817435</td>\n","      <td>0.568562</td>\n","      <td>0.589397</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.195700</td>\n","      <td>0.254963</td>\n","      <td>0.557692</td>\n","      <td>0.806643</td>\n","      <td>0.588629</td>\n","      <td>0.594086</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.184300</td>\n","      <td>0.256925</td>\n","      <td>0.526923</td>\n","      <td>0.818273</td>\n","      <td>0.518395</td>\n","      <td>0.538241</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.177700</td>\n","      <td>0.253729</td>\n","      <td>0.588462</td>\n","      <td>0.800320</td>\n","      <td>0.615385</td>\n","      <td>0.621793</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.185800</td>\n","      <td>0.253959</td>\n","      <td>0.561538</td>\n","      <td>0.811561</td>\n","      <td>0.588629</td>\n","      <td>0.612208</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.172400</td>\n","      <td>0.253367</td>\n","      <td>0.561538</td>\n","      <td>0.815883</td>\n","      <td>0.581940</td>\n","      <td>0.603783</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.169400</td>\n","      <td>0.248982</td>\n","      <td>0.569231</td>\n","      <td>0.810268</td>\n","      <td>0.598662</td>\n","      <td>0.617829</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.163100</td>\n","      <td>0.249718</td>\n","      <td>0.588462</td>\n","      <td>0.829810</td>\n","      <td>0.602007</td>\n","      <td>0.632066</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.164800</td>\n","      <td>0.247890</td>\n","      <td>0.573077</td>\n","      <td>0.831996</td>\n","      <td>0.581940</td>\n","      <td>0.614856</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.165900</td>\n","      <td>0.245773</td>\n","      <td>0.603846</td>\n","      <td>0.826698</td>\n","      <td>0.625418</td>\n","      <td>0.650654</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.158500</td>\n","      <td>0.244733</td>\n","      <td>0.607692</td>\n","      <td>0.824918</td>\n","      <td>0.618729</td>\n","      <td>0.645771</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.163600</td>\n","      <td>0.244665</td>\n","      <td>0.615385</td>\n","      <td>0.812944</td>\n","      <td>0.632107</td>\n","      <td>0.659800</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.176300</td>\n","      <td>0.244009</td>\n","      <td>0.603846</td>\n","      <td>0.828181</td>\n","      <td>0.618729</td>\n","      <td>0.650464</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.155700</td>\n","      <td>0.243505</td>\n","      <td>0.607692</td>\n","      <td>0.815733</td>\n","      <td>0.622074</td>\n","      <td>0.651006</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.174900</td>\n","      <td>0.243301</td>\n","      <td>0.611538</td>\n","      <td>0.818386</td>\n","      <td>0.625418</td>\n","      <td>0.656315</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [9/9 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-01 18:15:30,176] Trial 6 finished with value: 0.6563146997929605 and parameters: {'learning_rate': 2.0681880486463444e-05, 'batch_size': 16, 'num_train_epochs': 19, 'weight_decay': 0.001194804608966865}. Best is trial 6 with value: 0.6563146997929605.\n","<ipython-input-10-747f1883d862>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-747f1883d862>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1038\n","  Num Epochs = 18\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 2340\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2340' max='2340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2340/2340 02:01, Epoch 18/18]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.164800</td>\n","      <td>0.247014</td>\n","      <td>0.592308</td>\n","      <td>0.790228</td>\n","      <td>0.638796</td>\n","      <td>0.672049</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.198000</td>\n","      <td>0.240002</td>\n","      <td>0.615385</td>\n","      <td>0.790894</td>\n","      <td>0.638796</td>\n","      <td>0.666242</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.141300</td>\n","      <td>0.252351</td>\n","      <td>0.634615</td>\n","      <td>0.778363</td>\n","      <td>0.655518</td>\n","      <td>0.665257</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.142300</td>\n","      <td>0.242489</td>\n","      <td>0.661538</td>\n","      <td>0.795797</td>\n","      <td>0.685619</td>\n","      <td>0.705393</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.128800</td>\n","      <td>0.240166</td>\n","      <td>0.657692</td>\n","      <td>0.810111</td>\n","      <td>0.682274</td>\n","      <td>0.706736</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.107100</td>\n","      <td>0.244172</td>\n","      <td>0.650000</td>\n","      <td>0.806886</td>\n","      <td>0.682274</td>\n","      <td>0.708582</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.130200</td>\n","      <td>0.242393</td>\n","      <td>0.669231</td>\n","      <td>0.821337</td>\n","      <td>0.688963</td>\n","      <td>0.716924</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.111100</td>\n","      <td>0.232256</td>\n","      <td>0.680769</td>\n","      <td>0.773590</td>\n","      <td>0.712375</td>\n","      <td>0.720807</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.087400</td>\n","      <td>0.225463</td>\n","      <td>0.688462</td>\n","      <td>0.799727</td>\n","      <td>0.719064</td>\n","      <td>0.737118</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.093200</td>\n","      <td>0.238172</td>\n","      <td>0.676923</td>\n","      <td>0.759844</td>\n","      <td>0.712375</td>\n","      <td>0.727246</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.065400</td>\n","      <td>0.233933</td>\n","      <td>0.684615</td>\n","      <td>0.782445</td>\n","      <td>0.712375</td>\n","      <td>0.736369</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.090700</td>\n","      <td>0.234760</td>\n","      <td>0.692308</td>\n","      <td>0.809564</td>\n","      <td>0.705686</td>\n","      <td>0.735518</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.085700</td>\n","      <td>0.237218</td>\n","      <td>0.692308</td>\n","      <td>0.782384</td>\n","      <td>0.705686</td>\n","      <td>0.725782</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.090300</td>\n","      <td>0.237571</td>\n","      <td>0.684615</td>\n","      <td>0.789655</td>\n","      <td>0.698997</td>\n","      <td>0.726610</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.079700</td>\n","      <td>0.236360</td>\n","      <td>0.692308</td>\n","      <td>0.795442</td>\n","      <td>0.695652</td>\n","      <td>0.723031</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.095800</td>\n","      <td>0.234818</td>\n","      <td>0.696154</td>\n","      <td>0.781511</td>\n","      <td>0.722408</td>\n","      <td>0.741922</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.085500</td>\n","      <td>0.239438</td>\n","      <td>0.688462</td>\n","      <td>0.777552</td>\n","      <td>0.709030</td>\n","      <td>0.730631</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.084400</td>\n","      <td>0.237634</td>\n","      <td>0.696154</td>\n","      <td>0.776779</td>\n","      <td>0.709030</td>\n","      <td>0.731219</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1500\n","Configuration saved in ./results/checkpoint-1500/config.json\n","Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-2000\n","Configuration saved in ./results/checkpoint-2000/config.json\n","Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [33/33 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-01 18:17:32,704] Trial 7 finished with value: 0.7312187307131695 and parameters: {'learning_rate': 2.2212657302666784e-05, 'batch_size': 4, 'num_train_epochs': 18, 'weight_decay': 0.02242846062194608}. Best is trial 7 with value: 0.7312187307131695.\n","<ipython-input-10-747f1883d862>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-747f1883d862>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1038\n","  Num Epochs = 19\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 608\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='608' max='608' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [608/608 01:38, Epoch 18/19]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.074700</td>\n","      <td>0.236005</td>\n","      <td>0.692308</td>\n","      <td>0.788581</td>\n","      <td>0.712375</td>\n","      <td>0.734365</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.070400</td>\n","      <td>0.236205</td>\n","      <td>0.700000</td>\n","      <td>0.779053</td>\n","      <td>0.719064</td>\n","      <td>0.738209</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.057300</td>\n","      <td>0.235267</td>\n","      <td>0.696154</td>\n","      <td>0.787815</td>\n","      <td>0.719064</td>\n","      <td>0.738004</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.073400</td>\n","      <td>0.236515</td>\n","      <td>0.696154</td>\n","      <td>0.791640</td>\n","      <td>0.719064</td>\n","      <td>0.739787</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.063300</td>\n","      <td>0.236159</td>\n","      <td>0.696154</td>\n","      <td>0.784050</td>\n","      <td>0.719064</td>\n","      <td>0.735617</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.074500</td>\n","      <td>0.232822</td>\n","      <td>0.700000</td>\n","      <td>0.778393</td>\n","      <td>0.722408</td>\n","      <td>0.739784</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.062500</td>\n","      <td>0.235676</td>\n","      <td>0.696154</td>\n","      <td>0.796460</td>\n","      <td>0.715719</td>\n","      <td>0.738067</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.061000</td>\n","      <td>0.233619</td>\n","      <td>0.696154</td>\n","      <td>0.788579</td>\n","      <td>0.715719</td>\n","      <td>0.736162</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.067700</td>\n","      <td>0.231655</td>\n","      <td>0.703846</td>\n","      <td>0.780392</td>\n","      <td>0.722408</td>\n","      <td>0.741046</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.062000</td>\n","      <td>0.234669</td>\n","      <td>0.696154</td>\n","      <td>0.788579</td>\n","      <td>0.715719</td>\n","      <td>0.736162</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.062900</td>\n","      <td>0.231899</td>\n","      <td>0.700000</td>\n","      <td>0.790718</td>\n","      <td>0.715719</td>\n","      <td>0.738364</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.059800</td>\n","      <td>0.234058</td>\n","      <td>0.688462</td>\n","      <td>0.773193</td>\n","      <td>0.712375</td>\n","      <td>0.731674</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.059900</td>\n","      <td>0.234540</td>\n","      <td>0.688462</td>\n","      <td>0.770527</td>\n","      <td>0.709030</td>\n","      <td>0.727971</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.063800</td>\n","      <td>0.233809</td>\n","      <td>0.700000</td>\n","      <td>0.788490</td>\n","      <td>0.715719</td>\n","      <td>0.737102</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.060800</td>\n","      <td>0.234027</td>\n","      <td>0.688462</td>\n","      <td>0.768731</td>\n","      <td>0.712375</td>\n","      <td>0.729600</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.064900</td>\n","      <td>0.234430</td>\n","      <td>0.688462</td>\n","      <td>0.769980</td>\n","      <td>0.709030</td>\n","      <td>0.727491</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.070300</td>\n","      <td>0.234448</td>\n","      <td>0.692308</td>\n","      <td>0.774929</td>\n","      <td>0.712375</td>\n","      <td>0.731522</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.059600</td>\n","      <td>0.234737</td>\n","      <td>0.692308</td>\n","      <td>0.771920</td>\n","      <td>0.712375</td>\n","      <td>0.730243</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.066800</td>\n","      <td>0.234755</td>\n","      <td>0.692308</td>\n","      <td>0.771920</td>\n","      <td>0.712375</td>\n","      <td>0.730243</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [9/9 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-01 18:19:11,793] Trial 8 finished with value: 0.7302433043939522 and parameters: {'learning_rate': 2.9612332441506537e-06, 'batch_size': 16, 'num_train_epochs': 19, 'weight_decay': 0.0009098758721914081}. Best is trial 7 with value: 0.7312187307131695.\n","<ipython-input-10-747f1883d862>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-747f1883d862>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1038\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 910\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='910' max='910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [910/910 00:47, Epoch 7/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.065900</td>\n","      <td>0.232290</td>\n","      <td>0.696154</td>\n","      <td>0.798338</td>\n","      <td>0.712375</td>\n","      <td>0.739349</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.075800</td>\n","      <td>0.240316</td>\n","      <td>0.688462</td>\n","      <td>0.782574</td>\n","      <td>0.715719</td>\n","      <td>0.736635</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.054200</td>\n","      <td>0.239797</td>\n","      <td>0.684615</td>\n","      <td>0.775013</td>\n","      <td>0.715719</td>\n","      <td>0.732980</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.064600</td>\n","      <td>0.237697</td>\n","      <td>0.692308</td>\n","      <td>0.774565</td>\n","      <td>0.712375</td>\n","      <td>0.730919</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.065900</td>\n","      <td>0.239654</td>\n","      <td>0.688462</td>\n","      <td>0.770937</td>\n","      <td>0.719064</td>\n","      <td>0.734318</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.052600</td>\n","      <td>0.240581</td>\n","      <td>0.696154</td>\n","      <td>0.781270</td>\n","      <td>0.712375</td>\n","      <td>0.735352</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.070100</td>\n","      <td>0.239361</td>\n","      <td>0.696154</td>\n","      <td>0.780755</td>\n","      <td>0.709030</td>\n","      <td>0.733329</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [33/33 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-01 18:19:59,831] Trial 9 finished with value: 0.7333287137943633 and parameters: {'learning_rate': 4.106135285926957e-06, 'batch_size': 4, 'num_train_epochs': 7, 'weight_decay': 0.0007582135408121953}. Best is trial 9 with value: 0.7333287137943633.\n","<ipython-input-10-747f1883d862>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-747f1883d862>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1038\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 390\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='390' max='390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [390/390 00:20, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.068500</td>\n","      <td>0.252453</td>\n","      <td>0.676923</td>\n","      <td>0.754068</td>\n","      <td>0.715719</td>\n","      <td>0.724345</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.069600</td>\n","      <td>0.255715</td>\n","      <td>0.684615</td>\n","      <td>0.776388</td>\n","      <td>0.712375</td>\n","      <td>0.730391</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.040900</td>\n","      <td>0.261313</td>\n","      <td>0.680769</td>\n","      <td>0.762682</td>\n","      <td>0.712375</td>\n","      <td>0.726609</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [33/33 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-01 18:20:20,591] Trial 10 finished with value: 0.7266092547930287 and parameters: {'learning_rate': 4.126294439876252e-05, 'batch_size': 4, 'num_train_epochs': 3, 'weight_decay': 0.006727952141042996}. Best is trial 9 with value: 0.7333287137943633.\n","<ipython-input-10-747f1883d862>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-747f1883d862>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1038\n","  Num Epochs = 13\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 1690\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1690' max='1690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1690/1690 01:28, Epoch 13/13]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.085300</td>\n","      <td>0.315676</td>\n","      <td>0.626923</td>\n","      <td>0.730668</td>\n","      <td>0.655518</td>\n","      <td>0.646941</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.075800</td>\n","      <td>0.292889</td>\n","      <td>0.665385</td>\n","      <td>0.755714</td>\n","      <td>0.715719</td>\n","      <td>0.711166</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.076700</td>\n","      <td>0.302749</td>\n","      <td>0.665385</td>\n","      <td>0.751308</td>\n","      <td>0.705686</td>\n","      <td>0.714791</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.043600</td>\n","      <td>0.292997</td>\n","      <td>0.680769</td>\n","      <td>0.791917</td>\n","      <td>0.698997</td>\n","      <td>0.718914</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.049700</td>\n","      <td>0.326485</td>\n","      <td>0.650000</td>\n","      <td>0.764605</td>\n","      <td>0.675585</td>\n","      <td>0.702943</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.032600</td>\n","      <td>0.297735</td>\n","      <td>0.673077</td>\n","      <td>0.776614</td>\n","      <td>0.702341</td>\n","      <td>0.723063</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.038600</td>\n","      <td>0.318017</td>\n","      <td>0.680769</td>\n","      <td>0.758110</td>\n","      <td>0.698997</td>\n","      <td>0.715085</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.031100</td>\n","      <td>0.307437</td>\n","      <td>0.676923</td>\n","      <td>0.778282</td>\n","      <td>0.698997</td>\n","      <td>0.719030</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.019500</td>\n","      <td>0.312086</td>\n","      <td>0.688462</td>\n","      <td>0.763859</td>\n","      <td>0.712375</td>\n","      <td>0.726303</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.034000</td>\n","      <td>0.310339</td>\n","      <td>0.680769</td>\n","      <td>0.769059</td>\n","      <td>0.702341</td>\n","      <td>0.725498</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.011900</td>\n","      <td>0.292440</td>\n","      <td>0.707692</td>\n","      <td>0.792784</td>\n","      <td>0.715719</td>\n","      <td>0.744700</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.023900</td>\n","      <td>0.291536</td>\n","      <td>0.711538</td>\n","      <td>0.794360</td>\n","      <td>0.722408</td>\n","      <td>0.745526</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.031700</td>\n","      <td>0.294174</td>\n","      <td>0.707692</td>\n","      <td>0.781076</td>\n","      <td>0.719064</td>\n","      <td>0.741740</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1500\n","Configuration saved in ./results/checkpoint-1500/config.json\n","Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [33/33 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-01 18:21:50,112] Trial 11 finished with value: 0.7417402783928485 and parameters: {'learning_rate': 4.410661986666978e-05, 'batch_size': 4, 'num_train_epochs': 13, 'weight_decay': 0.05279174147151775}. Best is trial 11 with value: 0.7417402783928485.\n","<ipython-input-10-747f1883d862>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-747f1883d862>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1038\n","  Num Epochs = 13\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 1690\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1690' max='1690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1690/1690 01:28, Epoch 13/13]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.022500</td>\n","      <td>0.289331</td>\n","      <td>0.711538</td>\n","      <td>0.794110</td>\n","      <td>0.725753</td>\n","      <td>0.754217</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.019300</td>\n","      <td>0.291571</td>\n","      <td>0.707692</td>\n","      <td>0.776465</td>\n","      <td>0.725753</td>\n","      <td>0.746787</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.019900</td>\n","      <td>0.306890</td>\n","      <td>0.688462</td>\n","      <td>0.778399</td>\n","      <td>0.685619</td>\n","      <td>0.718362</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.044200</td>\n","      <td>0.296930</td>\n","      <td>0.723077</td>\n","      <td>0.807725</td>\n","      <td>0.725753</td>\n","      <td>0.756951</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.021800</td>\n","      <td>0.313875</td>\n","      <td>0.688462</td>\n","      <td>0.776646</td>\n","      <td>0.709030</td>\n","      <td>0.732756</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.015600</td>\n","      <td>0.305465</td>\n","      <td>0.707692</td>\n","      <td>0.786348</td>\n","      <td>0.715719</td>\n","      <td>0.742678</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.021700</td>\n","      <td>0.302534</td>\n","      <td>0.711538</td>\n","      <td>0.797723</td>\n","      <td>0.712375</td>\n","      <td>0.741829</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.021200</td>\n","      <td>0.304918</td>\n","      <td>0.711538</td>\n","      <td>0.789086</td>\n","      <td>0.722408</td>\n","      <td>0.748403</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.013600</td>\n","      <td>0.308478</td>\n","      <td>0.703846</td>\n","      <td>0.788308</td>\n","      <td>0.719064</td>\n","      <td>0.745112</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.026000</td>\n","      <td>0.302858</td>\n","      <td>0.707692</td>\n","      <td>0.788957</td>\n","      <td>0.715719</td>\n","      <td>0.744660</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.010400</td>\n","      <td>0.305774</td>\n","      <td>0.707692</td>\n","      <td>0.789223</td>\n","      <td>0.715719</td>\n","      <td>0.743792</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.020100</td>\n","      <td>0.308533</td>\n","      <td>0.707692</td>\n","      <td>0.790245</td>\n","      <td>0.715719</td>\n","      <td>0.744225</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.021900</td>\n","      <td>0.307700</td>\n","      <td>0.707692</td>\n","      <td>0.792145</td>\n","      <td>0.715719</td>\n","      <td>0.745284</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1500\n","Configuration saved in ./results/checkpoint-1500/config.json\n","Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [33/33 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-01 18:23:19,188] Trial 12 finished with value: 0.7452841564594869 and parameters: {'learning_rate': 4.663859628265855e-06, 'batch_size': 4, 'num_train_epochs': 13, 'weight_decay': 0.057818478644798214}. Best is trial 12 with value: 0.7452841564594869.\n","<ipython-input-10-747f1883d862>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-747f1883d862>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1038\n","  Num Epochs = 14\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 1820\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1820' max='1820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1820/1820 01:34, Epoch 14/14]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.028500</td>\n","      <td>0.333897</td>\n","      <td>0.680769</td>\n","      <td>0.788056</td>\n","      <td>0.712375</td>\n","      <td>0.734223</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.033900</td>\n","      <td>0.348426</td>\n","      <td>0.673077</td>\n","      <td>0.751590</td>\n","      <td>0.735786</td>\n","      <td>0.735597</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.019400</td>\n","      <td>0.357452</td>\n","      <td>0.680769</td>\n","      <td>0.756923</td>\n","      <td>0.719064</td>\n","      <td>0.730798</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.044500</td>\n","      <td>0.411227</td>\n","      <td>0.680769</td>\n","      <td>0.732282</td>\n","      <td>0.705686</td>\n","      <td>0.694780</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.017400</td>\n","      <td>0.344509</td>\n","      <td>0.700000</td>\n","      <td>0.795578</td>\n","      <td>0.715719</td>\n","      <td>0.746000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.008400</td>\n","      <td>0.330987</td>\n","      <td>0.696154</td>\n","      <td>0.792902</td>\n","      <td>0.712375</td>\n","      <td>0.742423</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.017000</td>\n","      <td>0.366419</td>\n","      <td>0.680769</td>\n","      <td>0.774147</td>\n","      <td>0.719064</td>\n","      <td>0.735165</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.016300</td>\n","      <td>0.328691</td>\n","      <td>0.707692</td>\n","      <td>0.793388</td>\n","      <td>0.742475</td>\n","      <td>0.761206</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.006000</td>\n","      <td>0.364514</td>\n","      <td>0.673077</td>\n","      <td>0.768692</td>\n","      <td>0.722408</td>\n","      <td>0.740197</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.015200</td>\n","      <td>0.354297</td>\n","      <td>0.696154</td>\n","      <td>0.794290</td>\n","      <td>0.729097</td>\n","      <td>0.754058</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.006100</td>\n","      <td>0.341716</td>\n","      <td>0.700000</td>\n","      <td>0.787663</td>\n","      <td>0.729097</td>\n","      <td>0.753168</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.011700</td>\n","      <td>0.352670</td>\n","      <td>0.703846</td>\n","      <td>0.798495</td>\n","      <td>0.725753</td>\n","      <td>0.754348</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.010500</td>\n","      <td>0.359746</td>\n","      <td>0.707692</td>\n","      <td>0.803891</td>\n","      <td>0.722408</td>\n","      <td>0.754107</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.007400</td>\n","      <td>0.357035</td>\n","      <td>0.700000</td>\n","      <td>0.799575</td>\n","      <td>0.725753</td>\n","      <td>0.754614</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1500\n","Configuration saved in ./results/checkpoint-1500/config.json\n","Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [33/33 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-01 18:24:54,711] Trial 13 finished with value: 0.7546142516568112 and parameters: {'learning_rate': 4.208119489397181e-05, 'batch_size': 4, 'num_train_epochs': 14, 'weight_decay': 0.09764711576010418}. Best is trial 13 with value: 0.7546142516568112.\n","<ipython-input-10-747f1883d862>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-747f1883d862>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1038\n","  Num Epochs = 14\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 1820\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1820' max='1820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1820/1820 01:35, Epoch 14/14]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.008500</td>\n","      <td>0.354051</td>\n","      <td>0.700000</td>\n","      <td>0.800790</td>\n","      <td>0.725753</td>\n","      <td>0.755877</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.006800</td>\n","      <td>0.358874</td>\n","      <td>0.692308</td>\n","      <td>0.774437</td>\n","      <td>0.732441</td>\n","      <td>0.748950</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.010500</td>\n","      <td>0.377844</td>\n","      <td>0.676923</td>\n","      <td>0.766787</td>\n","      <td>0.702341</td>\n","      <td>0.723547</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.010500</td>\n","      <td>0.352673</td>\n","      <td>0.696154</td>\n","      <td>0.788716</td>\n","      <td>0.729097</td>\n","      <td>0.753949</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.007200</td>\n","      <td>0.354063</td>\n","      <td>0.700000</td>\n","      <td>0.782301</td>\n","      <td>0.725753</td>\n","      <td>0.746872</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.004000</td>\n","      <td>0.354502</td>\n","      <td>0.692308</td>\n","      <td>0.773174</td>\n","      <td>0.722408</td>\n","      <td>0.743098</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.006800</td>\n","      <td>0.357722</td>\n","      <td>0.696154</td>\n","      <td>0.787630</td>\n","      <td>0.722408</td>\n","      <td>0.748645</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.007400</td>\n","      <td>0.357887</td>\n","      <td>0.696154</td>\n","      <td>0.777091</td>\n","      <td>0.719064</td>\n","      <td>0.743456</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.003800</td>\n","      <td>0.355265</td>\n","      <td>0.696154</td>\n","      <td>0.787136</td>\n","      <td>0.719064</td>\n","      <td>0.747028</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.009100</td>\n","      <td>0.357488</td>\n","      <td>0.696154</td>\n","      <td>0.781744</td>\n","      <td>0.722408</td>\n","      <td>0.747349</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.005300</td>\n","      <td>0.360529</td>\n","      <td>0.703846</td>\n","      <td>0.800347</td>\n","      <td>0.719064</td>\n","      <td>0.751973</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.006700</td>\n","      <td>0.366276</td>\n","      <td>0.688462</td>\n","      <td>0.781036</td>\n","      <td>0.712375</td>\n","      <td>0.738585</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.007600</td>\n","      <td>0.364454</td>\n","      <td>0.696154</td>\n","      <td>0.791161</td>\n","      <td>0.719064</td>\n","      <td>0.747204</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.006100</td>\n","      <td>0.362146</td>\n","      <td>0.696154</td>\n","      <td>0.791161</td>\n","      <td>0.719064</td>\n","      <td>0.747204</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1500\n","Configuration saved in ./results/checkpoint-1500/config.json\n","Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [33/33 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-01 18:26:30,927] Trial 14 finished with value: 0.7472041122639957 and parameters: {'learning_rate': 6.6331997967836e-06, 'batch_size': 4, 'num_train_epochs': 14, 'weight_decay': 0.08594636453190758}. Best is trial 13 with value: 0.7546142516568112.\n","<ipython-input-10-747f1883d862>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-747f1883d862>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1038\n","  Num Epochs = 15\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 1950\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1950' max='1950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1950/1950 01:42, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.006600</td>\n","      <td>0.363686</td>\n","      <td>0.703846</td>\n","      <td>0.798036</td>\n","      <td>0.729097</td>\n","      <td>0.755803</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.005000</td>\n","      <td>0.353533</td>\n","      <td>0.692308</td>\n","      <td>0.769078</td>\n","      <td>0.729097</td>\n","      <td>0.746142</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.013600</td>\n","      <td>0.393073</td>\n","      <td>0.669231</td>\n","      <td>0.765552</td>\n","      <td>0.698997</td>\n","      <td>0.721735</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.008100</td>\n","      <td>0.358238</td>\n","      <td>0.700000</td>\n","      <td>0.784006</td>\n","      <td>0.722408</td>\n","      <td>0.748249</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.005400</td>\n","      <td>0.373972</td>\n","      <td>0.700000</td>\n","      <td>0.783332</td>\n","      <td>0.725753</td>\n","      <td>0.747467</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.002900</td>\n","      <td>0.363384</td>\n","      <td>0.703846</td>\n","      <td>0.782615</td>\n","      <td>0.719064</td>\n","      <td>0.745013</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.004900</td>\n","      <td>0.368775</td>\n","      <td>0.696154</td>\n","      <td>0.786053</td>\n","      <td>0.725753</td>\n","      <td>0.749867</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.005200</td>\n","      <td>0.371985</td>\n","      <td>0.692308</td>\n","      <td>0.771219</td>\n","      <td>0.722408</td>\n","      <td>0.742406</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.002900</td>\n","      <td>0.365676</td>\n","      <td>0.707692</td>\n","      <td>0.793464</td>\n","      <td>0.722408</td>\n","      <td>0.750640</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.006400</td>\n","      <td>0.365750</td>\n","      <td>0.703846</td>\n","      <td>0.783644</td>\n","      <td>0.722408</td>\n","      <td>0.747847</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.004000</td>\n","      <td>0.367076</td>\n","      <td>0.703846</td>\n","      <td>0.803551</td>\n","      <td>0.719064</td>\n","      <td>0.751961</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.004500</td>\n","      <td>0.378471</td>\n","      <td>0.688462</td>\n","      <td>0.773485</td>\n","      <td>0.712375</td>\n","      <td>0.736393</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.005600</td>\n","      <td>0.373853</td>\n","      <td>0.692308</td>\n","      <td>0.782518</td>\n","      <td>0.722408</td>\n","      <td>0.746549</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.004400</td>\n","      <td>0.370437</td>\n","      <td>0.703846</td>\n","      <td>0.785603</td>\n","      <td>0.722408</td>\n","      <td>0.748452</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.004100</td>\n","      <td>0.373620</td>\n","      <td>0.703846</td>\n","      <td>0.783598</td>\n","      <td>0.722408</td>\n","      <td>0.747059</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1500\n","Configuration saved in ./results/checkpoint-1500/config.json\n","Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [33/33 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-01 18:28:14,041] Trial 15 finished with value: 0.747059143826805 and parameters: {'learning_rate': 8.035791799217374e-06, 'batch_size': 4, 'num_train_epochs': 15, 'weight_decay': 0.017853823559927463}. Best is trial 13 with value: 0.7546142516568112.\n","<ipython-input-10-747f1883d862>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-747f1883d862>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1038\n","  Num Epochs = 16\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 2080\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2080' max='2080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2080/2080 01:49, Epoch 16/16]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.004400</td>\n","      <td>0.382530</td>\n","      <td>0.676923</td>\n","      <td>0.778896</td>\n","      <td>0.719064</td>\n","      <td>0.742624</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.004300</td>\n","      <td>0.397526</td>\n","      <td>0.696154</td>\n","      <td>0.771353</td>\n","      <td>0.729097</td>\n","      <td>0.743838</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.006800</td>\n","      <td>0.379549</td>\n","      <td>0.692308</td>\n","      <td>0.782763</td>\n","      <td>0.729097</td>\n","      <td>0.751096</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.004800</td>\n","      <td>0.383121</td>\n","      <td>0.684615</td>\n","      <td>0.774262</td>\n","      <td>0.712375</td>\n","      <td>0.738566</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.003700</td>\n","      <td>0.380223</td>\n","      <td>0.692308</td>\n","      <td>0.781513</td>\n","      <td>0.729097</td>\n","      <td>0.751056</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.002300</td>\n","      <td>0.385712</td>\n","      <td>0.676923</td>\n","      <td>0.765288</td>\n","      <td>0.725753</td>\n","      <td>0.741976</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.003400</td>\n","      <td>0.370856</td>\n","      <td>0.692308</td>\n","      <td>0.784351</td>\n","      <td>0.725753</td>\n","      <td>0.750856</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.003500</td>\n","      <td>0.380614</td>\n","      <td>0.692308</td>\n","      <td>0.774323</td>\n","      <td>0.729097</td>\n","      <td>0.746638</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.003200</td>\n","      <td>0.398200</td>\n","      <td>0.684615</td>\n","      <td>0.779584</td>\n","      <td>0.712375</td>\n","      <td>0.735667</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.003700</td>\n","      <td>0.393456</td>\n","      <td>0.700000</td>\n","      <td>0.783800</td>\n","      <td>0.725753</td>\n","      <td>0.749274</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.002300</td>\n","      <td>0.388196</td>\n","      <td>0.707692</td>\n","      <td>0.799093</td>\n","      <td>0.725753</td>\n","      <td>0.754188</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.002900</td>\n","      <td>0.400975</td>\n","      <td>0.688462</td>\n","      <td>0.775893</td>\n","      <td>0.715719</td>\n","      <td>0.739085</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.003300</td>\n","      <td>0.393935</td>\n","      <td>0.692308</td>\n","      <td>0.788931</td>\n","      <td>0.722408</td>\n","      <td>0.748913</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.002700</td>\n","      <td>0.394766</td>\n","      <td>0.703846</td>\n","      <td>0.778425</td>\n","      <td>0.729097</td>\n","      <td>0.749041</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.002500</td>\n","      <td>0.401044</td>\n","      <td>0.703846</td>\n","      <td>0.784591</td>\n","      <td>0.725753</td>\n","      <td>0.749272</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.003100</td>\n","      <td>0.401731</td>\n","      <td>0.707692</td>\n","      <td>0.786778</td>\n","      <td>0.725753</td>\n","      <td>0.750515</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1500\n","Configuration saved in ./results/checkpoint-1500/config.json\n","Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-2000\n","Configuration saved in ./results/checkpoint-2000/config.json\n","Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [33/33 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-01 18:30:03,724] Trial 16 finished with value: 0.7505151618377716 and parameters: {'learning_rate': 1.2324092436246345e-05, 'batch_size': 4, 'num_train_epochs': 16, 'weight_decay': 0.08382090089863044}. Best is trial 13 with value: 0.7546142516568112.\n","<ipython-input-10-747f1883d862>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-747f1883d862>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1038\n","  Num Epochs = 16\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 2080\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2080' max='2080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2080/2080 01:50, Epoch 16/16]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.006900</td>\n","      <td>0.504214</td>\n","      <td>0.638462</td>\n","      <td>0.766995</td>\n","      <td>0.682274</td>\n","      <td>0.701509</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.004600</td>\n","      <td>0.427818</td>\n","      <td>0.696154</td>\n","      <td>0.773283</td>\n","      <td>0.739130</td>\n","      <td>0.747411</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.003700</td>\n","      <td>0.446322</td>\n","      <td>0.700000</td>\n","      <td>0.777136</td>\n","      <td>0.729097</td>\n","      <td>0.742405</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.002500</td>\n","      <td>0.450011</td>\n","      <td>0.680769</td>\n","      <td>0.765039</td>\n","      <td>0.732441</td>\n","      <td>0.742946</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.004100</td>\n","      <td>0.418664</td>\n","      <td>0.688462</td>\n","      <td>0.784409</td>\n","      <td>0.742475</td>\n","      <td>0.757803</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.001600</td>\n","      <td>0.431893</td>\n","      <td>0.673077</td>\n","      <td>0.780779</td>\n","      <td>0.735786</td>\n","      <td>0.751911</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.001900</td>\n","      <td>0.395486</td>\n","      <td>0.711538</td>\n","      <td>0.800078</td>\n","      <td>0.745819</td>\n","      <td>0.766738</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.001700</td>\n","      <td>0.446924</td>\n","      <td>0.684615</td>\n","      <td>0.772903</td>\n","      <td>0.739130</td>\n","      <td>0.748278</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.003200</td>\n","      <td>0.414467</td>\n","      <td>0.700000</td>\n","      <td>0.778267</td>\n","      <td>0.742475</td>\n","      <td>0.758232</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.001700</td>\n","      <td>0.423968</td>\n","      <td>0.688462</td>\n","      <td>0.784130</td>\n","      <td>0.725753</td>\n","      <td>0.750480</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.001100</td>\n","      <td>0.422798</td>\n","      <td>0.692308</td>\n","      <td>0.796401</td>\n","      <td>0.732441</td>\n","      <td>0.759184</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.001500</td>\n","      <td>0.422919</td>\n","      <td>0.692308</td>\n","      <td>0.790459</td>\n","      <td>0.725753</td>\n","      <td>0.750981</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.001500</td>\n","      <td>0.436898</td>\n","      <td>0.688462</td>\n","      <td>0.777578</td>\n","      <td>0.725753</td>\n","      <td>0.745441</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.001300</td>\n","      <td>0.429777</td>\n","      <td>0.700000</td>\n","      <td>0.789407</td>\n","      <td>0.732441</td>\n","      <td>0.757278</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.001200</td>\n","      <td>0.433736</td>\n","      <td>0.692308</td>\n","      <td>0.789478</td>\n","      <td>0.732441</td>\n","      <td>0.755687</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.001500</td>\n","      <td>0.428579</td>\n","      <td>0.688462</td>\n","      <td>0.778551</td>\n","      <td>0.732441</td>\n","      <td>0.751474</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1500\n","Configuration saved in ./results/checkpoint-1500/config.json\n","Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-2000\n","Configuration saved in ./results/checkpoint-2000/config.json\n","Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [33/33 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-01 18:31:54,492] Trial 17 finished with value: 0.7514737788076215 and parameters: {'learning_rate': 2.9631902701567638e-05, 'batch_size': 4, 'num_train_epochs': 16, 'weight_decay': 0.021350321484431434}. Best is trial 13 with value: 0.7546142516568112.\n","<ipython-input-10-747f1883d862>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-747f1883d862>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1038\n","  Num Epochs = 11\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 1430\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1430' max='1430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1430/1430 01:15, Epoch 11/11]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.001900</td>\n","      <td>0.535662</td>\n","      <td>0.607692</td>\n","      <td>0.729974</td>\n","      <td>0.745819</td>\n","      <td>0.726834</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.002900</td>\n","      <td>0.437564</td>\n","      <td>0.711538</td>\n","      <td>0.776761</td>\n","      <td>0.749164</td>\n","      <td>0.760243</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.003600</td>\n","      <td>0.442933</td>\n","      <td>0.676923</td>\n","      <td>0.769555</td>\n","      <td>0.732441</td>\n","      <td>0.747104</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.001400</td>\n","      <td>0.471719</td>\n","      <td>0.680769</td>\n","      <td>0.761270</td>\n","      <td>0.722408</td>\n","      <td>0.738335</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.001200</td>\n","      <td>0.476395</td>\n","      <td>0.669231</td>\n","      <td>0.772270</td>\n","      <td>0.719064</td>\n","      <td>0.738152</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.000700</td>\n","      <td>0.451675</td>\n","      <td>0.680769</td>\n","      <td>0.766126</td>\n","      <td>0.739130</td>\n","      <td>0.750514</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.001000</td>\n","      <td>0.452821</td>\n","      <td>0.692308</td>\n","      <td>0.775403</td>\n","      <td>0.739130</td>\n","      <td>0.754536</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.001000</td>\n","      <td>0.446695</td>\n","      <td>0.703846</td>\n","      <td>0.774782</td>\n","      <td>0.745819</td>\n","      <td>0.756997</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.000700</td>\n","      <td>0.458437</td>\n","      <td>0.703846</td>\n","      <td>0.786505</td>\n","      <td>0.742475</td>\n","      <td>0.760268</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.001000</td>\n","      <td>0.460937</td>\n","      <td>0.696154</td>\n","      <td>0.780633</td>\n","      <td>0.739130</td>\n","      <td>0.756153</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.000500</td>\n","      <td>0.459394</td>\n","      <td>0.703846</td>\n","      <td>0.784936</td>\n","      <td>0.742475</td>\n","      <td>0.760240</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [33/33 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-01 18:33:10,273] Trial 18 finished with value: 0.7602403360567198 and parameters: {'learning_rate': 2.888231039965605e-05, 'batch_size': 4, 'num_train_epochs': 11, 'weight_decay': 0.01929556880988707}. Best is trial 18 with value: 0.7602403360567198.\n","<ipython-input-10-747f1883d862>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-747f1883d862>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1038\n","  Num Epochs = 11\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 352\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='352' max='352' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [352/352 00:56, Epoch 10/11]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.001200</td>\n","      <td>0.452477</td>\n","      <td>0.692308</td>\n","      <td>0.783223</td>\n","      <td>0.745819</td>\n","      <td>0.761654</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.007200</td>\n","      <td>0.466141</td>\n","      <td>0.703846</td>\n","      <td>0.801766</td>\n","      <td>0.735786</td>\n","      <td>0.760865</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.008600</td>\n","      <td>0.493529</td>\n","      <td>0.684615</td>\n","      <td>0.771606</td>\n","      <td>0.729097</td>\n","      <td>0.739784</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.001800</td>\n","      <td>0.463223</td>\n","      <td>0.700000</td>\n","      <td>0.796979</td>\n","      <td>0.732441</td>\n","      <td>0.758748</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.000800</td>\n","      <td>0.458465</td>\n","      <td>0.707692</td>\n","      <td>0.777572</td>\n","      <td>0.752508</td>\n","      <td>0.763008</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.001000</td>\n","      <td>0.470276</td>\n","      <td>0.688462</td>\n","      <td>0.788491</td>\n","      <td>0.729097</td>\n","      <td>0.752029</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.000800</td>\n","      <td>0.458177</td>\n","      <td>0.696154</td>\n","      <td>0.782051</td>\n","      <td>0.735786</td>\n","      <td>0.754857</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.000800</td>\n","      <td>0.456390</td>\n","      <td>0.692308</td>\n","      <td>0.787725</td>\n","      <td>0.735786</td>\n","      <td>0.755761</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.000800</td>\n","      <td>0.475617</td>\n","      <td>0.665385</td>\n","      <td>0.773215</td>\n","      <td>0.715719</td>\n","      <td>0.736484</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.004400</td>\n","      <td>0.478987</td>\n","      <td>0.665385</td>\n","      <td>0.774356</td>\n","      <td>0.719064</td>\n","      <td>0.738476</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.001500</td>\n","      <td>0.468038</td>\n","      <td>0.673077</td>\n","      <td>0.781359</td>\n","      <td>0.732441</td>\n","      <td>0.749896</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [9/9 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-01 18:34:07,707] Trial 19 finished with value: 0.7498955172153927 and parameters: {'learning_rate': 3.0666349642617465e-05, 'batch_size': 16, 'num_train_epochs': 11, 'weight_decay': 0.009563083630882568}. Best is trial 18 with value: 0.7602403360567198.\n"]},{"output_type":"stream","name":"stdout","text":["Best trial:\n","FrozenTrial(number=18, state=TrialState.COMPLETE, values=[0.7602403360567198], datetime_start=datetime.datetime(2024, 12, 1, 18, 31, 54, 494059), datetime_complete=datetime.datetime(2024, 12, 1, 18, 33, 10, 272012), params={'learning_rate': 2.888231039965605e-05, 'batch_size': 4, 'num_train_epochs': 11, 'weight_decay': 0.01929556880988707}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=5e-05, log=True, low=1e-06, step=None), 'batch_size': CategoricalDistribution(choices=(4, 8, 16)), 'num_train_epochs': IntDistribution(high=20, log=False, low=3, step=1), 'weight_decay': FloatDistribution(high=0.1, log=True, low=0.0001, step=None)}, trial_id=18, value=None)\n"]}],"source":["study = optuna.create_study(direction=\"maximize\")\n","study.optimize(objective, n_trials=20)\n","\n","print(\"Best trial:\")\n","print(study.best_trial)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"YJceIAKW02z7","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"8e3218d6-0aeb-4557-fc9e-a9465bfc8272","executionInfo":{"status":"ok","timestamp":1733078122105,"user_tz":480,"elapsed":73854,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1038\n","  Num Epochs = 11\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 1430\n"]},{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1430' max='1430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1430/1430 01:13, Epoch 11/11]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.484730</td>\n","      <td>0.692308</td>\n","      <td>0.775827</td>\n","      <td>0.729097</td>\n","      <td>0.744146</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.519850</td>\n","      <td>0.688462</td>\n","      <td>0.779963</td>\n","      <td>0.725753</td>\n","      <td>0.745794</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.487079</td>\n","      <td>0.703846</td>\n","      <td>0.780691</td>\n","      <td>0.735786</td>\n","      <td>0.750682</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.002400</td>\n","      <td>0.522243</td>\n","      <td>0.680769</td>\n","      <td>0.773223</td>\n","      <td>0.712375</td>\n","      <td>0.729849</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.002400</td>\n","      <td>0.507484</td>\n","      <td>0.680769</td>\n","      <td>0.781162</td>\n","      <td>0.725753</td>\n","      <td>0.744547</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.002400</td>\n","      <td>0.491256</td>\n","      <td>0.696154</td>\n","      <td>0.791689</td>\n","      <td>0.725753</td>\n","      <td>0.750432</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.002400</td>\n","      <td>0.486379</td>\n","      <td>0.692308</td>\n","      <td>0.782738</td>\n","      <td>0.725753</td>\n","      <td>0.747722</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.000500</td>\n","      <td>0.491084</td>\n","      <td>0.696154</td>\n","      <td>0.789770</td>\n","      <td>0.729097</td>\n","      <td>0.753370</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.000500</td>\n","      <td>0.500096</td>\n","      <td>0.700000</td>\n","      <td>0.788901</td>\n","      <td>0.729097</td>\n","      <td>0.750961</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.000500</td>\n","      <td>0.505261</td>\n","      <td>0.696154</td>\n","      <td>0.791448</td>\n","      <td>0.729097</td>\n","      <td>0.751734</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.000500</td>\n","      <td>0.506745</td>\n","      <td>0.696154</td>\n","      <td>0.791448</td>\n","      <td>0.729097</td>\n","      <td>0.751734</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./best_results/checkpoint-500\n","Configuration saved in ./best_results/checkpoint-500/config.json\n","Model weights saved in ./best_results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","Saving model checkpoint to ./best_results/checkpoint-1000\n","Configuration saved in ./best_results/checkpoint-1000/config.json\n","Model weights saved in ./best_results/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training completed in 73.92 seconds.\n"]}],"source":["best_hyperparams = study.best_trial.params\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./best_results\",\n","    num_train_epochs=best_hyperparams[\"num_train_epochs\"],\n","    per_device_train_batch_size=best_hyperparams[\"batch_size\"],\n","    per_device_eval_batch_size=best_hyperparams[\"batch_size\"] * 2,\n","    learning_rate=best_hyperparams[\"learning_rate\"],\n","    weight_decay=best_hyperparams[\"weight_decay\"],\n","    warmup_steps=10,\n","    evaluation_strategy=\"epoch\",\n","    gradient_accumulation_steps=2,\n","    report_to=\"none\",\n",")\n","\n","trainer = OneHotTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# Measure training time\n","print(\"Starting training...\")\n","start_time = time.time()  # Start the timer\n","\n","trainer.train()\n","\n","end_time = time.time()  # End the timer\n","training_duration = end_time - start_time  # Calculate the duration\n","\n","# Print the training duration\n","print(f\"Training completed in {training_duration:.2f} seconds.\")"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"gmbA8nKW1IAq","colab":{"base_uri":"https://localhost:8080/","height":89},"outputId":"828546e0-c478-49d5-ec64-fa925af5fc96","executionInfo":{"status":"ok","timestamp":1733078122436,"user_tz":480,"elapsed":373,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 260\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [33/33 00:00]\n","    </div>\n","    "]},"metadata":{}}],"source":["eval_results = trainer.evaluate()"]},{"cell_type":"markdown","metadata":{"id":"nlNRlUlh-7y0"},"source":["### Model Saving"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"maZXl_QZ-Psa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bc0dd82a-1c20-4a7f-e77c-4bb7239b0516","executionInfo":{"status":"ok","timestamp":1733078123432,"user_tz":480,"elapsed":1002,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo\n","Configuration saved in ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo/config.json\n","Model weights saved in ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo/pytorch_model.bin\n","tokenizer config file saved in ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/tokenizer_config.json\n","Special tokens file saved in ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/special_tokens_map.json\n","loading configuration file ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo\",\n","  \"architectures\": [\n","    \"BertForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"cell\": {},\n","  \"classifier_dropout\": null,\n","  \"emb_size\": 312,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 312,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 1200,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 4,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"pre_trained\": \"\",\n","  \"structure\": [],\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo/pytorch_model.bin\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:1439: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(resolved_archive_file, map_location=\"cpu\")\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n","Didn't find file ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/added_tokens.json. We won't load it.\n","loading file ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/vocab.txt\n","loading file ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/tokenizer.json\n","loading file None\n","loading file ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/special_tokens_map.json\n","loading file ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/tokenizer_config.json\n"]}],"source":["!mkdir 'best_model_huawei-noah_TinyBERT_General_4L_312D_pharo'\n","!mkdir 'best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer'\n","\n","# Save model and tokenizer\n","trainer.save_model('./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo')\n","tokenizer.save_pretrained('./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer')\n","\n","# Load model and tokenizer\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","model = AutoModelForSequenceClassification.from_pretrained('./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo')\n","tokenizer = AutoTokenizer.from_pretrained('./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer')"]},{"cell_type":"markdown","metadata":{"id":"ejkhNznm77uR"},"source":["### Model Testing"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"EMvNuBr37lzY","executionInfo":{"status":"ok","timestamp":1733078123434,"user_tz":480,"elapsed":31,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[],"source":["X_test = list(test_df['combo'])\n","y_test = list(test_df['labels'])"]},{"cell_type":"code","execution_count":16,"metadata":{"collapsed":true,"id":"Tut5zEUc790m","colab":{"base_uri":"https://localhost:8080/"},"outputId":"19938f68-f90e-443f-fc17-7b56eae4a8b2","executionInfo":{"status":"ok","timestamp":1733078123435,"user_tz":480,"elapsed":31,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[array([0, 0, 1, 1, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 0, 1, 0, 0, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 0, 1, 0, 0, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 0, 1, 0, 0, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 0, 0, 0, 1, 0, 0])\n"," array([0, 0, 0, 0, 1, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 0, 1, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([1, 0, 0, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0, 0, 0]) array([1, 0, 0, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0, 0, 0]) array([0, 0, 0, 0, 1, 0, 0])\n"," array([1, 0, 0, 0, 0, 0, 0]) array([0, 0, 0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 0, 1, 0]) array([0, 0, 0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 0, 1, 0]) array([1, 0, 0, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 1, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 0, 1, 0, 0, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0, 0, 0]) array([1, 0, 0, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 1, 0, 0]) array([0, 0, 0, 1, 0, 0, 0])\n"," array([0, 0, 0, 0, 1, 0, 0]) array([0, 0, 0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1, 0, 0]) array([1, 0, 0, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0, 0, 0]) array([0, 0, 0, 0, 1, 0, 0])\n"," array([1, 0, 0, 0, 0, 0, 0]) array([1, 0, 0, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0, 0, 0]) array([1, 0, 0, 0, 0, 0, 0])\n"," array([0, 0, 1, 0, 0, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 1, 0, 0]) array([0, 0, 0, 0, 1, 0, 0])\n"," array([0, 0, 1, 0, 0, 0, 0]) array([0, 0, 0, 0, 1, 0, 0])\n"," array([0, 0, 0, 0, 0, 1, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0, 0, 0]) array([1, 0, 0, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0, 0, 0]) array([1, 0, 0, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0, 0, 0]) array([1, 0, 0, 0, 0, 0, 0])\n"," array([0, 0, 1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0, 0, 0]) array([1, 0, 0, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0, 0, 0]) array([1, 0, 0, 0, 0, 0, 0])\n"," array([0, 0, 1, 0, 0, 0, 0]) array([0, 0, 1, 0, 0, 0, 1])\n"," array([0, 0, 1, 0, 0, 0, 0]) array([0, 0, 0, 0, 1, 0, 0])\n"," array([0, 0, 0, 0, 1, 0, 0]) array([0, 0, 0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 0, 1, 0]) array([0, 0, 0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 1, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 0, 1, 0, 0, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 0, 1, 0]) array([0, 0, 0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 0, 1, 0]) array([0, 0, 0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 0, 1, 0]) array([0, 0, 0, 0, 0, 1, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([1, 0, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 0, 0, 0, 1, 0, 0])\n"," array([1, 0, 0, 1, 0, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 0, 0, 1]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 1, 0, 0]) array([0, 0, 0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 0, 1, 0]) array([0, 0, 0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 0, 1, 0]) array([0, 0, 0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 0, 1, 0]) array([0, 0, 0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 0, 1, 0]) array([0, 0, 0, 0, 1, 0, 0])\n"," array([0, 0, 0, 0, 1, 0, 0]) array([1, 0, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 0, 1, 0, 1, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 0, 0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 1, 0, 0]) array([0, 0, 0, 0, 1, 0, 0])\n"," array([0, 0, 1, 0, 0, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 1, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 0, 0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 0, 1, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 1, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0, 0, 0]) array([1, 0, 0, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 0, 1, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 0, 0, 1]) array([0, 0, 0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 1, 0, 0]) array([0, 0, 0, 0, 1, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 0, 0, 0, 0, 0, 1])\n"," array([0, 0, 1, 0, 0, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 0, 1, 0, 0, 0, 0]) array([0, 0, 0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1, 0, 0]) array([0, 0, 0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 0, 1, 0]) array([0, 0, 0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 0, 1, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 1, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 0, 1, 0, 0, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 0, 1, 0]) array([0, 0, 0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 0, 1, 0]) array([0, 0, 0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 0, 1, 0]) array([1, 0, 0, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0, 0, 0]) array([1, 0, 0, 0, 0, 0, 0])\n"," array([0, 0, 1, 0, 0, 0, 0]) array([0, 0, 0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 0, 0, 1]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 0, 0, 0, 1, 0, 0])\n"," array([1, 0, 1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0, 0, 0])\n"," array([0, 0, 1, 0, 0, 0, 0]) array([0, 0, 0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 0, 1, 0]) array([0, 0, 0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 0, 1, 0]) array([0, 0, 1, 0, 0, 0, 1])\n"," array([1, 0, 0, 0, 0, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0, 0, 0]) array([1, 0, 0, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0, 0, 0]) array([1, 0, 0, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 1, 0, 0]) array([0, 1, 0, 0, 0, 0, 0])\n"," array([0, 1, 0, 0, 0, 0, 0]) array([0, 1, 0, 0, 0, 1, 0])\n"," array([0, 1, 0, 0, 0, 1, 0]) array([0, 1, 0, 0, 0, 1, 0])\n"," array([0, 1, 0, 0, 0, 1, 0]) array([0, 0, 1, 0, 1, 0, 0])\n"," array([0, 0, 1, 0, 0, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([0, 0, 1, 0, 0, 0, 0]) array([0, 0, 1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0, 0, 0])]\n"]}],"source":["df_test = pd.DataFrame({\"combo\":X_test,\"labels\":y_test})\n","test_text = df_test.combo.values\n","test_label = df_test.labels.values\n","\n","print(test_label)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"v43dDI8E8AFv","colab":{"base_uri":"https://localhost:8080/","height":124},"outputId":"64bc5ced-47d7-43ac-832e-28b0d7a6d026","executionInfo":{"status":"ok","timestamp":1733078123844,"user_tz":480,"elapsed":436,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 289\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='70' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [33/33 00:01]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Evaluation Metrics: {'accuracy': 0.6505190311418685, 'precision': 0.69406080261562, 'recall': 0.6943521594684385, 'f1': 0.6882669637792822}\n","Inference Time: 0.69 seconds\n"]}],"source":["test_dataset = TextClassificationDataset(test_text, test_label, tokenizer)\n","\n","# Measure inference time\n","start_time = time.time()\n","\n","# Predict on the test dataset\n","predictions = trainer.predict(test_dataset)\n","\n","# Calculate elapsed time\n","end_time = time.time()\n","inference_time = end_time - start_time\n","\n","# Compute metrics using the `compute_metrics` function\n","metrics = compute_metrics(predictions)\n","\n","# Display metrics and inference time\n","print(\"Evaluation Metrics:\", metrics)\n","print(f\"Inference Time: {inference_time:.2f} seconds\")"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"hdd0lVlvALIk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9adb6f57-e2c6-4e49-e1ed-95b184c5208d","executionInfo":{"status":"ok","timestamp":1733078127051,"user_tz":480,"elapsed":3216,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: best_model_huawei-noah_TinyBERT_General_4L_312D_pharo/ (stored 0%)\n","  adding: best_model_huawei-noah_TinyBERT_General_4L_312D_pharo/pytorch_model.bin (deflated 7%)\n","  adding: best_model_huawei-noah_TinyBERT_General_4L_312D_pharo/training_args.bin (deflated 51%)\n","  adding: best_model_huawei-noah_TinyBERT_General_4L_312D_pharo/config.json (deflated 54%)\n","  adding: best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/ (stored 0%)\n","  adding: best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/tokenizer_config.json (deflated 41%)\n","  adding: best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/special_tokens_map.json (deflated 40%)\n","  adding: best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/tokenizer.json (deflated 71%)\n","  adding: best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/vocab.txt (deflated 53%)\n"]}],"source":["!zip -r best_model_huawei-noah_TinyBERT_General_4L_312D_pharo.zip './best_model_huawei-noah_TinyBERT_General_4L_312D_pharo'\n","!zip -r best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer.zip './best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer'"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"WI4xntMmASPi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e8ebfbff-da31-4ea8-b88e-5090b7a0b9c5","executionInfo":{"status":"ok","timestamp":1733078166549,"user_tz":480,"elapsed":39519,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Transferring the model to Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!cp best_model_huawei-noah_TinyBERT_General_4L_312D_pharo.zip \"/content/drive/MyDrive/FYP/Revised/Models/huawei-noah_TinyBERT_General_4L_312D_pharo/\"\n","!cp best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer.zip \"/content/drive/MyDrive/FYP/Revised/Models/huawei-noah_TinyBERT_General_4L_312D_pharo_Tokenizer/\""]},{"cell_type":"markdown","metadata":{"id":"Le2HUk3TBuT1"},"source":["### Load and Test Model"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"ei49o7unAVBx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"be94ac1f-d8de-4095-a306-d40a5876a15c","executionInfo":{"status":"ok","timestamp":1733078318816,"user_tz":480,"elapsed":4191,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"6Dskeu5MBz_j","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d93ce3a2-ee4d-4d10-847f-1a9e4406f82a","executionInfo":{"status":"ok","timestamp":1733078336130,"user_tz":480,"elapsed":17320,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/MyDrive/FYP/Revised/Models/huawei-noah_TinyBERT_General_4L_312D_pharo/best_model_huawei-noah_TinyBERT_General_4L_312D_pharo.zip\n","replace ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo/pytorch_model.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n","  inflating: ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo/pytorch_model.bin  \n","  inflating: ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo/training_args.bin  \n","  inflating: ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo/config.json  \n","Archive:  /content/drive/MyDrive/FYP/Revised/Models/huawei-noah_TinyBERT_General_4L_312D_pharo_Tokenizer/best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer.zip\n","replace ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/tokenizer_config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n","  inflating: ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/tokenizer_config.json  \n","  inflating: ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/special_tokens_map.json  \n","  inflating: ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/tokenizer.json  \n","  inflating: ./best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/vocab.txt  \n"]}],"source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","# Replace 'path/to/checkpoint-folder' with the actual path to your checkpoint folder.\n","model_folder = '/content/drive/MyDrive/FYP/Revised/Models/huawei-noah_TinyBERT_General_4L_312D_pharo/'\n","tokenizer_folder = '/content/drive/MyDrive/FYP/Revised/Models/huawei-noah_TinyBERT_General_4L_312D_pharo_Tokenizer/'\n","\n","!unzip '/content/drive/MyDrive/FYP/Revised/Models/huawei-noah_TinyBERT_General_4L_312D_pharo/best_model_huawei-noah_TinyBERT_General_4L_312D_pharo.zip' -d './'\n","!unzip '/content/drive/MyDrive/FYP/Revised/Models/huawei-noah_TinyBERT_General_4L_312D_pharo_Tokenizer/best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer.zip' -d './'"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"SzPbirKSCa8B","executionInfo":{"status":"ok","timestamp":1733078336131,"user_tz":480,"elapsed":28,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[],"source":["best_model_huawei_noah_TinyBERT_General_4L_312D_pharo = 'best_model_huawei-noah_TinyBERT_General_4L_312D_pharo'\n","best_model_huawei_noah_TinyBERT_General_4L_312D_pharo_tokenizer = 'best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer'"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"TVduIUYeCbc1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9319ddc6-fa80-4b98-c042-193596751b88","executionInfo":{"status":"ok","timestamp":1733078336131,"user_tz":480,"elapsed":27,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file best_model_huawei-noah_TinyBERT_General_4L_312D_pharo/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"best_model_huawei-noah_TinyBERT_General_4L_312D_pharo\",\n","  \"architectures\": [\n","    \"BertForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"cell\": {},\n","  \"classifier_dropout\": null,\n","  \"emb_size\": 312,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 312,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 1200,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 4,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"pre_trained\": \"\",\n","  \"structure\": [],\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file best_model_huawei-noah_TinyBERT_General_4L_312D_pharo/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","All the weights of BertForSequenceClassification were initialized from the model checkpoint at best_model_huawei-noah_TinyBERT_General_4L_312D_pharo.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n","Didn't find file best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/added_tokens.json. We won't load it.\n","loading file best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/vocab.txt\n","loading file best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/tokenizer.json\n","loading file None\n","loading file best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/special_tokens_map.json\n","loading file best_model_huawei-noah_TinyBERT_General_4L_312D_pharo_tokenizer/tokenizer_config.json\n"]}],"source":["# Load the model and tokenizer from the checkpoint\n","model = AutoModelForSequenceClassification.from_pretrained(best_model_huawei_noah_TinyBERT_General_4L_312D_pharo)\n","tokenizer = AutoTokenizer.from_pretrained(best_model_huawei_noah_TinyBERT_General_4L_312D_pharo_tokenizer)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"mraiRFgv8MG6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"359523a1-535e-47f3-c62e-e886a39deccd","executionInfo":{"status":"ok","timestamp":1733078336132,"user_tz":480,"elapsed":16,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["SequenceClassifierOutput(loss=None, logits=tensor([[-8.3854, -8.3199, -8.9910, -9.3650, -9.3535,  7.3401, -8.9232]],\n","       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"]},"metadata":{},"execution_count":30}],"source":["text = \"Logits from the model output.\"\n","encoded_input = tokenizer(text, return_tensors='pt')\n","output = model(**encoded_input)\n","output"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"WNGL38Kk9Vua","colab":{"base_uri":"https://localhost:8080/"},"outputId":"47b4cd95-33d9-4778-96f4-7685078fae84","executionInfo":{"status":"ok","timestamp":1733078336133,"user_tz":480,"elapsed":13,"user":{"displayName":"Wajid Ali","userId":"00222716800998021162"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class/es: 6\n"]}],"source":["logits = output.logits\n","\n","# Apply sigmoid to convert logits to probabilities\n","probabilities = torch.sigmoid(logits)\n","\n","# Define a threshold to determine if a class is positive\n","threshold = 0.5\n","predicted_indices = (probabilities > threshold).nonzero(as_tuple=True)[1]\n","\n","# Convert indices to a list for output\n","predicted_classes = (predicted_indices + 1).tolist()\n","\n","# Format the output to display classes\n","if len(predicted_classes) > 0:\n","    predicted_classes_str = \", \".join(map(str, predicted_classes))\n","    print(f\"Predicted class/es: {predicted_classes_str}\")\n","else:\n","    print(\"No positive classes predicted.\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b82b0e8a1eb0463198043cea88273161":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8013c29158ca4eaf95307a27e702b1fc","IPY_MODEL_9a29f095074040f08c712c13f61a7ede","IPY_MODEL_6747442b0ba1464ca0e6960b0e8adc04"],"layout":"IPY_MODEL_98e51bc301b249bbbadbde10b0dd81f4"}},"8013c29158ca4eaf95307a27e702b1fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7aad82966c774937b8b2870b171079a4","placeholder":"​","style":"IPY_MODEL_48bf4c9eb7fb4330a8be3f6e4f8d0aae","value":"Downloading: 100%"}},"9a29f095074040f08c712c13f61a7ede":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_976ff798dbf5498ebc8e0be6e9623893","max":409,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eef4781e64b24eba8149c9be5a5b463e","value":409}},"6747442b0ba1464ca0e6960b0e8adc04":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50a687f9bfb3480aa31442a242ef9b9b","placeholder":"​","style":"IPY_MODEL_60f4b959dd0d4196be48a91d7d155b03","value":" 409/409 [00:00&lt;00:00, 12.6kB/s]"}},"98e51bc301b249bbbadbde10b0dd81f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7aad82966c774937b8b2870b171079a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48bf4c9eb7fb4330a8be3f6e4f8d0aae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"976ff798dbf5498ebc8e0be6e9623893":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eef4781e64b24eba8149c9be5a5b463e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50a687f9bfb3480aa31442a242ef9b9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60f4b959dd0d4196be48a91d7d155b03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a92e56b34ba4e40a1bb9b393fb43bcc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3c271d0869a04cc98b435000914dda71","IPY_MODEL_420aadfa4d494c499d34dc7f7dbb77f5","IPY_MODEL_39c37137b837475bb53cd53e02ae583d"],"layout":"IPY_MODEL_4239d58e790e491da1b09611bd885116"}},"3c271d0869a04cc98b435000914dda71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4873b7238c44e2b9d7e18d279efbdd1","placeholder":"​","style":"IPY_MODEL_c81767e8afe64075af1c38f6e0ca74f4","value":"Downloading: 100%"}},"420aadfa4d494c499d34dc7f7dbb77f5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e60905acac704f0a8db6fc8914c68898","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c1e3d60bec147e5bdf3043517624354","value":231508}},"39c37137b837475bb53cd53e02ae583d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97788bc2891d490eb6ddcda626a71b58","placeholder":"​","style":"IPY_MODEL_f2a2cabfe49f44ca9cf68ba38d378010","value":" 226k/226k [00:00&lt;00:00, 2.32MB/s]"}},"4239d58e790e491da1b09611bd885116":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4873b7238c44e2b9d7e18d279efbdd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c81767e8afe64075af1c38f6e0ca74f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e60905acac704f0a8db6fc8914c68898":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c1e3d60bec147e5bdf3043517624354":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"97788bc2891d490eb6ddcda626a71b58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2a2cabfe49f44ca9cf68ba38d378010":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1ff95018bd34bec8b8132121200b51d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_861cbe93fc6f4a3390cf007a8f7d4544","IPY_MODEL_321d5d304073466296009736d31ff3c6","IPY_MODEL_7844851374b14f298aa5ac8563b33999"],"layout":"IPY_MODEL_88d01bfed2864b9c9d794b017e2a3f70"}},"861cbe93fc6f4a3390cf007a8f7d4544":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c255f02fa54f400ba7e0d099b45a301e","placeholder":"​","style":"IPY_MODEL_c93c5169701547d8911ecaae6f68e15f","value":"Downloading: 100%"}},"321d5d304073466296009736d31ff3c6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_948300ae1c684c84a0b4a1572b50ec87","max":62747391,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd3f439b83dd404390ddbe326fb915d8","value":62747391}},"7844851374b14f298aa5ac8563b33999":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7dd0660174e3435a959a1bbe1c29cb06","placeholder":"​","style":"IPY_MODEL_c3ddce7aeb674c46ad22b37abc2d2b08","value":" 59.8M/59.8M [00:01&lt;00:00, 43.2MB/s]"}},"88d01bfed2864b9c9d794b017e2a3f70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c255f02fa54f400ba7e0d099b45a301e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c93c5169701547d8911ecaae6f68e15f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"948300ae1c684c84a0b4a1572b50ec87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd3f439b83dd404390ddbe326fb915d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7dd0660174e3435a959a1bbe1c29cb06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3ddce7aeb674c46ad22b37abc2d2b08":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}