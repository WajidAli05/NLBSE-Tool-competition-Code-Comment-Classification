{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20666,"status":"ok","timestamp":1732994822851,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"},"user_tz":480},"id":"ahiO5v1-U-Bx","outputId":"ec2c1728-3961-4105-a9f5-fdea26980b1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.17\n","  Downloading transformers-4.17.0-py3-none-any.whl.metadata (67 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (0.26.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (2.32.3)\n","Collecting sacremoses (from transformers==4.17)\n","  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (0.20.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (4.66.6)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.17) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.17) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.17) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.17) (2024.8.30)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.17) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.17) (1.4.2)\n","Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sacremoses, transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.46.2\n","    Uninstalling transformers-4.46.2:\n","      Successfully uninstalled transformers-4.46.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sentence-transformers 3.2.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.17.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed sacremoses-0.1.1 transformers-4.17.0\n","Collecting optuna\n","  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n","Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.6 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"]}],"source":["!pip install transformers==4.17\n","!pip install optuna"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hJqdqTUdVLdQ"},"outputs":[],"source":["from transformers import Trainer, TrainingArguments, DistilBertTokenizer, DistilBertForSequenceClassification\n","import torch\n","import pandas as pd\n","import nltk\n","import re\n","import ast\n","import numpy as np\n","from torch.utils.data import Dataset\n","from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_fscore_support, accuracy_score\n","from sklearn.model_selection import train_test_split\n","import torch.nn as nn\n","import optuna\n","import time"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":563},"executionInfo":{"elapsed":4302,"status":"ok","timestamp":1732994842215,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"},"user_tz":480},"id":"A2X7abTWVVoT","outputId":"a076af93-23fe-4713-eb18-d22fd67e8ad4"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["   index        class                                   comment_sentence  \\\n","0      1  AccessMixin                                     functionality.   \n","1      8       Atomic  when it s used as a decorator, call wraps the ...   \n","2     10       Atomic  when it s used as a context manager, enter cre...   \n","3     12       Atomic  exit commits the transaction or releases the s...   \n","4     14       Atomic  it s possible to disable the creation of savep...   \n","\n","   partition                                              combo  \\\n","0          0                       functionality. | AccessMixin   \n","1          0  when it s used as a decorator, call wraps the ...   \n","2          0  when it s used as a context manager, enter cre...   \n","3          0  exit commits the transaction or releases the s...   \n","4          0  it s possible to disable the creation of savep...   \n","\n","            labels  \n","0  [0, 0, 0, 0, 1]  \n","1  [1, 0, 0, 0, 0]  \n","2  [1, 0, 0, 0, 0]  \n","3  [1, 0, 0, 0, 0]  \n","4  [1, 0, 0, 0, 0]  "],"text/html":["\n","  <div id=\"df-30a29cea-b458-4778-a74e-18a9dff9dbfe\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>class</th>\n","      <th>comment_sentence</th>\n","      <th>partition</th>\n","      <th>combo</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>AccessMixin</td>\n","      <td>functionality.</td>\n","      <td>0</td>\n","      <td>functionality. | AccessMixin</td>\n","      <td>[0, 0, 0, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8</td>\n","      <td>Atomic</td>\n","      <td>when it s used as a decorator, call wraps the ...</td>\n","      <td>0</td>\n","      <td>when it s used as a decorator, call wraps the ...</td>\n","      <td>[1, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10</td>\n","      <td>Atomic</td>\n","      <td>when it s used as a context manager, enter cre...</td>\n","      <td>0</td>\n","      <td>when it s used as a context manager, enter cre...</td>\n","      <td>[1, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>12</td>\n","      <td>Atomic</td>\n","      <td>exit commits the transaction or releases the s...</td>\n","      <td>0</td>\n","      <td>exit commits the transaction or releases the s...</td>\n","      <td>[1, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14</td>\n","      <td>Atomic</td>\n","      <td>it s possible to disable the creation of savep...</td>\n","      <td>0</td>\n","      <td>it s possible to disable the creation of savep...</td>\n","      <td>[1, 0, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30a29cea-b458-4778-a74e-18a9dff9dbfe')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-30a29cea-b458-4778-a74e-18a9dff9dbfe button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-30a29cea-b458-4778-a74e-18a9dff9dbfe');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-66578759-96e5-4902-982d-08aa75b60f48\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-66578759-96e5-4902-982d-08aa75b60f48')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-66578759-96e5-4902-982d-08aa75b60f48 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(test_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 1,\n        \"max\": 14,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          8,\n          14,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Atomic\",\n          \"AccessMixin\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comment_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"when it s used as a decorator, call wraps the execution of the\",\n          \"it s possible to disable the creation of savepoints if the goal is to\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"partition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"combo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"when it s used as a decorator, call wraps the execution of the | Atomic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["   index           class                                   comment_sentence  \\\n","0      0     AccessMixin  abstract cbv mixin that gives access mixins th...   \n","1      2  AmbiguityError     more than one migration matches a name prefix.   \n","2      3   AppConfigStub                              stub of an appconfig.   \n","3      4   AppConfigStub        only provides a label and a dict of models.   \n","4      5         Archive  the external api class that encapsulates an ar...   \n","\n","   partition                                              combo  \\\n","0          1  abstract cbv mixin that gives access mixins th...   \n","1          1  more than one migration matches a name prefix....   \n","2          1              stub of an appconfig. | AppConfigStub   \n","3          1  only provides a label and a dict of models. | ...   \n","4          1  the external api class that encapsulates an ar...   \n","\n","            labels  \n","0  [0, 0, 0, 0, 1]  \n","1  [0, 0, 0, 0, 1]  \n","2  [0, 0, 0, 0, 1]  \n","3  [0, 1, 0, 0, 0]  \n","4  [0, 0, 1, 0, 1]  "],"text/html":["\n","  <div id=\"df-e5aabff7-19f2-4086-8a8d-8b4e168ab45b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>class</th>\n","      <th>comment_sentence</th>\n","      <th>partition</th>\n","      <th>combo</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>AccessMixin</td>\n","      <td>abstract cbv mixin that gives access mixins th...</td>\n","      <td>1</td>\n","      <td>abstract cbv mixin that gives access mixins th...</td>\n","      <td>[0, 0, 0, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>AmbiguityError</td>\n","      <td>more than one migration matches a name prefix.</td>\n","      <td>1</td>\n","      <td>more than one migration matches a name prefix....</td>\n","      <td>[0, 0, 0, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>AppConfigStub</td>\n","      <td>stub of an appconfig.</td>\n","      <td>1</td>\n","      <td>stub of an appconfig. | AppConfigStub</td>\n","      <td>[0, 0, 0, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>AppConfigStub</td>\n","      <td>only provides a label and a dict of models.</td>\n","      <td>1</td>\n","      <td>only provides a label and a dict of models. | ...</td>\n","      <td>[0, 1, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Archive</td>\n","      <td>the external api class that encapsulates an ar...</td>\n","      <td>1</td>\n","      <td>the external api class that encapsulates an ar...</td>\n","      <td>[0, 0, 1, 0, 1]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5aabff7-19f2-4086-8a8d-8b4e168ab45b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e5aabff7-19f2-4086-8a8d-8b4e168ab45b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e5aabff7-19f2-4086-8a8d-8b4e168ab45b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-e88e843a-ebd0-4aab-a2b3-668d96e53b5d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e88e843a-ebd0-4aab-a2b3-668d96e53b5d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-e88e843a-ebd0-4aab-a2b3-668d96e53b5d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(test_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"AmbiguityError\",\n          \"Archive\",\n          \"AccessMixin\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comment_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"more than one migration matches a name prefix.\",\n          \"the external api class that encapsulates an archive implementation.\",\n          \"stub of an appconfig.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"partition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"combo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"more than one migration matches a name prefix. | AmbiguityError\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["(1884, 6)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["(406, 6)"]},"metadata":{}}],"source":["splits = {'python_train': 'data/python_train-00000-of-00001.parquet', 'python_test': 'data/python_test-00000-of-00001.parquet'}\n","train_df = pd.read_parquet(\"hf://datasets/NLBSE/nlbse25-code-comment-classification/\" + splits[\"python_train\"])\n","test_df = pd.read_parquet(\"hf://datasets/NLBSE/nlbse25-code-comment-classification/\" + splits[\"python_test\"])\n","\n","display(train_df.head())\n","display(test_df.head())\n","display(train_df.shape)\n","display(test_df.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":469},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1732994842216,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"},"user_tz":480},"id":"Kb64vwSsXAef","outputId":"170e4f28-9200-49ca-fbc5-9f71a9d5bd43"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-df4392ae2e99>:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n","  train_str_df = train_df[[\"class\", \"comment_sentence\", \"combo\"]].applymap(\n","<ipython-input-4-df4392ae2e99>:12: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n","  test_str_df = test_df[[\"class\", \"comment_sentence\", \"combo\"]].applymap(\n"]},{"output_type":"display_data","data":{"text/plain":["   index        class                                   comment_sentence  \\\n","0      1  accessmixin                                     functionality.   \n","1      8       atomic  when it s used as a decorator, call wraps the ...   \n","2     10       atomic  when it s used as a context manager, enter cre...   \n","3     12       atomic  exit commits the transaction or releases the s...   \n","4     14       atomic  it s possible to disable the creation of savep...   \n","\n","   partition                                              combo  \\\n","0          0                        functionality | accessmixin   \n","1          0  when it s used as a decorator call wraps the e...   \n","2          0  when it s used as a context manager enter crea...   \n","3          0  exit commits the transaction or releases the s...   \n","4          0  it s possible to disable the creation of savep...   \n","\n","            labels  \n","0  [0, 0, 0, 0, 1]  \n","1  [1, 0, 0, 0, 0]  \n","2  [1, 0, 0, 0, 0]  \n","3  [1, 0, 0, 0, 0]  \n","4  [1, 0, 0, 0, 0]  "],"text/html":["\n","  <div id=\"df-eb83426d-e461-4c1f-8f77-2c89f106c15a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>class</th>\n","      <th>comment_sentence</th>\n","      <th>partition</th>\n","      <th>combo</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>accessmixin</td>\n","      <td>functionality.</td>\n","      <td>0</td>\n","      <td>functionality | accessmixin</td>\n","      <td>[0, 0, 0, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8</td>\n","      <td>atomic</td>\n","      <td>when it s used as a decorator, call wraps the ...</td>\n","      <td>0</td>\n","      <td>when it s used as a decorator call wraps the e...</td>\n","      <td>[1, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10</td>\n","      <td>atomic</td>\n","      <td>when it s used as a context manager, enter cre...</td>\n","      <td>0</td>\n","      <td>when it s used as a context manager enter crea...</td>\n","      <td>[1, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>12</td>\n","      <td>atomic</td>\n","      <td>exit commits the transaction or releases the s...</td>\n","      <td>0</td>\n","      <td>exit commits the transaction or releases the s...</td>\n","      <td>[1, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14</td>\n","      <td>atomic</td>\n","      <td>it s possible to disable the creation of savep...</td>\n","      <td>0</td>\n","      <td>it s possible to disable the creation of savep...</td>\n","      <td>[1, 0, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb83426d-e461-4c1f-8f77-2c89f106c15a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-eb83426d-e461-4c1f-8f77-2c89f106c15a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-eb83426d-e461-4c1f-8f77-2c89f106c15a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5c4a1b64-ee76-4eb4-bed9-12f05dce7471\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c4a1b64-ee76-4eb4-bed9-12f05dce7471')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5c4a1b64-ee76-4eb4-bed9-12f05dce7471 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(test_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 1,\n        \"max\": 14,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          8,\n          14,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"atomic\",\n          \"accessmixin\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comment_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"when it s used as a decorator, call wraps the execution of the\",\n          \"it s possible to disable the creation of savepoints if the goal is to\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"partition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"combo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"when it s used as a decorator call wraps the execution of the | atomic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["   index           class                                   comment_sentence  \\\n","0      0     accessmixin  abstract cbv mixin that gives access mixins th...   \n","1      2  ambiguityerror     more than one migration matches a name prefix.   \n","2      3   appconfigstub                              stub of an appconfig.   \n","3      4   appconfigstub        only provides a label and a dict of models.   \n","4      5         archive  the external api class that encapsulates an ar...   \n","\n","   partition                                              combo  \\\n","0          1  abstract cbv mixin that gives access mixins th...   \n","1          1  more than one migration matches a name prefix ...   \n","2          1               stub of an appconfig | appconfigstub   \n","3          1  only provides a label and a dict of models | a...   \n","4          1  the external api class that encapsulates an ar...   \n","\n","            labels  \n","0  [0, 0, 0, 0, 1]  \n","1  [0, 0, 0, 0, 1]  \n","2  [0, 0, 0, 0, 1]  \n","3  [0, 1, 0, 0, 0]  \n","4  [0, 0, 1, 0, 1]  "],"text/html":["\n","  <div id=\"df-e51dc9c3-f7bc-4852-a13d-ccce015d1f2f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>class</th>\n","      <th>comment_sentence</th>\n","      <th>partition</th>\n","      <th>combo</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>accessmixin</td>\n","      <td>abstract cbv mixin that gives access mixins th...</td>\n","      <td>1</td>\n","      <td>abstract cbv mixin that gives access mixins th...</td>\n","      <td>[0, 0, 0, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>ambiguityerror</td>\n","      <td>more than one migration matches a name prefix.</td>\n","      <td>1</td>\n","      <td>more than one migration matches a name prefix ...</td>\n","      <td>[0, 0, 0, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>appconfigstub</td>\n","      <td>stub of an appconfig.</td>\n","      <td>1</td>\n","      <td>stub of an appconfig | appconfigstub</td>\n","      <td>[0, 0, 0, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>appconfigstub</td>\n","      <td>only provides a label and a dict of models.</td>\n","      <td>1</td>\n","      <td>only provides a label and a dict of models | a...</td>\n","      <td>[0, 1, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>archive</td>\n","      <td>the external api class that encapsulates an ar...</td>\n","      <td>1</td>\n","      <td>the external api class that encapsulates an ar...</td>\n","      <td>[0, 0, 1, 0, 1]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e51dc9c3-f7bc-4852-a13d-ccce015d1f2f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e51dc9c3-f7bc-4852-a13d-ccce015d1f2f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e51dc9c3-f7bc-4852-a13d-ccce015d1f2f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5f12f2ec-dece-43c8-abca-929ce76b129e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f12f2ec-dece-43c8-abca-929ce76b129e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5f12f2ec-dece-43c8-abca-929ce76b129e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(test_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"ambiguityerror\",\n          \"archive\",\n          \"accessmixin\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comment_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"more than one migration matches a name prefix.\",\n          \"the external api class that encapsulates an archive implementation.\",\n          \"stub of an appconfig.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"partition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"combo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"more than one migration matches a name prefix | ambiguityerror\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}],"source":["def remove_punctuation_except_pipe(text):\n","    return re.sub(r\"[^\\w\\s\\|]\", \"\", text)\n","\n","# Apply the function to the 'combo' column\n","train_df['combo'] = train_df['combo'].apply(remove_punctuation_except_pipe)\n","test_df['combo'] = test_df['combo'].apply(remove_punctuation_except_pipe)\n","\n","# Convert data to lowercase\n","train_str_df = train_df[[\"class\", \"comment_sentence\", \"combo\"]].applymap(\n","    lambda x: x.lower() if isinstance(x, str) else str(x)\n",")\n","test_str_df = test_df[[\"class\", \"comment_sentence\", \"combo\"]].applymap(\n","    lambda x: x.lower() if isinstance(x, str) else str(x)\n",")\n","\n","train_df[[\"class\", \"comment_sentence\", \"combo\"]] = train_str_df[[\"class\", \"comment_sentence\", \"combo\"]]\n","test_df[[\"class\", \"comment_sentence\", \"combo\"]] = test_str_df[[\"class\", \"comment_sentence\", \"combo\"]]\n","\n","display(train_df.head())\n","display(test_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tZx55HL8XEbr"},"outputs":[],"source":["X = list(train_df['combo'])\n","y = list(train_df['labels'])\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":294,"referenced_widgets":["0ab2ceb1697e450cb8646889009fee22","960b72af86b5484eb4375cf87bd4acde","ccda7f0cef0449ff84cf8afceffc9242","21336c5a9b874cf8ae29763a230bfc98","c81ed4186cca42cfb5ce93890e09566c","056146ebfb2f40fcacd4a39d9555e94e","2cf8ed9c32dd4c66bef892d77d7f0b93","241fb7617b714cd7b9321534e798031a","6907cc95f03c46959312999363c05418","acdce59e02734e0f888a92ca251a9943","69d309eb596a45ff998a185886e1a4a1","83149b6ca8014850b1563fd9932bf778","cac53db9ad19434399200a3e8d8e99ae","c06cea1e5c744d70a57b7eff757e4752","4e53f56b4e6c413b96ca57f1d309f80b","ead8f92861334b7a93f8ab954ad3b567","eaaa04a5683f41e7b64291e31ecc2d91","c706b5daae8e4583a020c6ec51206fb5","8a68a106f5d245f3a08174ac8e876989","868a377eb5b24a77af946818471c1b0d","8624f5b75b004effa4a8d60900a3813b","ae3a5a4e9e324a18b3642b83b73c10b0","552afc9df70c486ca10067b436f833d9","0c92f4a4525045a5a56218cd7ba0fb5f","8e98d850c5454d988d9e56dd0d5936f0","f80989f64e674ddeb854aa91afd81cdf","95bda1e2935f467aa438ea5f2d63d365","9ae8e02b94c64c5b81bf3d22cd09605c","7ebe9c963cbc4c8395237e0ecb96af76","bf5cdeef18d54e67ad97a0f06d177745","345a3cb273494f348b33a00064dda8a0","f5cd5fc2b1744223aa2fe625f8792655","84c1d2dd2dbe4d658bd2ce82f56f3db0","c55c6c550098477581bb3eb25ef04732","705af00f1ca542faa4fd7a5a49f13002","9a1df43db8da46fd91a1c48f864a545f","d0f4df56fc834aeeb949f0db8dca7cd8","4208ea0aab64466d836ddacd1baeb4cc","e42e888200d24f92bbca9ca338f6f2b4","4a81d0575a744438b68eeb03b38c2265","fd0235f4b9b546e88bb1c4c7f4cd08e8","24bcd5069e0845ca88aabeb505d4ad8b","4e8417d3cce6422781a104dae13234c8","2e5c3711ee43422088680845b89453c5"]},"executionInfo":{"elapsed":15807,"status":"ok","timestamp":1732994858000,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"},"user_tz":480},"id":"yjykL1KCZwxN","outputId":"973a166d-d822-40e6-af11-361089ed766e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ab2ceb1697e450cb8646889009fee22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83149b6ca8014850b1563fd9932bf778"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"552afc9df70c486ca10067b436f833d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c55c6c550098477581bb3eb25ef04732"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:1439: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(resolved_archive_file, map_location=\"cpu\")\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fPuB7b6UbOB3"},"outputs":[],"source":["class TextClassificationDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, device=\"cpu\"):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.device = device\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, index):\n","        text = self.texts[index]\n","        label = self.labels[index]\n","\n","        encoded_text = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=256,\n","            padding='max_length',\n","            truncation=True,\n","            return_token_type_ids=False,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","        )\n","\n","        input_ids = encoded_text['input_ids'].squeeze().to(self.device)\n","        attention_mask = encoded_text['attention_mask'].squeeze().to(self.device)\n","        label = torch.tensor(label, dtype=torch.float).to(self.device)\n","\n","        return {\n","            'input_ids': input_ids,\n","            'attention_mask': attention_mask,\n","            'labels': label\n","        }\n","\n","train_dataset = TextClassificationDataset(X_train, y_train, tokenizer)\n","eval_dataset = TextClassificationDataset(X_val, y_val, tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nW_lCG9IbnPm"},"outputs":[],"source":["class OneHotTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        labels = inputs.get(\"labels\")\n","        outputs = model(**inputs)\n","        logits = outputs.get(\"logits\")\n","\n","        # Use BCEWithLogitsLoss for multi-label classification\n","        loss_fct = nn.BCEWithLogitsLoss()\n","        loss = loss_fct(logits, labels.float())\n","\n","        return (loss, outputs) if return_outputs else loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bu8oOgzmZqAv"},"outputs":[],"source":["def compute_metrics(pred):\n","    logits = pred.predictions\n","    preds = (logits > 0).astype(int)\n","\n","    labels = pred.label_ids\n","\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n","    accuracy = (preds == labels).mean()\n","\n","    return {\n","        'accuracy': accuracy,\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1\n","    }\n","\n","\n","# Optional compute_metrics function to get the accuracy, precision, recall, f1 for each of the individual labels\n","# without averaging them\n","\n","# from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","# def compute_metrics(pred):\n","#     # Get predictions and apply sigmoid to get probabilities\n","#     logits = pred.predictions\n","#     preds = (logits > 0).astype(int)  # Threshold at 0 to get binary predictions\n","\n","#     # Get true labels\n","#     labels = pred.label_ids\n","\n","#     # Calculate precision, recall, and f1-score for each label without averaging\n","#     precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=None)\n","#     # Calculate accuracy per label (how many times each label is correctly predicted)\n","#     accuracy_per_label = (preds == labels).mean(axis=0)\n","\n","#     # Prepare a dictionary to store metrics per category\n","#     metrics = {\n","#         'accuracy_per_label': accuracy_per_label,\n","#         'precision_per_label': precision,\n","#         'recall_per_label': recall,\n","#         'f1_per_label': f1\n","#     }\n","\n","#     # Optionally, if you want to calculate an overall accuracy:\n","#     overall_accuracy = (preds == labels).all(axis=1).mean()  # This gives the fraction of samples where all labels are correctly predicted\n","#     metrics['overall_accuracy'] = overall_accuracy\n","\n","#     return metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hJHqn0cbd2mj"},"outputs":[],"source":["def objective(trial):\n","    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","    batch_size = trial.suggest_categorical(\"batch_size\", [4, 8, 16])\n","    num_train_epochs = trial.suggest_int(\"num_train_epochs\", 3, 10)\n","    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","\n","    training_args = TrainingArguments(\n","        output_dir=\"./results\",\n","        num_train_epochs=num_train_epochs,\n","        per_device_train_batch_size=batch_size,\n","        per_device_eval_batch_size=batch_size * 2,\n","        warmup_steps=10,\n","        weight_decay=weight_decay,\n","        evaluation_strategy=\"epoch\",\n","        learning_rate=learning_rate,\n","        gradient_accumulation_steps=2,\n","        report_to=\"none\",\n","    )\n","\n","    trainer = OneHotTrainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=train_dataset,\n","        eval_dataset=eval_dataset,\n","        compute_metrics=compute_metrics,\n","    )\n","\n","    trainer.train()\n","    eval_results = trainer.evaluate()\n","\n","    return eval_results[\"eval_f1\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"wJ5YN2fBjTTD","executionInfo":{"status":"ok","timestamp":1733000046454,"user_tz":480,"elapsed":5188469,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"e3322fe6-a502-4ea3-e38b-039c3d7976f2"},"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-11-30 19:27:37,409] A new study created in memory with name: no-name-cf2b126a-43ef-473f-8607-2a3a514fd55e\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 282\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='282' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [282/282 01:44, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.489946</td>\n","      <td>0.783024</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.452661</td>\n","      <td>0.810610</td>\n","      <td>0.501702</td>\n","      <td>0.141809</td>\n","      <td>0.205888</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.435868</td>\n","      <td>0.828647</td>\n","      <td>0.473789</td>\n","      <td>0.256724</td>\n","      <td>0.329053</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [24/24 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","[I 2024-11-30 19:29:37,619] Trial 0 finished with value: 0.3290530233915995 and parameters: {'learning_rate': 9.936905260984444e-06, 'batch_size': 8, 'num_train_epochs': 3, 'weight_decay': 0.08999766298907733}. Best is trial 0 with value: 0.3290530233915995.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 1504\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1504' max='1504' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1504/1504 05:37, Epoch 7/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.341361</td>\n","      <td>0.863660</td>\n","      <td>0.705112</td>\n","      <td>0.488998</td>\n","      <td>0.560276</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.317425</td>\n","      <td>0.875862</td>\n","      <td>0.692439</td>\n","      <td>0.621027</td>\n","      <td>0.652749</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.295500</td>\n","      <td>0.319571</td>\n","      <td>0.878515</td>\n","      <td>0.755899</td>\n","      <td>0.657702</td>\n","      <td>0.682680</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.295500</td>\n","      <td>0.361003</td>\n","      <td>0.879576</td>\n","      <td>0.752510</td>\n","      <td>0.682152</td>\n","      <td>0.691598</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.295500</td>\n","      <td>0.334092</td>\n","      <td>0.897613</td>\n","      <td>0.784268</td>\n","      <td>0.728606</td>\n","      <td>0.752711</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.103400</td>\n","      <td>0.333054</td>\n","      <td>0.901857</td>\n","      <td>0.802773</td>\n","      <td>0.733496</td>\n","      <td>0.764948</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.103400</td>\n","      <td>0.340389</td>\n","      <td>0.900265</td>\n","      <td>0.794929</td>\n","      <td>0.723716</td>\n","      <td>0.757056</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.036200</td>\n","      <td>0.350222</td>\n","      <td>0.898143</td>\n","      <td>0.781876</td>\n","      <td>0.728606</td>\n","      <td>0.752393</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1500\n","Configuration saved in ./results/checkpoint-1500/config.json\n","Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [48/48 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-30 19:35:18,837] Trial 1 finished with value: 0.7523931995345864 and parameters: {'learning_rate': 3.403387612097251e-05, 'batch_size': 4, 'num_train_epochs': 8, 'weight_decay': 0.008365005257918763}. Best is trial 1 with value: 0.7523931995345864.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 1504\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1504' max='1504' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1504/1504 05:35, Epoch 7/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.382922</td>\n","      <td>0.894960</td>\n","      <td>0.776614</td>\n","      <td>0.723716</td>\n","      <td>0.745236</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.392806</td>\n","      <td>0.896552</td>\n","      <td>0.775322</td>\n","      <td>0.735941</td>\n","      <td>0.749184</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.020900</td>\n","      <td>0.405464</td>\n","      <td>0.894960</td>\n","      <td>0.769250</td>\n","      <td>0.738386</td>\n","      <td>0.748134</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.020900</td>\n","      <td>0.389206</td>\n","      <td>0.896552</td>\n","      <td>0.772895</td>\n","      <td>0.740831</td>\n","      <td>0.755144</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.020900</td>\n","      <td>0.399857</td>\n","      <td>0.897613</td>\n","      <td>0.774702</td>\n","      <td>0.743276</td>\n","      <td>0.755438</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.015000</td>\n","      <td>0.395141</td>\n","      <td>0.901326</td>\n","      <td>0.785932</td>\n","      <td>0.745721</td>\n","      <td>0.764848</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.015000</td>\n","      <td>0.400643</td>\n","      <td>0.897082</td>\n","      <td>0.773934</td>\n","      <td>0.738386</td>\n","      <td>0.753918</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.009800</td>\n","      <td>0.402740</td>\n","      <td>0.897082</td>\n","      <td>0.773653</td>\n","      <td>0.738386</td>\n","      <td>0.753650</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1500\n","Configuration saved in ./results/checkpoint-1500/config.json\n","Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [48/48 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-30 19:40:57,315] Trial 2 finished with value: 0.7536498162355401 and parameters: {'learning_rate': 6.252111623008766e-06, 'batch_size': 4, 'num_train_epochs': 8, 'weight_decay': 0.011102647121284889}. Best is trial 2 with value: 0.7536498162355401.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 6\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 282\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='282' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [282/282 03:25, Epoch 5/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.419280</td>\n","      <td>0.898143</td>\n","      <td>0.765138</td>\n","      <td>0.762836</td>\n","      <td>0.760437</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.426106</td>\n","      <td>0.893369</td>\n","      <td>0.757931</td>\n","      <td>0.757946</td>\n","      <td>0.753847</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.439734</td>\n","      <td>0.893899</td>\n","      <td>0.756369</td>\n","      <td>0.753056</td>\n","      <td>0.750108</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.432320</td>\n","      <td>0.901326</td>\n","      <td>0.781191</td>\n","      <td>0.753056</td>\n","      <td>0.763338</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.423177</td>\n","      <td>0.898143</td>\n","      <td>0.772030</td>\n","      <td>0.750611</td>\n","      <td>0.759761</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>No log</td>\n","      <td>0.427718</td>\n","      <td>0.900265</td>\n","      <td>0.778000</td>\n","      <td>0.753056</td>\n","      <td>0.764416</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12/12 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-30 19:44:27,025] Trial 3 finished with value: 0.7644155853326999 and parameters: {'learning_rate': 1.3227814907787768e-05, 'batch_size': 16, 'num_train_epochs': 6, 'weight_decay': 0.0074505590236146274}. Best is trial 3 with value: 0.7644155853326999.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 329\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='329' max='329' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [329/329 03:59, Epoch 6/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.433114</td>\n","      <td>0.898674</td>\n","      <td>0.772844</td>\n","      <td>0.753056</td>\n","      <td>0.761730</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.433054</td>\n","      <td>0.899735</td>\n","      <td>0.773549</td>\n","      <td>0.757946</td>\n","      <td>0.764236</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.431939</td>\n","      <td>0.899204</td>\n","      <td>0.775082</td>\n","      <td>0.750611</td>\n","      <td>0.761398</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.433523</td>\n","      <td>0.900265</td>\n","      <td>0.778807</td>\n","      <td>0.750611</td>\n","      <td>0.763171</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.433790</td>\n","      <td>0.900796</td>\n","      <td>0.780637</td>\n","      <td>0.750611</td>\n","      <td>0.764150</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>No log</td>\n","      <td>0.433044</td>\n","      <td>0.900265</td>\n","      <td>0.779892</td>\n","      <td>0.748166</td>\n","      <td>0.762660</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>No log</td>\n","      <td>0.433397</td>\n","      <td>0.900796</td>\n","      <td>0.780343</td>\n","      <td>0.750611</td>\n","      <td>0.764049</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12/12 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-30 19:48:30,472] Trial 4 finished with value: 0.7640492527743392 and parameters: {'learning_rate': 3.0315491507502885e-06, 'batch_size': 16, 'num_train_epochs': 7, 'weight_decay': 0.0014550325138242017}. Best is trial 3 with value: 0.7644155853326999.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 376\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='376' max='376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [376/376 04:34, Epoch 7/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.462360</td>\n","      <td>0.899735</td>\n","      <td>0.780021</td>\n","      <td>0.750611</td>\n","      <td>0.764164</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.452513</td>\n","      <td>0.898143</td>\n","      <td>0.769090</td>\n","      <td>0.755501</td>\n","      <td>0.761195</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.464721</td>\n","      <td>0.896021</td>\n","      <td>0.764179</td>\n","      <td>0.757946</td>\n","      <td>0.757621</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.467696</td>\n","      <td>0.901326</td>\n","      <td>0.784013</td>\n","      <td>0.748166</td>\n","      <td>0.762496</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.459497</td>\n","      <td>0.899204</td>\n","      <td>0.772184</td>\n","      <td>0.755501</td>\n","      <td>0.763009</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>No log</td>\n","      <td>0.466692</td>\n","      <td>0.900265</td>\n","      <td>0.777233</td>\n","      <td>0.753056</td>\n","      <td>0.763531</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>No log</td>\n","      <td>0.466306</td>\n","      <td>0.901857</td>\n","      <td>0.780922</td>\n","      <td>0.755501</td>\n","      <td>0.766231</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>No log</td>\n","      <td>0.465084</td>\n","      <td>0.899735</td>\n","      <td>0.776481</td>\n","      <td>0.750611</td>\n","      <td>0.762237</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12/12 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-30 19:53:08,316] Trial 5 finished with value: 0.7622365592836666 and parameters: {'learning_rate': 1.1517370970098138e-05, 'batch_size': 16, 'num_train_epochs': 8, 'weight_decay': 0.0036339189127131445}. Best is trial 3 with value: 0.7644155853326999.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 940\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [940/940 06:02, Epoch 9/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.475023</td>\n","      <td>0.902387</td>\n","      <td>0.778872</td>\n","      <td>0.762836</td>\n","      <td>0.769741</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.481350</td>\n","      <td>0.904509</td>\n","      <td>0.786435</td>\n","      <td>0.765281</td>\n","      <td>0.773410</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.479742</td>\n","      <td>0.902387</td>\n","      <td>0.779622</td>\n","      <td>0.760391</td>\n","      <td>0.769063</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.481133</td>\n","      <td>0.899735</td>\n","      <td>0.775896</td>\n","      <td>0.753056</td>\n","      <td>0.763604</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.493133</td>\n","      <td>0.899735</td>\n","      <td>0.779903</td>\n","      <td>0.745721</td>\n","      <td>0.759957</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.002300</td>\n","      <td>0.487453</td>\n","      <td>0.900796</td>\n","      <td>0.780767</td>\n","      <td>0.753056</td>\n","      <td>0.765077</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.002300</td>\n","      <td>0.490142</td>\n","      <td>0.900265</td>\n","      <td>0.779902</td>\n","      <td>0.750611</td>\n","      <td>0.762778</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.002300</td>\n","      <td>0.487874</td>\n","      <td>0.901326</td>\n","      <td>0.780994</td>\n","      <td>0.755501</td>\n","      <td>0.766228</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.002300</td>\n","      <td>0.489108</td>\n","      <td>0.901326</td>\n","      <td>0.780994</td>\n","      <td>0.755501</td>\n","      <td>0.766228</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.002300</td>\n","      <td>0.490747</td>\n","      <td>0.901326</td>\n","      <td>0.780994</td>\n","      <td>0.755501</td>\n","      <td>0.766228</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [24/24 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-30 19:59:13,871] Trial 6 finished with value: 0.7662276745280352 and parameters: {'learning_rate': 2.5963546829701276e-06, 'batch_size': 8, 'num_train_epochs': 10, 'weight_decay': 0.0013370395866551545}. Best is trial 6 with value: 0.7662276745280352.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 9\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 1692\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1692' max='1692' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1692/1692 06:20, Epoch 8/9]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.485274</td>\n","      <td>0.901857</td>\n","      <td>0.779226</td>\n","      <td>0.762836</td>\n","      <td>0.770091</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.504665</td>\n","      <td>0.897613</td>\n","      <td>0.771743</td>\n","      <td>0.757946</td>\n","      <td>0.762227</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.002000</td>\n","      <td>0.511892</td>\n","      <td>0.901326</td>\n","      <td>0.781961</td>\n","      <td>0.757946</td>\n","      <td>0.765960</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.002000</td>\n","      <td>0.506886</td>\n","      <td>0.900265</td>\n","      <td>0.777667</td>\n","      <td>0.755501</td>\n","      <td>0.764175</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.002000</td>\n","      <td>0.508513</td>\n","      <td>0.897613</td>\n","      <td>0.773183</td>\n","      <td>0.748166</td>\n","      <td>0.758698</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.001400</td>\n","      <td>0.506512</td>\n","      <td>0.897613</td>\n","      <td>0.768446</td>\n","      <td>0.755501</td>\n","      <td>0.761012</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.001400</td>\n","      <td>0.514277</td>\n","      <td>0.898143</td>\n","      <td>0.774181</td>\n","      <td>0.750611</td>\n","      <td>0.760436</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.001200</td>\n","      <td>0.510576</td>\n","      <td>0.897082</td>\n","      <td>0.772990</td>\n","      <td>0.745721</td>\n","      <td>0.757558</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.001200</td>\n","      <td>0.511220</td>\n","      <td>0.897613</td>\n","      <td>0.772787</td>\n","      <td>0.748166</td>\n","      <td>0.758723</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1500\n","Configuration saved in ./results/checkpoint-1500/config.json\n","Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [48/48 00:03]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-30 20:05:37,227] Trial 7 finished with value: 0.758722802959022 and parameters: {'learning_rate': 3.0803819219255988e-06, 'batch_size': 4, 'num_train_epochs': 9, 'weight_decay': 0.03581155318461229}. Best is trial 6 with value: 0.7662276745280352.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 6\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 1128\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1128' max='1128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1128/1128 04:11, Epoch 5/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.531010</td>\n","      <td>0.897082</td>\n","      <td>0.777236</td>\n","      <td>0.738386</td>\n","      <td>0.755184</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.538065</td>\n","      <td>0.900265</td>\n","      <td>0.780356</td>\n","      <td>0.753056</td>\n","      <td>0.764007</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.000800</td>\n","      <td>0.540538</td>\n","      <td>0.898674</td>\n","      <td>0.779381</td>\n","      <td>0.743276</td>\n","      <td>0.758610</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.000800</td>\n","      <td>0.543718</td>\n","      <td>0.899204</td>\n","      <td>0.777656</td>\n","      <td>0.750611</td>\n","      <td>0.761559</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.000800</td>\n","      <td>0.540625</td>\n","      <td>0.898674</td>\n","      <td>0.773711</td>\n","      <td>0.750611</td>\n","      <td>0.760171</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.000700</td>\n","      <td>0.539292</td>\n","      <td>0.899204</td>\n","      <td>0.777391</td>\n","      <td>0.750611</td>\n","      <td>0.761920</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [48/48 00:03]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-30 20:09:51,995] Trial 8 finished with value: 0.7619197939347515 and parameters: {'learning_rate': 2.36155019362175e-06, 'batch_size': 4, 'num_train_epochs': 6, 'weight_decay': 0.0020572454630452598}. Best is trial 6 with value: 0.7662276745280352.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 9\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 846\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='846' max='846' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [846/846 05:31, Epoch 8/9]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.598366</td>\n","      <td>0.899735</td>\n","      <td>0.779092</td>\n","      <td>0.743276</td>\n","      <td>0.757537</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.560354</td>\n","      <td>0.902918</td>\n","      <td>0.780329</td>\n","      <td>0.775061</td>\n","      <td>0.773257</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.595574</td>\n","      <td>0.901326</td>\n","      <td>0.784999</td>\n","      <td>0.743276</td>\n","      <td>0.761292</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.599428</td>\n","      <td>0.899204</td>\n","      <td>0.772130</td>\n","      <td>0.757946</td>\n","      <td>0.763170</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.600793</td>\n","      <td>0.899735</td>\n","      <td>0.780532</td>\n","      <td>0.743276</td>\n","      <td>0.759897</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.002300</td>\n","      <td>0.612988</td>\n","      <td>0.901326</td>\n","      <td>0.784477</td>\n","      <td>0.748166</td>\n","      <td>0.763461</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.002300</td>\n","      <td>0.608367</td>\n","      <td>0.898143</td>\n","      <td>0.778711</td>\n","      <td>0.743276</td>\n","      <td>0.758597</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.002300</td>\n","      <td>0.613190</td>\n","      <td>0.897613</td>\n","      <td>0.776365</td>\n","      <td>0.743276</td>\n","      <td>0.757032</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.002300</td>\n","      <td>0.612132</td>\n","      <td>0.898143</td>\n","      <td>0.779032</td>\n","      <td>0.740831</td>\n","      <td>0.757354</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [24/24 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-30 20:15:26,894] Trial 9 finished with value: 0.7573535988737815 and parameters: {'learning_rate': 1.6214165466362665e-05, 'batch_size': 8, 'num_train_epochs': 9, 'weight_decay': 0.00018757887500422745}. Best is trial 6 with value: 0.7662276745280352.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 940\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [940/940 06:08, Epoch 9/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.606270</td>\n","      <td>0.895491</td>\n","      <td>0.767969</td>\n","      <td>0.745721</td>\n","      <td>0.755110</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.621504</td>\n","      <td>0.898143</td>\n","      <td>0.768781</td>\n","      <td>0.760391</td>\n","      <td>0.761449</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.617264</td>\n","      <td>0.898674</td>\n","      <td>0.771928</td>\n","      <td>0.755501</td>\n","      <td>0.761525</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.615657</td>\n","      <td>0.899204</td>\n","      <td>0.778378</td>\n","      <td>0.745721</td>\n","      <td>0.759781</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.616767</td>\n","      <td>0.899735</td>\n","      <td>0.778228</td>\n","      <td>0.748166</td>\n","      <td>0.760837</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.000500</td>\n","      <td>0.618465</td>\n","      <td>0.899735</td>\n","      <td>0.779715</td>\n","      <td>0.745721</td>\n","      <td>0.760205</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.000500</td>\n","      <td>0.618396</td>\n","      <td>0.899204</td>\n","      <td>0.777820</td>\n","      <td>0.745721</td>\n","      <td>0.759406</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.000500</td>\n","      <td>0.616116</td>\n","      <td>0.898143</td>\n","      <td>0.778642</td>\n","      <td>0.738386</td>\n","      <td>0.756152</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.000500</td>\n","      <td>0.614741</td>\n","      <td>0.897613</td>\n","      <td>0.778228</td>\n","      <td>0.735941</td>\n","      <td>0.754683</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.000500</td>\n","      <td>0.615502</td>\n","      <td>0.897613</td>\n","      <td>0.778228</td>\n","      <td>0.735941</td>\n","      <td>0.754683</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [24/24 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-30 20:21:38,313] Trial 10 finished with value: 0.7546831055440526 and parameters: {'learning_rate': 1.2977308798512037e-06, 'batch_size': 8, 'num_train_epochs': 10, 'weight_decay': 0.00035069973814453155}. Best is trial 6 with value: 0.7662276745280352.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 235\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='235' max='235' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [235/235 02:50, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.652202</td>\n","      <td>0.898674</td>\n","      <td>0.780098</td>\n","      <td>0.740831</td>\n","      <td>0.757069</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.634921</td>\n","      <td>0.900265</td>\n","      <td>0.764711</td>\n","      <td>0.797066</td>\n","      <td>0.779083</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.664600</td>\n","      <td>0.897613</td>\n","      <td>0.775681</td>\n","      <td>0.728606</td>\n","      <td>0.748269</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.644963</td>\n","      <td>0.898674</td>\n","      <td>0.775319</td>\n","      <td>0.745721</td>\n","      <td>0.758847</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.645202</td>\n","      <td>0.900796</td>\n","      <td>0.782030</td>\n","      <td>0.745721</td>\n","      <td>0.761915</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12/12 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-30 20:24:32,793] Trial 11 finished with value: 0.7619150364280564 and parameters: {'learning_rate': 2.7666367431042764e-05, 'batch_size': 16, 'num_train_epochs': 5, 'weight_decay': 0.0006448585124851145}. Best is trial 6 with value: 0.7662276745280352.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 235\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='235' max='235' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [235/235 02:51, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.646177</td>\n","      <td>0.898143</td>\n","      <td>0.781886</td>\n","      <td>0.740831</td>\n","      <td>0.759612</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.658634</td>\n","      <td>0.898674</td>\n","      <td>0.777186</td>\n","      <td>0.745721</td>\n","      <td>0.758583</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.656427</td>\n","      <td>0.898143</td>\n","      <td>0.772434</td>\n","      <td>0.750611</td>\n","      <td>0.759481</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.656746</td>\n","      <td>0.899204</td>\n","      <td>0.776073</td>\n","      <td>0.748166</td>\n","      <td>0.760120</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.657449</td>\n","      <td>0.899204</td>\n","      <td>0.777149</td>\n","      <td>0.745721</td>\n","      <td>0.759128</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12/12 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-30 20:27:27,796] Trial 12 finished with value: 0.7591283436995445 and parameters: {'learning_rate': 5.194760598409354e-06, 'batch_size': 16, 'num_train_epochs': 5, 'weight_decay': 0.007456652868230061}. Best is trial 6 with value: 0.7662276745280352.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 282\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='282' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [282/282 01:47, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.652971</td>\n","      <td>0.899735</td>\n","      <td>0.777762</td>\n","      <td>0.745721</td>\n","      <td>0.759611</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.658763</td>\n","      <td>0.900265</td>\n","      <td>0.779455</td>\n","      <td>0.748166</td>\n","      <td>0.761566</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.659436</td>\n","      <td>0.901326</td>\n","      <td>0.783234</td>\n","      <td>0.748166</td>\n","      <td>0.763087</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [24/24 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-30 20:29:18,473] Trial 13 finished with value: 0.7630868208489473 and parameters: {'learning_rate': 1.3741722932814452e-06, 'batch_size': 8, 'num_train_epochs': 3, 'weight_decay': 0.0007649819919088713}. Best is trial 6 with value: 0.7662276745280352.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 6\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 282\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='282' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [282/282 03:25, Epoch 5/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.694220</td>\n","      <td>0.897082</td>\n","      <td>0.772729</td>\n","      <td>0.762836</td>\n","      <td>0.761610</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.731963</td>\n","      <td>0.887003</td>\n","      <td>0.738828</td>\n","      <td>0.765281</td>\n","      <td>0.749345</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.758954</td>\n","      <td>0.897613</td>\n","      <td>0.775540</td>\n","      <td>0.748166</td>\n","      <td>0.752132</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.714308</td>\n","      <td>0.895491</td>\n","      <td>0.764259</td>\n","      <td>0.750611</td>\n","      <td>0.755062</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.694335</td>\n","      <td>0.900265</td>\n","      <td>0.773890</td>\n","      <td>0.757946</td>\n","      <td>0.764242</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>No log</td>\n","      <td>0.695762</td>\n","      <td>0.901326</td>\n","      <td>0.776484</td>\n","      <td>0.760391</td>\n","      <td>0.766409</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12/12 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-30 20:32:47,656] Trial 14 finished with value: 0.7664093810806344 and parameters: {'learning_rate': 2.0071035169373224e-05, 'batch_size': 16, 'num_train_epochs': 6, 'weight_decay': 0.028779217423793482}. Best is trial 14 with value: 0.7664093810806344.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 470\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [470/470 02:59, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.737214</td>\n","      <td>0.897082</td>\n","      <td>0.764186</td>\n","      <td>0.750611</td>\n","      <td>0.755057</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.856272</td>\n","      <td>0.888594</td>\n","      <td>0.769342</td>\n","      <td>0.731051</td>\n","      <td>0.736120</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.753704</td>\n","      <td>0.898143</td>\n","      <td>0.780644</td>\n","      <td>0.743276</td>\n","      <td>0.757281</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.764816</td>\n","      <td>0.899204</td>\n","      <td>0.779262</td>\n","      <td>0.745721</td>\n","      <td>0.757637</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.754181</td>\n","      <td>0.900265</td>\n","      <td>0.785905</td>\n","      <td>0.743276</td>\n","      <td>0.756674</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [24/24 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-30 20:35:50,478] Trial 15 finished with value: 0.7566738737805662 and parameters: {'learning_rate': 2.3088859475157345e-05, 'batch_size': 8, 'num_train_epochs': 5, 'weight_decay': 0.02390329603865844}. Best is trial 14 with value: 0.7664093810806344.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 940\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [940/940 06:07, Epoch 9/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.859616</td>\n","      <td>0.873210</td>\n","      <td>0.724362</td>\n","      <td>0.706601</td>\n","      <td>0.703124</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.793436</td>\n","      <td>0.893899</td>\n","      <td>0.772569</td>\n","      <td>0.738386</td>\n","      <td>0.753803</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.762645</td>\n","      <td>0.890716</td>\n","      <td>0.760556</td>\n","      <td>0.753056</td>\n","      <td>0.750734</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.743810</td>\n","      <td>0.894960</td>\n","      <td>0.768563</td>\n","      <td>0.738386</td>\n","      <td>0.750097</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.825038</td>\n","      <td>0.884881</td>\n","      <td>0.758950</td>\n","      <td>0.711491</td>\n","      <td>0.726480</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.010500</td>\n","      <td>0.775316</td>\n","      <td>0.894960</td>\n","      <td>0.768382</td>\n","      <td>0.753056</td>\n","      <td>0.754133</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.010500</td>\n","      <td>0.776427</td>\n","      <td>0.896021</td>\n","      <td>0.770922</td>\n","      <td>0.750611</td>\n","      <td>0.757135</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.010500</td>\n","      <td>0.780790</td>\n","      <td>0.894960</td>\n","      <td>0.759438</td>\n","      <td>0.760391</td>\n","      <td>0.757211</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.010500</td>\n","      <td>0.786209</td>\n","      <td>0.892838</td>\n","      <td>0.756108</td>\n","      <td>0.753056</td>\n","      <td>0.751098</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.010500</td>\n","      <td>0.782313</td>\n","      <td>0.897082</td>\n","      <td>0.766924</td>\n","      <td>0.757946</td>\n","      <td>0.759975</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [24/24 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-30 20:42:01,714] Trial 16 finished with value: 0.7599745824781375 and parameters: {'learning_rate': 4.588831169078321e-05, 'batch_size': 8, 'num_train_epochs': 10, 'weight_decay': 0.06804919039883983}. Best is trial 14 with value: 0.7664093810806344.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 188\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='188' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [188/188 02:16, Epoch 3/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.795709</td>\n","      <td>0.898143</td>\n","      <td>0.774013</td>\n","      <td>0.755501</td>\n","      <td>0.762133</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.804763</td>\n","      <td>0.895491</td>\n","      <td>0.763786</td>\n","      <td>0.757946</td>\n","      <td>0.757477</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.804997</td>\n","      <td>0.894430</td>\n","      <td>0.760745</td>\n","      <td>0.753056</td>\n","      <td>0.754209</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.805054</td>\n","      <td>0.894430</td>\n","      <td>0.760745</td>\n","      <td>0.753056</td>\n","      <td>0.754209</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12/12 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-30 20:44:22,174] Trial 17 finished with value: 0.754209391186191 and parameters: {'learning_rate': 4.540236626615014e-06, 'batch_size': 16, 'num_train_epochs': 4, 'weight_decay': 0.00010706948642444814}. Best is trial 14 with value: 0.7664093810806344.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 329\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='329' max='329' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [329/329 04:00, Epoch 6/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.829859</td>\n","      <td>0.899735</td>\n","      <td>0.783622</td>\n","      <td>0.750611</td>\n","      <td>0.762804</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.835165</td>\n","      <td>0.897082</td>\n","      <td>0.772908</td>\n","      <td>0.750611</td>\n","      <td>0.758871</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.842590</td>\n","      <td>0.898674</td>\n","      <td>0.776098</td>\n","      <td>0.750611</td>\n","      <td>0.760249</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.838163</td>\n","      <td>0.899735</td>\n","      <td>0.778598</td>\n","      <td>0.753056</td>\n","      <td>0.763413</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.843826</td>\n","      <td>0.898674</td>\n","      <td>0.776193</td>\n","      <td>0.748166</td>\n","      <td>0.759847</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>No log</td>\n","      <td>0.844501</td>\n","      <td>0.897082</td>\n","      <td>0.769136</td>\n","      <td>0.750611</td>\n","      <td>0.757570</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>No log</td>\n","      <td>0.847615</td>\n","      <td>0.897082</td>\n","      <td>0.771026</td>\n","      <td>0.748166</td>\n","      <td>0.757163</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12/12 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-30 20:48:26,144] Trial 18 finished with value: 0.7571633066830137 and parameters: {'learning_rate': 8.06494012495203e-06, 'batch_size': 16, 'num_train_epochs': 7, 'weight_decay': 0.0037009462787351926}. Best is trial 14 with value: 0.7664093810806344.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 9\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 846\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='846' max='846' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [846/846 05:36, Epoch 8/9]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.844785</td>\n","      <td>0.896021</td>\n","      <td>0.767298</td>\n","      <td>0.748166</td>\n","      <td>0.756031</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.862137</td>\n","      <td>0.897082</td>\n","      <td>0.770002</td>\n","      <td>0.757946</td>\n","      <td>0.761264</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.860023</td>\n","      <td>0.896021</td>\n","      <td>0.767753</td>\n","      <td>0.753056</td>\n","      <td>0.756863</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.857765</td>\n","      <td>0.897082</td>\n","      <td>0.769532</td>\n","      <td>0.755501</td>\n","      <td>0.759864</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.851376</td>\n","      <td>0.896021</td>\n","      <td>0.765364</td>\n","      <td>0.753056</td>\n","      <td>0.757585</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.000000</td>\n","      <td>0.863781</td>\n","      <td>0.896552</td>\n","      <td>0.771111</td>\n","      <td>0.753056</td>\n","      <td>0.758970</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.000000</td>\n","      <td>0.863133</td>\n","      <td>0.897613</td>\n","      <td>0.775229</td>\n","      <td>0.753056</td>\n","      <td>0.760727</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.000000</td>\n","      <td>0.862491</td>\n","      <td>0.897082</td>\n","      <td>0.772598</td>\n","      <td>0.753056</td>\n","      <td>0.759739</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.000000</td>\n","      <td>0.862999</td>\n","      <td>0.897613</td>\n","      <td>0.774384</td>\n","      <td>0.755501</td>\n","      <td>0.761396</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [24/24 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-11-30 20:54:05,984] Trial 19 finished with value: 0.7613955355470121 and parameters: {'learning_rate': 1.945827508559902e-06, 'batch_size': 8, 'num_train_epochs': 9, 'weight_decay': 0.02037909320490351}. Best is trial 14 with value: 0.7664093810806344.\n"]},{"output_type":"stream","name":"stdout","text":["Best trial:\n","FrozenTrial(number=14, state=TrialState.COMPLETE, values=[0.7664093810806344], datetime_start=datetime.datetime(2024, 11, 30, 20, 29, 18, 475437), datetime_complete=datetime.datetime(2024, 11, 30, 20, 32, 47, 656203), params={'learning_rate': 2.0071035169373224e-05, 'batch_size': 16, 'num_train_epochs': 6, 'weight_decay': 0.028779217423793482}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=5e-05, log=True, low=1e-06, step=None), 'batch_size': CategoricalDistribution(choices=(4, 8, 16)), 'num_train_epochs': IntDistribution(high=10, log=False, low=3, step=1), 'weight_decay': FloatDistribution(high=0.1, log=True, low=0.0001, step=None)}, trial_id=14, value=None)\n"]}],"source":["study = optuna.create_study(direction=\"maximize\")\n","study.optimize(objective, n_trials=20)\n","\n","print(\"Best trial:\")\n","print(study.best_trial)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pLWKONgej8cE","colab":{"base_uri":"https://localhost:8080/","height":929},"executionInfo":{"status":"ok","timestamp":1733000252356,"user_tz":480,"elapsed":205910,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"51e40396-634f-4c35-89af-556aee672399"},"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 6\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 282\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='282' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [282/282 03:25, Epoch 5/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.923222</td>\n","      <td>0.894960</td>\n","      <td>0.768639</td>\n","      <td>0.748166</td>\n","      <td>0.753845</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.971287</td>\n","      <td>0.891247</td>\n","      <td>0.761478</td>\n","      <td>0.740831</td>\n","      <td>0.743622</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.908051</td>\n","      <td>0.893899</td>\n","      <td>0.766098</td>\n","      <td>0.745721</td>\n","      <td>0.753367</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.915926</td>\n","      <td>0.896021</td>\n","      <td>0.768218</td>\n","      <td>0.753056</td>\n","      <td>0.757172</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.915880</td>\n","      <td>0.894430</td>\n","      <td>0.764844</td>\n","      <td>0.748166</td>\n","      <td>0.753034</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>No log</td>\n","      <td>0.915147</td>\n","      <td>0.894960</td>\n","      <td>0.767088</td>\n","      <td>0.748166</td>\n","      <td>0.754075</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=282, training_loss=9.004434848085362e-05, metrics={'train_runtime': 206.0722, 'train_samples_per_second': 43.878, 'train_steps_per_second': 1.368, 'total_flos': 598718438392320.0, 'train_loss': 9.004434848085362e-05, 'epoch': 5.99})"]},"metadata":{},"execution_count":12}],"source":["best_hyperparams = study.best_trial.params\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./best_results\",\n","    num_train_epochs=best_hyperparams[\"num_train_epochs\"],\n","    per_device_train_batch_size=best_hyperparams[\"batch_size\"],\n","    per_device_eval_batch_size=best_hyperparams[\"batch_size\"] * 2,\n","    learning_rate=best_hyperparams[\"learning_rate\"],\n","    weight_decay=best_hyperparams[\"weight_decay\"],\n","    warmup_steps=10,\n","    evaluation_strategy=\"epoch\",\n","    gradient_accumulation_steps=2,\n","    report_to=\"none\",\n",")\n","\n","trainer = OneHotTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics,\n",")\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WduIvUWwd-4k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733000260998,"user_tz":480,"elapsed":8647,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"e1ec3db6-0902-4cf6-9fb7-16a7df1841d0"},"outputs":[{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to ./best_model_distilbert_python\n","Configuration saved in ./best_model_distilbert_python/config.json\n","Model weights saved in ./best_model_distilbert_python/pytorch_model.bin\n","tokenizer config file saved in ./best_model_distilbert_python_tokenizer/tokenizer_config.json\n","Special tokens file saved in ./best_model_distilbert_python_tokenizer/special_tokens_map.json\n","loading configuration file ./best_model_distilbert_python/config.json\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForSequenceClassification\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"problem_type\": \"multi_label_classification\",\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file ./best_model_distilbert_python/pytorch_model.bin\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:1439: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(resolved_archive_file, map_location=\"cpu\")\n","All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n","\n","All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at ./best_model_distilbert_python.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n","Didn't find file ./best_model_distilbert_python_tokenizer/added_tokens.json. We won't load it.\n","loading file ./best_model_distilbert_python_tokenizer/vocab.txt\n","loading file None\n","loading file ./best_model_distilbert_python_tokenizer/special_tokens_map.json\n","loading file ./best_model_distilbert_python_tokenizer/tokenizer_config.json\n"]}],"source":["!mkdir 'best_model_distilbert_python'\n","!mkdir 'best_model_distilbert_python_tokenizer'\n","\n","# Save model and tokenizer\n","trainer.save_model('./best_model_distilbert_python')\n","tokenizer.save_pretrained('./best_model_distilbert_python_tokenizer')\n","\n","# Load model and tokenizer\n","from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n","\n","model = DistilBertForSequenceClassification.from_pretrained('./best_model_distilbert_python')\n","tokenizer = DistilBertTokenizer.from_pretrained('./best_model_distilbert_python_tokenizer')"]},{"cell_type":"markdown","metadata":{"id":"Cs8GQ1fMHfC5"},"source":["## Model Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xbla2FVJHlJ5"},"outputs":[],"source":["X_test = list(test_df['combo'])\n","y_test = list(test_df['labels'])"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Kyn9yo7HHrDF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733000260999,"user_tz":480,"elapsed":18,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"60ca8023-343f-4e43-e0d7-7ec322e8b53f"},"outputs":[{"output_type":"stream","name":"stdout","text":["[array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 1, 0, 0, 0]) array([0, 0, 1, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([1, 0, 0, 1, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 1, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([0, 0, 1, 0, 0]) array([0, 0, 0, 0, 1])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 1, 0, 0]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 1, 0, 0])\n"," array([0, 0, 0, 0, 1]) array([1, 0, 0, 0, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 1, 1, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([0, 0, 1, 0, 1]) array([0, 1, 0, 0, 1]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 1, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 1, 0, 0]) array([0, 0, 1, 0, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([1, 0, 0, 0, 0]) array([0, 0, 0, 1, 0]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([1, 0, 0, 0, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 1, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([0, 0, 1, 0, 0]) array([0, 0, 1, 0, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0])\n"," array([1, 0, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([1, 0, 0, 1, 0]) array([1, 0, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 1, 0]) array([0, 1, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 0, 0, 0, 1]) array([0, 0, 1, 1, 0])\n"," array([0, 0, 1, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 0, 0, 0, 1]) array([1, 0, 0, 0, 0])\n"," array([0, 0, 1, 0, 0]) array([0, 0, 1, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 1, 0]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 1, 0, 0]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 1, 1, 0]) array([0, 0, 1, 1, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 1, 0]) array([0, 1, 0, 1, 1])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 1, 0, 0])\n"," array([0, 0, 1, 0, 0]) array([0, 1, 0, 1, 0]) array([1, 1, 0, 1, 0])\n"," array([1, 0, 1, 0, 0]) array([1, 0, 1, 0, 0]) array([1, 0, 1, 0, 0])\n"," array([0, 0, 0, 0, 1]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 1, 0, 0]) array([0, 1, 0, 0, 1]) array([0, 1, 1, 0, 0])\n"," array([0, 1, 1, 0, 0]) array([0, 0, 1, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([0, 0, 1, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([1, 0, 0, 0, 0]) array([0, 0, 0, 0, 1]) array([1, 0, 1, 0, 0])\n"," array([0, 0, 1, 0, 0]) array([0, 0, 1, 0, 0]) array([0, 0, 1, 0, 0])\n"," array([1, 0, 1, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 1, 0, 0]) array([0, 0, 1, 0, 0]) array([0, 0, 1, 1, 0])\n"," array([0, 0, 1, 0, 0]) array([0, 0, 1, 1, 0]) array([0, 0, 1, 0, 0])\n"," array([0, 0, 1, 0, 0]) array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 1]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 0, 0, 0, 1])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 1, 0, 0]) array([0, 0, 1, 0, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 1]) array([1, 0, 0, 1, 0]) array([1, 0, 0, 1, 0])\n"," array([1, 0, 0, 1, 0]) array([1, 0, 0, 1, 0]) array([0, 0, 0, 1, 0])\n"," array([1, 0, 0, 1, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([1, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 1])]\n"]}],"source":["df_test = pd.DataFrame({\"combo\":X_test,\"labels\":y_test})\n","test_text = df_test.combo.values\n","test_label = df_test.labels.values\n","\n","print(test_label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_35s4NGfIGbz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733000260999,"user_tz":480,"elapsed":15,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"44ac1dda-dfbf-4c98-832f-53cbafd33748"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{},"execution_count":16}],"source":["type(test_label[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5euYrzC3HiU9","colab":{"base_uri":"https://localhost:8080/","height":129},"executionInfo":{"status":"ok","timestamp":1733000264362,"user_tz":480,"elapsed":3372,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"9204217c-c79d-40df-e043-1d076142a7cf"},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 406\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [13/13 00:02]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Evaluation Metrics: {'accuracy': 0.8605911330049261, 'precision': 0.6843921427560762, 'recall': 0.6422018348623854, 'f1': 0.6591660558686011}\n","Inference Time: 3.31 seconds\n"]}],"source":["test_dataset = TextClassificationDataset(test_text, test_label, tokenizer)\n","\n","# Measure inference time\n","start_time = time.time()\n","\n","# Predict on the test dataset\n","predictions = trainer.predict(test_dataset)\n","\n","# Calculate elapsed time\n","end_time = time.time()\n","inference_time = end_time - start_time\n","\n","# Compute metrics using the `compute_metrics` function\n","metrics = compute_metrics(predictions)\n","\n","# Display metrics and inference time\n","print(\"Evaluation Metrics:\", metrics)\n","print(f\"Inference Time: {inference_time:.2f} seconds\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WRp9UcCfGrfn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733000279524,"user_tz":480,"elapsed":15169,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"2dc68c6b-288a-431f-a22a-25c3b7736ed7"},"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: best_model_distilbert_python/ (stored 0%)\n","  adding: best_model_distilbert_python/pytorch_model.bin (deflated 8%)\n","  adding: best_model_distilbert_python/training_args.bin (deflated 51%)\n","  adding: best_model_distilbert_python/config.json (deflated 51%)\n","  adding: best_model_distilbert_python_tokenizer/ (stored 0%)\n","  adding: best_model_distilbert_python_tokenizer/tokenizer_config.json (deflated 43%)\n","  adding: best_model_distilbert_python_tokenizer/special_tokens_map.json (deflated 40%)\n","  adding: best_model_distilbert_python_tokenizer/vocab.txt (deflated 53%)\n"]}],"source":["!zip -r best_model_distilbert_python.zip './best_model_distilbert_python'\n","!zip -r best_model_distilbert_python_tokenizer.zip './best_model_distilbert_python_tokenizer'\n","\n","# For downloading model locally\n","# from google.colab import files\n","# files.download('checkpoint-6000.zip')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k7FVxMA7KH9Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733001268154,"user_tz":480,"elapsed":11426,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"7dd331b8-36f5-4887-a08a-6d944b544f7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# prompt: transfer the checkpoint-6000.zip created to the google drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!cp best_model_distilbert_python.zip \"/content/drive/MyDrive/FYP/Revised/Models/DistilBert_Python/\"\n","!cp best_model_distilbert_python_tokenizer.zip \"/content/drive/MyDrive/FYP/Revised/Models/DistilBert_Python_Tokenizer/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tl-1xZApMY_v"},"outputs":[],"source":["# Save the tokenizer\n","# tokenizer.save_pretrained('/content/drive/MyDrive/FYP/Revised/Models/DistilBert_Python_Tokenizer/')"]},{"cell_type":"markdown","metadata":{"id":"x4H49PZzDpQd"},"source":["# **Load and Test Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c4WNjTO2qKMC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733001270657,"user_tz":480,"elapsed":2507,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"2101194d-fc25-4b0c-9f5c-27cadc37daae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uOAXyquCMPJ-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733001816191,"user_tz":480,"elapsed":545544,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"01a52ef8-1345-4668-ed2f-b26abbf0aa7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/MyDrive/FYP/Revised/Models/DistilBert_Python/best_model_distilbert_python.zip\n","replace ./best_model_distilbert_python/pytorch_model.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n","  inflating: ./best_model_distilbert_python/pytorch_model.bin  \n","  inflating: ./best_model_distilbert_python/training_args.bin  \n","  inflating: ./best_model_distilbert_python/config.json  \n","Archive:  /content/drive/MyDrive/FYP/Revised/Models/DistilBert_Python_Tokenizer/best_model_distilbert_python_tokenizer.zip\n","replace ./best_model_distilbert_python_tokenizer/tokenizer_config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n","  inflating: ./best_model_distilbert_python_tokenizer/tokenizer_config.json  \n","  inflating: ./best_model_distilbert_python_tokenizer/special_tokens_map.json  \n","  inflating: ./best_model_distilbert_python_tokenizer/vocab.txt  \n"]}],"source":["from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n","\n","# Replace 'path/to/checkpoint-folder' with the actual path to your checkpoint folder.\n","model_folder = '/content/drive/MyDrive/FYP/Revised/Models/DistilBert_Python/'\n","tokenizer_folder = '/content/drive/MyDrive/FYP/Revised/Models/DistilBert_Python_Tokenizer/'\n","\n","!unzip '/content/drive/MyDrive/FYP/Revised/Models/DistilBert_Python/best_model_distilbert_python.zip' -d './'\n","!unzip '/content/drive/MyDrive/FYP/Revised/Models/DistilBert_Python_Tokenizer/best_model_distilbert_python_tokenizer.zip' -d './'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6N76rCMSrrz5"},"outputs":[],"source":["best_model_distilbert_python = 'best_model_distilbert_python'\n","best_model_distilbert_python_tokenizer = 'best_model_distilbert_python_tokenizer'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bdm4d_X0pO3K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733001847133,"user_tz":480,"elapsed":898,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"0862b6e4-b170-4273-f24e-beb73d553726"},"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file best_model_distilbert_python/config.json\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForSequenceClassification\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4\n","  },\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"problem_type\": \"multi_label_classification\",\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file best_model_distilbert_python/pytorch_model.bin\n","All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n","\n","All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at best_model_distilbert_python.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n","Didn't find file best_model_distilbert_python_tokenizer/added_tokens.json. We won't load it.\n","loading file best_model_distilbert_python_tokenizer/vocab.txt\n","loading file None\n","loading file best_model_distilbert_python_tokenizer/special_tokens_map.json\n","loading file best_model_distilbert_python_tokenizer/tokenizer_config.json\n"]},{"output_type":"execute_result","data":{"text/plain":["SequenceClassifierOutput(loss=None, logits=tensor([[-10.4652, -11.5933,   6.8568,  -9.4027, -12.2137]],\n","       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"]},"metadata":{},"execution_count":28}],"source":["# Load the model and tokenizer from the checkpoint\n","model = DistilBertForSequenceClassification.from_pretrained(best_model_distilbert_python)\n","tokenizer = DistilBertTokenizer.from_pretrained(best_model_distilbert_python_tokenizer)\n","\n","text = \"what is this?\"\n","encoded_input = tokenizer(text, return_tensors='pt')\n","output = model(**encoded_input)\n","output"]},{"cell_type":"code","source":["logits = output.logits\n","\n","# Apply sigmoid to convert logits to probabilities\n","probabilities = torch.sigmoid(logits)\n","\n","# Define a threshold to determine if a class is positive\n","threshold = 0.5\n","predicted_indices = (probabilities > threshold).nonzero(as_tuple=True)[1]\n","\n","# Convert indices to a list for output\n","predicted_classes = (predicted_indices + 1).tolist()\n","\n","# Format the output to display classes\n","if len(predicted_classes) > 0:\n","    predicted_classes_str = \", \".join(map(str, predicted_classes))\n","    print(f\"Predicted class/es: {predicted_classes_str}\")\n","else:\n","    print(\"No positive classes predicted.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-X1P_vK_q5pF","executionInfo":{"status":"ok","timestamp":1733001852688,"user_tz":480,"elapsed":415,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"2d0ca773-e691-477e-cbc2-0160dd67789f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class/es: 3\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e9YFZQfdts-W"},"outputs":[],"source":["# import torch\n","\n","# # Logits from the model output\n","# logits =  output.logits #torch.tensor([[-17.5500, -13.8129, 9.7042, -16.6331, -6.6066]])\n","\n","# # Get the index of the highest score\n","# predicted_class = ((torch.argmax(logits, dim=1).item()) + 1)\n","\n","# print(f\"Predicted class: {predicted_class}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0ab2ceb1697e450cb8646889009fee22":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_960b72af86b5484eb4375cf87bd4acde","IPY_MODEL_ccda7f0cef0449ff84cf8afceffc9242","IPY_MODEL_21336c5a9b874cf8ae29763a230bfc98"],"layout":"IPY_MODEL_c81ed4186cca42cfb5ce93890e09566c"}},"960b72af86b5484eb4375cf87bd4acde":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_056146ebfb2f40fcacd4a39d9555e94e","placeholder":"​","style":"IPY_MODEL_2cf8ed9c32dd4c66bef892d77d7f0b93","value":"Downloading: 100%"}},"ccda7f0cef0449ff84cf8afceffc9242":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_241fb7617b714cd7b9321534e798031a","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6907cc95f03c46959312999363c05418","value":231508}},"21336c5a9b874cf8ae29763a230bfc98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_acdce59e02734e0f888a92ca251a9943","placeholder":"​","style":"IPY_MODEL_69d309eb596a45ff998a185886e1a4a1","value":" 226k/226k [00:00&lt;00:00, 3.04MB/s]"}},"c81ed4186cca42cfb5ce93890e09566c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"056146ebfb2f40fcacd4a39d9555e94e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cf8ed9c32dd4c66bef892d77d7f0b93":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"241fb7617b714cd7b9321534e798031a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6907cc95f03c46959312999363c05418":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"acdce59e02734e0f888a92ca251a9943":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69d309eb596a45ff998a185886e1a4a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83149b6ca8014850b1563fd9932bf778":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cac53db9ad19434399200a3e8d8e99ae","IPY_MODEL_c06cea1e5c744d70a57b7eff757e4752","IPY_MODEL_4e53f56b4e6c413b96ca57f1d309f80b"],"layout":"IPY_MODEL_ead8f92861334b7a93f8ab954ad3b567"}},"cac53db9ad19434399200a3e8d8e99ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eaaa04a5683f41e7b64291e31ecc2d91","placeholder":"​","style":"IPY_MODEL_c706b5daae8e4583a020c6ec51206fb5","value":"Downloading: 100%"}},"c06cea1e5c744d70a57b7eff757e4752":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a68a106f5d245f3a08174ac8e876989","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_868a377eb5b24a77af946818471c1b0d","value":48}},"4e53f56b4e6c413b96ca57f1d309f80b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8624f5b75b004effa4a8d60900a3813b","placeholder":"​","style":"IPY_MODEL_ae3a5a4e9e324a18b3642b83b73c10b0","value":" 48.0/48.0 [00:00&lt;00:00, 828B/s]"}},"ead8f92861334b7a93f8ab954ad3b567":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaaa04a5683f41e7b64291e31ecc2d91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c706b5daae8e4583a020c6ec51206fb5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a68a106f5d245f3a08174ac8e876989":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"868a377eb5b24a77af946818471c1b0d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8624f5b75b004effa4a8d60900a3813b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae3a5a4e9e324a18b3642b83b73c10b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"552afc9df70c486ca10067b436f833d9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0c92f4a4525045a5a56218cd7ba0fb5f","IPY_MODEL_8e98d850c5454d988d9e56dd0d5936f0","IPY_MODEL_f80989f64e674ddeb854aa91afd81cdf"],"layout":"IPY_MODEL_95bda1e2935f467aa438ea5f2d63d365"}},"0c92f4a4525045a5a56218cd7ba0fb5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ae8e02b94c64c5b81bf3d22cd09605c","placeholder":"​","style":"IPY_MODEL_7ebe9c963cbc4c8395237e0ecb96af76","value":"Downloading: 100%"}},"8e98d850c5454d988d9e56dd0d5936f0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf5cdeef18d54e67ad97a0f06d177745","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_345a3cb273494f348b33a00064dda8a0","value":483}},"f80989f64e674ddeb854aa91afd81cdf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5cd5fc2b1744223aa2fe625f8792655","placeholder":"​","style":"IPY_MODEL_84c1d2dd2dbe4d658bd2ce82f56f3db0","value":" 483/483 [00:00&lt;00:00, 9.10kB/s]"}},"95bda1e2935f467aa438ea5f2d63d365":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ae8e02b94c64c5b81bf3d22cd09605c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ebe9c963cbc4c8395237e0ecb96af76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf5cdeef18d54e67ad97a0f06d177745":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"345a3cb273494f348b33a00064dda8a0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f5cd5fc2b1744223aa2fe625f8792655":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84c1d2dd2dbe4d658bd2ce82f56f3db0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c55c6c550098477581bb3eb25ef04732":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_705af00f1ca542faa4fd7a5a49f13002","IPY_MODEL_9a1df43db8da46fd91a1c48f864a545f","IPY_MODEL_d0f4df56fc834aeeb949f0db8dca7cd8"],"layout":"IPY_MODEL_4208ea0aab64466d836ddacd1baeb4cc"}},"705af00f1ca542faa4fd7a5a49f13002":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e42e888200d24f92bbca9ca338f6f2b4","placeholder":"​","style":"IPY_MODEL_4a81d0575a744438b68eeb03b38c2265","value":"Downloading: 100%"}},"9a1df43db8da46fd91a1c48f864a545f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd0235f4b9b546e88bb1c4c7f4cd08e8","max":267967963,"min":0,"orientation":"horizontal","style":"IPY_MODEL_24bcd5069e0845ca88aabeb505d4ad8b","value":267967963}},"d0f4df56fc834aeeb949f0db8dca7cd8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e8417d3cce6422781a104dae13234c8","placeholder":"​","style":"IPY_MODEL_2e5c3711ee43422088680845b89453c5","value":" 256M/256M [00:12&lt;00:00, 45.3MB/s]"}},"4208ea0aab64466d836ddacd1baeb4cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e42e888200d24f92bbca9ca338f6f2b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a81d0575a744438b68eeb03b38c2265":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd0235f4b9b546e88bb1c4c7f4cd08e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24bcd5069e0845ca88aabeb505d4ad8b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4e8417d3cce6422781a104dae13234c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e5c3711ee43422088680845b89453c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}