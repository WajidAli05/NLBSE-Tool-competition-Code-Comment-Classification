{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ahiO5v1-U-Bx","outputId":"369a38d2-b90e-4032-e770-58a0241ac792","collapsed":true,"executionInfo":{"status":"ok","timestamp":1733247373211,"user_tz":480,"elapsed":28450,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sentence-transformers 3.2.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.17.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip -q install transformers==4.17\n","!pip -q install optuna"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"hJqdqTUdVLdQ","executionInfo":{"status":"ok","timestamp":1733247397845,"user_tz":480,"elapsed":24644,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}}},"outputs":[],"source":["from transformers import Trainer, TrainingArguments, RobertaTokenizer, RobertaModel, RobertaForSequenceClassification, AutoTokenizer\n","import torch\n","import pandas as pd\n","import nltk\n","import re\n","import ast\n","import numpy as np\n","from torch.utils.data import Dataset\n","from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_fscore_support, accuracy_score\n","from sklearn.model_selection import train_test_split\n","import torch.nn as nn\n","import optuna\n","import time"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":502},"id":"A2X7abTWVVoT","outputId":"f85aacc3-80c3-4ee5-82b1-30c6a0d258fc","executionInfo":{"status":"ok","timestamp":1733247405619,"user_tz":480,"elapsed":7800,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n","Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n","You are not authenticated with the Hugging Face Hub in this notebook.\n","If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["   index        class                                   comment_sentence  \\\n","0      1  AccessMixin                                     functionality.   \n","1      8       Atomic  when it s used as a decorator, call wraps the ...   \n","2     10       Atomic  when it s used as a context manager, enter cre...   \n","3     12       Atomic  exit commits the transaction or releases the s...   \n","4     14       Atomic  it s possible to disable the creation of savep...   \n","\n","   partition                                              combo  \\\n","0          0                       functionality. | AccessMixin   \n","1          0  when it s used as a decorator, call wraps the ...   \n","2          0  when it s used as a context manager, enter cre...   \n","3          0  exit commits the transaction or releases the s...   \n","4          0  it s possible to disable the creation of savep...   \n","\n","            labels  \n","0  [0, 0, 0, 0, 1]  \n","1  [1, 0, 0, 0, 0]  \n","2  [1, 0, 0, 0, 0]  \n","3  [1, 0, 0, 0, 0]  \n","4  [1, 0, 0, 0, 0]  "],"text/html":["\n","  <div id=\"df-836a4bdb-da8e-443b-aee0-09986fcfccb2\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>class</th>\n","      <th>comment_sentence</th>\n","      <th>partition</th>\n","      <th>combo</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>AccessMixin</td>\n","      <td>functionality.</td>\n","      <td>0</td>\n","      <td>functionality. | AccessMixin</td>\n","      <td>[0, 0, 0, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8</td>\n","      <td>Atomic</td>\n","      <td>when it s used as a decorator, call wraps the ...</td>\n","      <td>0</td>\n","      <td>when it s used as a decorator, call wraps the ...</td>\n","      <td>[1, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10</td>\n","      <td>Atomic</td>\n","      <td>when it s used as a context manager, enter cre...</td>\n","      <td>0</td>\n","      <td>when it s used as a context manager, enter cre...</td>\n","      <td>[1, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>12</td>\n","      <td>Atomic</td>\n","      <td>exit commits the transaction or releases the s...</td>\n","      <td>0</td>\n","      <td>exit commits the transaction or releases the s...</td>\n","      <td>[1, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14</td>\n","      <td>Atomic</td>\n","      <td>it s possible to disable the creation of savep...</td>\n","      <td>0</td>\n","      <td>it s possible to disable the creation of savep...</td>\n","      <td>[1, 0, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-836a4bdb-da8e-443b-aee0-09986fcfccb2')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-836a4bdb-da8e-443b-aee0-09986fcfccb2 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-836a4bdb-da8e-443b-aee0-09986fcfccb2');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c0e09eb0-5eaa-4480-97f1-ccc7ced534b1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c0e09eb0-5eaa-4480-97f1-ccc7ced534b1')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c0e09eb0-5eaa-4480-97f1-ccc7ced534b1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(test_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 1,\n        \"max\": 14,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          8,\n          14,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Atomic\",\n          \"AccessMixin\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comment_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"when it s used as a decorator, call wraps the execution of the\",\n          \"it s possible to disable the creation of savepoints if the goal is to\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"partition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"combo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"when it s used as a decorator, call wraps the execution of the | Atomic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["   index           class                                   comment_sentence  \\\n","0      0     AccessMixin  abstract cbv mixin that gives access mixins th...   \n","1      2  AmbiguityError     more than one migration matches a name prefix.   \n","2      3   AppConfigStub                              stub of an appconfig.   \n","3      4   AppConfigStub        only provides a label and a dict of models.   \n","4      5         Archive  the external api class that encapsulates an ar...   \n","\n","   partition                                              combo  \\\n","0          1  abstract cbv mixin that gives access mixins th...   \n","1          1  more than one migration matches a name prefix....   \n","2          1              stub of an appconfig. | AppConfigStub   \n","3          1  only provides a label and a dict of models. | ...   \n","4          1  the external api class that encapsulates an ar...   \n","\n","            labels  \n","0  [0, 0, 0, 0, 1]  \n","1  [0, 0, 0, 0, 1]  \n","2  [0, 0, 0, 0, 1]  \n","3  [0, 1, 0, 0, 0]  \n","4  [0, 0, 1, 0, 1]  "],"text/html":["\n","  <div id=\"df-49610763-2702-491a-8ee6-f945bf75b3fc\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>class</th>\n","      <th>comment_sentence</th>\n","      <th>partition</th>\n","      <th>combo</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>AccessMixin</td>\n","      <td>abstract cbv mixin that gives access mixins th...</td>\n","      <td>1</td>\n","      <td>abstract cbv mixin that gives access mixins th...</td>\n","      <td>[0, 0, 0, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>AmbiguityError</td>\n","      <td>more than one migration matches a name prefix.</td>\n","      <td>1</td>\n","      <td>more than one migration matches a name prefix....</td>\n","      <td>[0, 0, 0, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>AppConfigStub</td>\n","      <td>stub of an appconfig.</td>\n","      <td>1</td>\n","      <td>stub of an appconfig. | AppConfigStub</td>\n","      <td>[0, 0, 0, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>AppConfigStub</td>\n","      <td>only provides a label and a dict of models.</td>\n","      <td>1</td>\n","      <td>only provides a label and a dict of models. | ...</td>\n","      <td>[0, 1, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Archive</td>\n","      <td>the external api class that encapsulates an ar...</td>\n","      <td>1</td>\n","      <td>the external api class that encapsulates an ar...</td>\n","      <td>[0, 0, 1, 0, 1]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49610763-2702-491a-8ee6-f945bf75b3fc')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-49610763-2702-491a-8ee6-f945bf75b3fc button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-49610763-2702-491a-8ee6-f945bf75b3fc');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-3f22322d-72ef-46a1-b96c-909a86139bb9\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3f22322d-72ef-46a1-b96c-909a86139bb9')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-3f22322d-72ef-46a1-b96c-909a86139bb9 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(test_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"AmbiguityError\",\n          \"Archive\",\n          \"AccessMixin\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comment_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"more than one migration matches a name prefix.\",\n          \"the external api class that encapsulates an archive implementation.\",\n          \"stub of an appconfig.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"partition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"combo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"more than one migration matches a name prefix. | AmbiguityError\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}],"source":["splits = {'python_train': 'data/python_train-00000-of-00001.parquet', 'python_test': 'data/python_test-00000-of-00001.parquet'}\n","train_df = pd.read_parquet(\"hf://datasets/NLBSE/nlbse25-code-comment-classification/\" + splits[\"python_train\"])\n","test_df = pd.read_parquet(\"hf://datasets/NLBSE/nlbse25-code-comment-classification/\" + splits[\"python_test\"])\n","\n","display(train_df.head())\n","display(test_df.head())"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Kb64vwSsXAef","colab":{"base_uri":"https://localhost:8080/","height":465},"outputId":"2e4c57f9-9d53-41cb-b921-eee2962ef331","executionInfo":{"status":"ok","timestamp":1733247405620,"user_tz":480,"elapsed":72,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-df4392ae2e99>:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n","  train_str_df = train_df[[\"class\", \"comment_sentence\", \"combo\"]].applymap(\n","<ipython-input-4-df4392ae2e99>:12: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n","  test_str_df = test_df[[\"class\", \"comment_sentence\", \"combo\"]].applymap(\n"]},{"output_type":"display_data","data":{"text/plain":["   index        class                                   comment_sentence  \\\n","0      1  accessmixin                                     functionality.   \n","1      8       atomic  when it s used as a decorator, call wraps the ...   \n","2     10       atomic  when it s used as a context manager, enter cre...   \n","3     12       atomic  exit commits the transaction or releases the s...   \n","4     14       atomic  it s possible to disable the creation of savep...   \n","\n","   partition                                              combo  \\\n","0          0                        functionality | accessmixin   \n","1          0  when it s used as a decorator call wraps the e...   \n","2          0  when it s used as a context manager enter crea...   \n","3          0  exit commits the transaction or releases the s...   \n","4          0  it s possible to disable the creation of savep...   \n","\n","            labels  \n","0  [0, 0, 0, 0, 1]  \n","1  [1, 0, 0, 0, 0]  \n","2  [1, 0, 0, 0, 0]  \n","3  [1, 0, 0, 0, 0]  \n","4  [1, 0, 0, 0, 0]  "],"text/html":["\n","  <div id=\"df-05b1a55e-bbd5-4a8f-9501-dcde55a3414b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>class</th>\n","      <th>comment_sentence</th>\n","      <th>partition</th>\n","      <th>combo</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>accessmixin</td>\n","      <td>functionality.</td>\n","      <td>0</td>\n","      <td>functionality | accessmixin</td>\n","      <td>[0, 0, 0, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8</td>\n","      <td>atomic</td>\n","      <td>when it s used as a decorator, call wraps the ...</td>\n","      <td>0</td>\n","      <td>when it s used as a decorator call wraps the e...</td>\n","      <td>[1, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10</td>\n","      <td>atomic</td>\n","      <td>when it s used as a context manager, enter cre...</td>\n","      <td>0</td>\n","      <td>when it s used as a context manager enter crea...</td>\n","      <td>[1, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>12</td>\n","      <td>atomic</td>\n","      <td>exit commits the transaction or releases the s...</td>\n","      <td>0</td>\n","      <td>exit commits the transaction or releases the s...</td>\n","      <td>[1, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14</td>\n","      <td>atomic</td>\n","      <td>it s possible to disable the creation of savep...</td>\n","      <td>0</td>\n","      <td>it s possible to disable the creation of savep...</td>\n","      <td>[1, 0, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05b1a55e-bbd5-4a8f-9501-dcde55a3414b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-05b1a55e-bbd5-4a8f-9501-dcde55a3414b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-05b1a55e-bbd5-4a8f-9501-dcde55a3414b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-796e1fd5-6d15-4da2-a8b7-157c7cccd8af\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-796e1fd5-6d15-4da2-a8b7-157c7cccd8af')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-796e1fd5-6d15-4da2-a8b7-157c7cccd8af button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(test_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 1,\n        \"max\": 14,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          8,\n          14,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"atomic\",\n          \"accessmixin\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comment_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"when it s used as a decorator, call wraps the execution of the\",\n          \"it s possible to disable the creation of savepoints if the goal is to\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"partition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"combo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"when it s used as a decorator call wraps the execution of the | atomic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["   index           class                                   comment_sentence  \\\n","0      0     accessmixin  abstract cbv mixin that gives access mixins th...   \n","1      2  ambiguityerror     more than one migration matches a name prefix.   \n","2      3   appconfigstub                              stub of an appconfig.   \n","3      4   appconfigstub        only provides a label and a dict of models.   \n","4      5         archive  the external api class that encapsulates an ar...   \n","\n","   partition                                              combo  \\\n","0          1  abstract cbv mixin that gives access mixins th...   \n","1          1  more than one migration matches a name prefix ...   \n","2          1               stub of an appconfig | appconfigstub   \n","3          1  only provides a label and a dict of models | a...   \n","4          1  the external api class that encapsulates an ar...   \n","\n","            labels  \n","0  [0, 0, 0, 0, 1]  \n","1  [0, 0, 0, 0, 1]  \n","2  [0, 0, 0, 0, 1]  \n","3  [0, 1, 0, 0, 0]  \n","4  [0, 0, 1, 0, 1]  "],"text/html":["\n","  <div id=\"df-fff93659-edc8-4660-9204-e6b1e961d5c3\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>class</th>\n","      <th>comment_sentence</th>\n","      <th>partition</th>\n","      <th>combo</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>accessmixin</td>\n","      <td>abstract cbv mixin that gives access mixins th...</td>\n","      <td>1</td>\n","      <td>abstract cbv mixin that gives access mixins th...</td>\n","      <td>[0, 0, 0, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>ambiguityerror</td>\n","      <td>more than one migration matches a name prefix.</td>\n","      <td>1</td>\n","      <td>more than one migration matches a name prefix ...</td>\n","      <td>[0, 0, 0, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>appconfigstub</td>\n","      <td>stub of an appconfig.</td>\n","      <td>1</td>\n","      <td>stub of an appconfig | appconfigstub</td>\n","      <td>[0, 0, 0, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>appconfigstub</td>\n","      <td>only provides a label and a dict of models.</td>\n","      <td>1</td>\n","      <td>only provides a label and a dict of models | a...</td>\n","      <td>[0, 1, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>archive</td>\n","      <td>the external api class that encapsulates an ar...</td>\n","      <td>1</td>\n","      <td>the external api class that encapsulates an ar...</td>\n","      <td>[0, 0, 1, 0, 1]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fff93659-edc8-4660-9204-e6b1e961d5c3')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fff93659-edc8-4660-9204-e6b1e961d5c3 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fff93659-edc8-4660-9204-e6b1e961d5c3');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-80e9f2ca-944e-407b-a81e-0c95fc4a5973\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-80e9f2ca-944e-407b-a81e-0c95fc4a5973')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-80e9f2ca-944e-407b-a81e-0c95fc4a5973 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(test_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"ambiguityerror\",\n          \"archive\",\n          \"accessmixin\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comment_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"more than one migration matches a name prefix.\",\n          \"the external api class that encapsulates an archive implementation.\",\n          \"stub of an appconfig.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"partition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"combo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"more than one migration matches a name prefix | ambiguityerror\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}],"source":["def remove_punctuation_except_pipe(text):\n","    return re.sub(r\"[^\\w\\s\\|]\", \"\", text)\n","\n","# Apply the function to the 'combo' column\n","train_df['combo'] = train_df['combo'].apply(remove_punctuation_except_pipe)\n","test_df['combo'] = test_df['combo'].apply(remove_punctuation_except_pipe)\n","\n","# Convert data to lowercase\n","train_str_df = train_df[[\"class\", \"comment_sentence\", \"combo\"]].applymap(\n","    lambda x: x.lower() if isinstance(x, str) else str(x)\n",")\n","test_str_df = test_df[[\"class\", \"comment_sentence\", \"combo\"]].applymap(\n","    lambda x: x.lower() if isinstance(x, str) else str(x)\n",")\n","\n","train_df[[\"class\", \"comment_sentence\", \"combo\"]] = train_str_df[[\"class\", \"comment_sentence\", \"combo\"]]\n","test_df[[\"class\", \"comment_sentence\", \"combo\"]] = test_str_df[[\"class\", \"comment_sentence\", \"combo\"]]\n","\n","display(train_df.head())\n","display(test_df.head())"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"tZx55HL8XEbr","executionInfo":{"status":"ok","timestamp":1733247405621,"user_tz":480,"elapsed":61,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}}},"outputs":[],"source":["X = list(train_df['combo'])\n","y = list(train_df['labels'])\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":319,"referenced_widgets":["4eea98cb69e348ebb7be176f806ecb72","e67ac4c21bea4f79b61624b76b1b7f3a","4bb733a9c8cd49689425f3018ffb56a3","78616e4a5ee949d7800eb7a7b043bab3","e9335132f9af4d618d76531cc5f47300","43b25bd8319f4774bdc294f1bab701f9","6889f2d376294a96b79d795a2c78b4ad","51ce69ea5c9f492dbe6f090002f4f965","0dd3a78fa9fc49aaa3b15a0b0f5daf56","ea21c46c6a844d97a6e760b5ccdcca00","b38d93f192bd403cacbc2c73df9e65d9","4db42af9b52c40a08950bc72078d939b","4215040808734b669b35ae35b3a083dd","101926200ced4faab847bfe07e782abf","908edfe0cc1c4a7fb5c5cf6816779d33","97c2a3925600434cb52d0940e5bddbc9","c7419aded3864868b8409bc8bad06d5d","b50f5b012d7548938a816b5dc7b381b3","d461892f155a4907b3144e7f8d8cc395","9a30f7f76ecc4590ba23f3a6f1020d9b","429fcb083ed54ce4962c57436ea115f0","53290cf276c141018b4919b0cd0de36e","ed3f86a3c48f491c9afc0de922b1450a","652684cbea6c46249bc13fc205863275","7fd5aaf4eceb408ca2f0d3be11db4b8a","b6e2cbd292e9448e87e669d81b29a51e","99a681eb91c74504b0fd76d2b4768304","230ddac6564e47348ef69b82319c7527","c94588e3b36445a298331318668b6b64","fc1272bef6b04f57865876847e5a6255","6f6b8ddfa3674864848ec5b6ffe7ef55","72fb81e0bc26498d88aac9f3fdc1ea15","be747aaaf11a490ab7d977eb70509660","6ce2e5a043a84783a3351fe554f17740","eeb11a6a170f4d659c65b38efa0f6865","40396ed0e8a14a35911b68ba6ee1bbd3","bb7fa9cab328430282673698b6429f2a","52e7f19adb3946c7ab5480ab09f5a84c","ef5c32db54ad4bfaa7be666681052d61","093e6ed0e352454b9a4f2162599825d3","80a57ca7356c40b9b170288add8b4438","c0a2f71013cd43e7a4b16aa6dd82d440","138f98dc40a34074a08c871d9ab8dfb8","4608f1703df04279aafc3860754db6a9","31af92439d84422daaab2522aeb36b3f","9142f7fec1924a8b86483655799fac46","5d8ad01ba7634fe29bbfb1d7a208fc37","945137af87fd46698bf36ae53a4c3e49","886175de49b647088ca4e55dcaf93dfa","d654c0a7c55547289ed29662eae56bfa","0b98732c7bed45c6be76676aed75ab90","0931bee84d5d46119aa200decd677511","68131eb5cdcd4f81ab1e457c233a0003","6900457844774643849d5edf89194f8d","875b344e82284214b34e97917dc89b46"]},"id":"yjykL1KCZwxN","outputId":"29b82981-e208-4804-d1db-45393fe6ef6f","executionInfo":{"status":"ok","timestamp":1733247428858,"user_tz":480,"elapsed":23297,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4eea98cb69e348ebb7be176f806ecb72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4db42af9b52c40a08950bc72078d939b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed3f86a3c48f491c9afc0de922b1450a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ce2e5a043a84783a3351fe554f17740"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31af92439d84422daaab2522aeb36b3f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:1439: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(resolved_archive_file, map_location=\"cpu\")\n","Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=5)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"fPuB7b6UbOB3","executionInfo":{"status":"ok","timestamp":1733247428859,"user_tz":480,"elapsed":45,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}}},"outputs":[],"source":["class TextClassificationDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, device=\"cpu\"):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.device = device\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, index):\n","        text = self.texts[index]\n","        label = self.labels[index]\n","\n","        encoded_text = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=256,\n","            padding='max_length',\n","            truncation=True,\n","            return_token_type_ids=False,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","        )\n","\n","        input_ids = encoded_text['input_ids'].squeeze().to(self.device)\n","        attention_mask = encoded_text['attention_mask'].squeeze().to(self.device)\n","        label = torch.tensor(label, dtype=torch.float).to(self.device)\n","\n","        return {\n","            'input_ids': input_ids,\n","            'attention_mask': attention_mask,\n","            'labels': label\n","        }\n","\n","train_dataset = TextClassificationDataset(X_train, y_train, tokenizer)\n","eval_dataset = TextClassificationDataset(X_val, y_val, tokenizer)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"nW_lCG9IbnPm","executionInfo":{"status":"ok","timestamp":1733247428860,"user_tz":480,"elapsed":44,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}}},"outputs":[],"source":["# class OneHotTrainer(Trainer):\n","#     def compute_loss(self, model, inputs, return_outputs=False):\n","#         labels = inputs.get(\"labels\")\n","#         outputs = model(**inputs)\n","#         logits = outputs.get(\"logits\")\n","\n","#         # Use BCEWithLogitsLoss for multi-label classification\n","#         loss_fct = nn.BCEWithLogitsLoss()\n","#         loss = loss_fct(logits, labels.float())\n","\n","#         return (loss, outputs) if return_outputs else loss\n","\n","class OneHotTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        labels = inputs.get(\"labels\")\n","        # Remove 'labels' from inputs before passing to model\n","        model_inputs = {k: v for k, v in inputs.items() if k != \"labels\"}\n","        outputs = model(**model_inputs)  # Pass only the required inputs to the model\n","        logits = outputs.get(\"logits\")\n","\n","        if logits is None:\n","            # Handle the case where logits are missing, e.g., raise an exception or return a default loss\n","            raise ValueError(\"Logits are missing from the model output.\")  # Or return a default loss\n","\n","        # Use BCEWithLogitsLoss for multi-label classification\n","        loss_fct = nn.BCEWithLogitsLoss()\n","        loss = loss_fct(logits, labels.float())\n","\n","        return (loss, outputs) if return_outputs else loss"]},{"cell_type":"code","source":["def compute_metrics(pred):\n","    logits = pred.predictions\n","    preds = (logits > 0).astype(int)\n","\n","    labels = pred.label_ids\n","\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n","    accuracy = (preds == labels).mean()\n","\n","    return {\n","        'accuracy': accuracy,\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1\n","    }\n","\n","\n","# Optional compute_metrics function to get the accuracy, precision, recall, f1 for each of the individual labels\n","# without averaging them\n","\n","# Function for individual metrics of each category\n","# from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","# def compute_metrics(pred):\n","#     # Get predictions and apply sigmoid to get probabilities\n","#     logits = pred.predictions\n","#     preds = (logits > 0).astype(int)  # Threshold at 0 to get binary predictions\n","\n","#     # Get true labels\n","#     labels = pred.label_ids\n","\n","#     # Calculate precision, recall, and f1-score for each label without averaging\n","#     precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=None)\n","#     # Calculate accuracy per label (how many times each label is correctly predicted)\n","#     accuracy_per_label = (preds == labels).mean(axis=0)\n","\n","#     # Prepare a dictionary to store metrics per category\n","#     metrics = {\n","#         'accuracy_per_label': accuracy_per_label,\n","#         'precision_per_label': precision,\n","#         'recall_per_label': recall,\n","#         'f1_per_label': f1\n","#     }\n","\n","#     # Optionally, if you want to calculate an overall accuracy:\n","#     overall_accuracy = (preds == labels).all(axis=1).mean()  # This gives the fraction of samples where all labels are correctly predicted\n","#     metrics['overall_accuracy'] = overall_accuracy\n","\n","#     return metrics"],"metadata":{"id":"bu8oOgzmZqAv","executionInfo":{"status":"ok","timestamp":1733247428860,"user_tz":480,"elapsed":42,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","execution_count":10,"metadata":{"id":"hJHqn0cbd2mj","executionInfo":{"status":"ok","timestamp":1733247428861,"user_tz":480,"elapsed":42,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}}},"outputs":[],"source":["def objective(trial):\n","    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","    batch_size = trial.suggest_categorical(\"batch_size\", [4, 8, 16])\n","    num_train_epochs = trial.suggest_int(\"num_train_epochs\", 3, 10)\n","    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","\n","    training_args = TrainingArguments(\n","        output_dir=\"./results\",\n","        num_train_epochs=num_train_epochs,\n","        per_device_train_batch_size=batch_size,\n","        per_device_eval_batch_size=batch_size * 2,\n","        warmup_steps=10,\n","        weight_decay=weight_decay,\n","        evaluation_strategy=\"epoch\",\n","        learning_rate=learning_rate,\n","        gradient_accumulation_steps=2,\n","        report_to=\"none\",\n","    )\n","\n","    trainer = OneHotTrainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=train_dataset,\n","        eval_dataset=eval_dataset,\n","        compute_metrics=compute_metrics,\n","    )\n","\n","    trainer.train()\n","    eval_results = trainer.evaluate()\n","\n","    return eval_results[\"eval_f1\"]"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"wJ5YN2fBjTTD","outputId":"e1cc5f86-82f2-4e08-b171-b3ccee46c88d","executionInfo":{"status":"ok","timestamp":1733250928747,"user_tz":480,"elapsed":3499926,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-12-03 17:37:06,709] A new study created in memory with name: no-name-acd808ba-c1ce-4ed7-af17-e69c95df869d\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 141\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [141/141 03:08, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.480986</td>\n","      <td>0.787798</td>\n","      <td>0.242640</td>\n","      <td>0.038741</td>\n","      <td>0.066814</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.403726</td>\n","      <td>0.843501</td>\n","      <td>0.609820</td>\n","      <td>0.377724</td>\n","      <td>0.454801</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.382152</td>\n","      <td>0.851989</td>\n","      <td>0.574094</td>\n","      <td>0.460048</td>\n","      <td>0.508127</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12/12 00:04]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","[I 2024-12-03 17:40:30,554] Trial 0 finished with value: 0.5081273306161127 and parameters: {'learning_rate': 3.402796222957594e-05, 'batch_size': 16, 'num_train_epochs': 3, 'weight_decay': 0.011024836319189686}. Best is trial 0 with value: 0.5081273306161127.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 9\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 1692\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1692' max='1692' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1692/1692 12:43, Epoch 8/9]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.381324</td>\n","      <td>0.849867</td>\n","      <td>0.647859</td>\n","      <td>0.537530</td>\n","      <td>0.557665</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.349867</td>\n","      <td>0.862069</td>\n","      <td>0.675904</td>\n","      <td>0.542373</td>\n","      <td>0.590148</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.326100</td>\n","      <td>0.356325</td>\n","      <td>0.858886</td>\n","      <td>0.637829</td>\n","      <td>0.578692</td>\n","      <td>0.600977</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.326100</td>\n","      <td>0.351538</td>\n","      <td>0.857825</td>\n","      <td>0.639149</td>\n","      <td>0.595642</td>\n","      <td>0.616531</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.326100</td>\n","      <td>0.350883</td>\n","      <td>0.854642</td>\n","      <td>0.635721</td>\n","      <td>0.593220</td>\n","      <td>0.611737</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.262600</td>\n","      <td>0.346484</td>\n","      <td>0.862069</td>\n","      <td>0.645939</td>\n","      <td>0.600484</td>\n","      <td>0.621180</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.262600</td>\n","      <td>0.346325</td>\n","      <td>0.859416</td>\n","      <td>0.691321</td>\n","      <td>0.600484</td>\n","      <td>0.625297</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.222000</td>\n","      <td>0.352535</td>\n","      <td>0.859947</td>\n","      <td>0.733025</td>\n","      <td>0.612591</td>\n","      <td>0.624725</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.222000</td>\n","      <td>0.350289</td>\n","      <td>0.860477</td>\n","      <td>0.701647</td>\n","      <td>0.612591</td>\n","      <td>0.629043</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1500\n","Configuration saved in ./results/checkpoint-1500/config.json\n","Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [48/48 00:05]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-03 17:53:20,066] Trial 1 finished with value: 0.6290433941673135 and parameters: {'learning_rate': 4.092582638498643e-06, 'batch_size': 4, 'num_train_epochs': 9, 'weight_decay': 0.0003408051012757653}. Best is trial 1 with value: 0.6290433941673135.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 940\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [940/940 12:00, Epoch 9/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.360010</td>\n","      <td>0.858886</td>\n","      <td>0.706482</td>\n","      <td>0.600484</td>\n","      <td>0.622532</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.352208</td>\n","      <td>0.863660</td>\n","      <td>0.698619</td>\n","      <td>0.629540</td>\n","      <td>0.650717</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.357079</td>\n","      <td>0.864721</td>\n","      <td>0.714606</td>\n","      <td>0.639225</td>\n","      <td>0.662279</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.356043</td>\n","      <td>0.873740</td>\n","      <td>0.732378</td>\n","      <td>0.673123</td>\n","      <td>0.687259</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.358510</td>\n","      <td>0.866313</td>\n","      <td>0.713740</td>\n","      <td>0.658596</td>\n","      <td>0.680943</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.174700</td>\n","      <td>0.363224</td>\n","      <td>0.872149</td>\n","      <td>0.721503</td>\n","      <td>0.665860</td>\n","      <td>0.685584</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.174700</td>\n","      <td>0.362226</td>\n","      <td>0.866313</td>\n","      <td>0.698256</td>\n","      <td>0.670702</td>\n","      <td>0.682326</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.174700</td>\n","      <td>0.360049</td>\n","      <td>0.870027</td>\n","      <td>0.725107</td>\n","      <td>0.670702</td>\n","      <td>0.693166</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.174700</td>\n","      <td>0.363236</td>\n","      <td>0.873210</td>\n","      <td>0.712986</td>\n","      <td>0.692494</td>\n","      <td>0.700162</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.174700</td>\n","      <td>0.361808</td>\n","      <td>0.875332</td>\n","      <td>0.722650</td>\n","      <td>0.697337</td>\n","      <td>0.707301</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [24/24 00:04]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-03 18:05:26,463] Trial 2 finished with value: 0.7073009782235269 and parameters: {'learning_rate': 7.387467380519272e-06, 'batch_size': 8, 'num_train_epochs': 10, 'weight_decay': 0.0026305267897253183}. Best is trial 2 with value: 0.7073009782235269.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 470\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [470/470 05:45, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.393954</td>\n","      <td>0.870027</td>\n","      <td>0.721183</td>\n","      <td>0.680387</td>\n","      <td>0.694724</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.386879</td>\n","      <td>0.872149</td>\n","      <td>0.719571</td>\n","      <td>0.685230</td>\n","      <td>0.701428</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.403590</td>\n","      <td>0.872149</td>\n","      <td>0.721998</td>\n","      <td>0.690073</td>\n","      <td>0.702205</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.396500</td>\n","      <td>0.875862</td>\n","      <td>0.732599</td>\n","      <td>0.699758</td>\n","      <td>0.711083</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.397009</td>\n","      <td>0.875862</td>\n","      <td>0.725053</td>\n","      <td>0.699758</td>\n","      <td>0.710319</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [24/24 00:04]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-03 18:11:17,171] Trial 3 finished with value: 0.7103187751460976 and parameters: {'learning_rate': 7.187811270976668e-06, 'batch_size': 8, 'num_train_epochs': 5, 'weight_decay': 0.0014706433550626733}. Best is trial 3 with value: 0.7103187751460976.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 376\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='376' max='376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [376/376 04:36, Epoch 3/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.432074</td>\n","      <td>0.871088</td>\n","      <td>0.715519</td>\n","      <td>0.680387</td>\n","      <td>0.695643</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.446475</td>\n","      <td>0.871618</td>\n","      <td>0.723290</td>\n","      <td>0.694915</td>\n","      <td>0.707976</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.454819</td>\n","      <td>0.873210</td>\n","      <td>0.719892</td>\n","      <td>0.704600</td>\n","      <td>0.709915</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.458887</td>\n","      <td>0.875332</td>\n","      <td>0.727398</td>\n","      <td>0.702179</td>\n","      <td>0.713448</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [24/24 00:04]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-03 18:15:59,044] Trial 4 finished with value: 0.7134482822046609 and parameters: {'learning_rate': 1.3732135482016293e-05, 'batch_size': 8, 'num_train_epochs': 4, 'weight_decay': 0.0006272019646921947}. Best is trial 4 with value: 0.7134482822046609.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 376\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='376' max='376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [376/376 04:36, Epoch 3/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.474347</td>\n","      <td>0.867905</td>\n","      <td>0.724093</td>\n","      <td>0.709443</td>\n","      <td>0.706599</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.456128</td>\n","      <td>0.880106</td>\n","      <td>0.735422</td>\n","      <td>0.694915</td>\n","      <td>0.712162</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.472007</td>\n","      <td>0.872149</td>\n","      <td>0.734251</td>\n","      <td>0.697337</td>\n","      <td>0.706568</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.467511</td>\n","      <td>0.879045</td>\n","      <td>0.731989</td>\n","      <td>0.719128</td>\n","      <td>0.723972</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [24/24 00:04]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-03 18:20:41,728] Trial 5 finished with value: 0.7239724537261685 and parameters: {'learning_rate': 1.4359912002036424e-05, 'batch_size': 8, 'num_train_epochs': 4, 'weight_decay': 0.0002138667606988428}. Best is trial 5 with value: 0.7239724537261685.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 282\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='282' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [282/282 03:26, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.480170</td>\n","      <td>0.879045</td>\n","      <td>0.729171</td>\n","      <td>0.726392</td>\n","      <td>0.726389</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.478478</td>\n","      <td>0.878515</td>\n","      <td>0.733916</td>\n","      <td>0.714286</td>\n","      <td>0.723036</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.478133</td>\n","      <td>0.880106</td>\n","      <td>0.732901</td>\n","      <td>0.723971</td>\n","      <td>0.727370</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [24/24 00:04]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-03 18:24:13,967] Trial 6 finished with value: 0.7273703652729121 and parameters: {'learning_rate': 6.369414513935845e-06, 'batch_size': 8, 'num_train_epochs': 3, 'weight_decay': 0.0014542879427658277}. Best is trial 6 with value: 0.7273703652729121.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 282\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='282' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [282/282 03:26, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.545489</td>\n","      <td>0.871088</td>\n","      <td>0.726498</td>\n","      <td>0.692494</td>\n","      <td>0.704977</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.564925</td>\n","      <td>0.866844</td>\n","      <td>0.726497</td>\n","      <td>0.682809</td>\n","      <td>0.696630</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.536314</td>\n","      <td>0.877454</td>\n","      <td>0.728707</td>\n","      <td>0.707022</td>\n","      <td>0.717611</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [24/24 00:04]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-03 18:27:46,486] Trial 7 finished with value: 0.717610799715519 and parameters: {'learning_rate': 1.8612806545696882e-05, 'batch_size': 8, 'num_train_epochs': 3, 'weight_decay': 0.00035269096963575175}. Best is trial 6 with value: 0.7273703652729121.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 188\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='188' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [188/188 04:16, Epoch 3/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.545258</td>\n","      <td>0.876393</td>\n","      <td>0.732459</td>\n","      <td>0.704600</td>\n","      <td>0.714485</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.528388</td>\n","      <td>0.877454</td>\n","      <td>0.738585</td>\n","      <td>0.702179</td>\n","      <td>0.718309</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.525147</td>\n","      <td>0.876923</td>\n","      <td>0.725682</td>\n","      <td>0.709443</td>\n","      <td>0.717297</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.529204</td>\n","      <td>0.878515</td>\n","      <td>0.732544</td>\n","      <td>0.709443</td>\n","      <td>0.720404</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12/12 00:04]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-03 18:32:09,268] Trial 8 finished with value: 0.7204038732487624 and parameters: {'learning_rate': 2.9129784853795005e-06, 'batch_size': 16, 'num_train_epochs': 4, 'weight_decay': 0.011606996728274414}. Best is trial 6 with value: 0.7273703652729121.\n","<ipython-input-10-9265609bdcc0>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 5e-5)\n","<ipython-input-10-9265609bdcc0>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 0.1)\n","PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 141\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [141/141 03:11, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.537820</td>\n","      <td>0.875862</td>\n","      <td>0.726040</td>\n","      <td>0.709443</td>\n","      <td>0.717140</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.533898</td>\n","      <td>0.877454</td>\n","      <td>0.734875</td>\n","      <td>0.711864</td>\n","      <td>0.721565</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.531153</td>\n","      <td>0.877454</td>\n","      <td>0.736583</td>\n","      <td>0.707022</td>\n","      <td>0.720132</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12/12 00:04]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2024-12-03 18:35:27,423] Trial 9 finished with value: 0.7201320505873573 and parameters: {'learning_rate': 1.03416016002016e-06, 'batch_size': 16, 'num_train_epochs': 3, 'weight_decay': 0.0014317096033832073}. Best is trial 6 with value: 0.7273703652729121.\n"]},{"output_type":"stream","name":"stdout","text":["Best trial:\n","FrozenTrial(number=6, state=TrialState.COMPLETE, values=[0.7273703652729121], datetime_start=datetime.datetime(2024, 12, 3, 18, 20, 41, 729707), datetime_complete=datetime.datetime(2024, 12, 3, 18, 24, 13, 967669), params={'learning_rate': 6.369414513935845e-06, 'batch_size': 8, 'num_train_epochs': 3, 'weight_decay': 0.0014542879427658277}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=5e-05, log=True, low=1e-06, step=None), 'batch_size': CategoricalDistribution(choices=(4, 8, 16)), 'num_train_epochs': IntDistribution(high=10, log=False, low=3, step=1), 'weight_decay': FloatDistribution(high=0.1, log=True, low=0.0001, step=None)}, trial_id=6, value=None)\n"]}],"source":["study = optuna.create_study(direction=\"maximize\")\n","study.optimize(objective, n_trials=10)\n","\n","print(\"Best trial:\")\n","print(study.best_trial)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"pLWKONgej8cE","colab":{"base_uri":"https://localhost:8080/","height":658},"executionInfo":{"status":"ok","timestamp":1733251137967,"user_tz":480,"elapsed":209245,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"cb5b5b73-6f22-4f71-8cda-256f4e197624"},"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 1507\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 282\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='282' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [282/282 03:26, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>No log</td>\n","      <td>0.541811</td>\n","      <td>0.879045</td>\n","      <td>0.730809</td>\n","      <td>0.699758</td>\n","      <td>0.713415</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.546354</td>\n","      <td>0.872679</td>\n","      <td>0.731747</td>\n","      <td>0.694915</td>\n","      <td>0.710346</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.534776</td>\n","      <td>0.877984</td>\n","      <td>0.728530</td>\n","      <td>0.711864</td>\n","      <td>0.719443</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["<<=================Training Time================>>\n","Training time: 207.05 seconds\n","<<==============================================>>\n"]}],"source":["best_hyperparams = study.best_trial.params\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./best_results\",\n","    num_train_epochs=best_hyperparams[\"num_train_epochs\"],\n","    per_device_train_batch_size=best_hyperparams[\"batch_size\"],\n","    per_device_eval_batch_size=best_hyperparams[\"batch_size\"] * 2,\n","    learning_rate=best_hyperparams[\"learning_rate\"],\n","    weight_decay=best_hyperparams[\"weight_decay\"],\n","    warmup_steps=10,\n","    evaluation_strategy=\"epoch\",\n","    gradient_accumulation_steps=2,\n","    report_to=\"none\",\n",")\n","\n","trainer = OneHotTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics,\n",")\n","\n","start_time = time.time()\n","trainer.train()\n","end_time = time.time()\n","training_time = end_time - start_time\n","print(\"<<=================Training Time================>>\")\n","print(f\"Training time: {training_time:.2f} seconds\")\n","print(\"<<==============================================>>\")"]},{"cell_type":"code","source":["eval_results = trainer.evaluate()\n","print(eval_results)"],"metadata":{"id":"8GHL_S6Cjtqm","colab":{"base_uri":"https://localhost:8080/","height":126},"executionInfo":{"status":"ok","timestamp":1733251146296,"user_tz":480,"elapsed":8373,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"19b7de97-cf9b-4768-cf93-627d97b5cc51"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 377\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [24/24 00:04]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 0.534775972366333, 'eval_accuracy': 0.8779840848806366, 'eval_precision': 0.7285300731695988, 'eval_recall': 0.711864406779661, 'eval_f1': 0.7194425299788136, 'eval_runtime': 4.9708, 'eval_samples_per_second': 75.844, 'eval_steps_per_second': 4.828, 'epoch': 2.99}\n"]}]},{"cell_type":"code","execution_count":14,"metadata":{"id":"WduIvUWwd-4k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733251187910,"user_tz":480,"elapsed":41638,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"8a5c968e-8339-4c5f-def3-3ac151edcd66"},"outputs":[{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to ./best_model_roberta-large_python\n","Configuration saved in ./best_model_roberta-large_python/config.json\n","Model weights saved in ./best_model_roberta-large_python/pytorch_model.bin\n","tokenizer config file saved in ./best_model_roberta-large_python_tokenizer/tokenizer_config.json\n","Special tokens file saved in ./best_model_roberta-large_python_tokenizer/special_tokens_map.json\n","loading configuration file ./best_model_roberta-large_python/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file ./best_model_roberta-large_python/pytorch_model.bin\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:1439: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(resolved_archive_file, map_location=\"cpu\")\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at ./best_model_roberta-large_python.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","Didn't find file ./best_model_roberta-large_python_tokenizer/added_tokens.json. We won't load it.\n","loading file ./best_model_roberta-large_python_tokenizer/vocab.json\n","loading file ./best_model_roberta-large_python_tokenizer/merges.txt\n","loading file None\n","loading file ./best_model_roberta-large_python_tokenizer/special_tokens_map.json\n","loading file ./best_model_roberta-large_python_tokenizer/tokenizer_config.json\n"]}],"source":["!mkdir 'best_model_roberta-large_python'\n","!mkdir 'best_model_roberta-large_python_tokenizer'\n","\n","# Save model and tokenizer\n","trainer.save_model('./best_model_roberta-large_python')\n","tokenizer.save_pretrained('./best_model_roberta-large_python_tokenizer')\n","\n","# Load model and tokenizer\n","from transformers import RobertaForSequenceClassification, RobertaTokenizer\n","\n","model = RobertaForSequenceClassification.from_pretrained('./best_model_roberta-large_python')\n","tokenizer = RobertaTokenizer.from_pretrained('./best_model_roberta-large_python_tokenizer')"]},{"cell_type":"markdown","source":["## Model Testing"],"metadata":{"id":"Cs8GQ1fMHfC5"}},{"cell_type":"code","source":["X_test = list(test_df['combo'])\n","y_test = list(test_df['labels'])"],"metadata":{"id":"xbla2FVJHlJ5","executionInfo":{"status":"ok","timestamp":1733251187921,"user_tz":480,"elapsed":68,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["df_test = pd.DataFrame({\"combo\":X_test,\"labels\":y_test})\n","test_text = df_test.combo.values\n","test_label = df_test.labels.values\n","\n","print(test_label)"],"metadata":{"collapsed":true,"id":"Kyn9yo7HHrDF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733251187922,"user_tz":480,"elapsed":67,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"31773a36-57b1-4044-f332-940a211968e0"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 1, 0, 0, 0]) array([0, 0, 1, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([1, 0, 0, 1, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 1, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([0, 0, 1, 0, 0]) array([0, 0, 0, 0, 1])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 1, 0, 0]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 1, 0, 0])\n"," array([0, 0, 0, 0, 1]) array([1, 0, 0, 0, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 1, 1, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([0, 0, 1, 0, 1]) array([0, 1, 0, 0, 1]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 1, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 1, 0, 0]) array([0, 0, 1, 0, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([1, 0, 0, 0, 0]) array([0, 0, 0, 1, 0]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([1, 0, 0, 0, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 1, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([0, 0, 1, 0, 0]) array([0, 0, 1, 0, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0])\n"," array([1, 0, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([1, 0, 0, 1, 0]) array([1, 0, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 1, 0]) array([0, 1, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 0, 0, 0, 1]) array([0, 0, 1, 1, 0])\n"," array([0, 0, 1, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 0, 0, 0, 1]) array([1, 0, 0, 0, 0])\n"," array([0, 0, 1, 0, 0]) array([0, 0, 1, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 1, 0]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 1, 0, 0]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 1, 1, 0]) array([0, 0, 1, 1, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 1, 0]) array([0, 1, 0, 1, 1])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 1, 0, 0])\n"," array([0, 0, 1, 0, 0]) array([0, 1, 0, 1, 0]) array([1, 1, 0, 1, 0])\n"," array([1, 0, 1, 0, 0]) array([1, 0, 1, 0, 0]) array([1, 0, 1, 0, 0])\n"," array([0, 0, 0, 0, 1]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 1, 0, 0]) array([0, 1, 0, 0, 1]) array([0, 1, 1, 0, 0])\n"," array([0, 1, 1, 0, 0]) array([0, 0, 1, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([0, 0, 1, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([1, 0, 0, 0, 0]) array([0, 0, 0, 0, 1]) array([1, 0, 1, 0, 0])\n"," array([0, 0, 1, 0, 0]) array([0, 0, 1, 0, 0]) array([0, 0, 1, 0, 0])\n"," array([1, 0, 1, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 1, 0, 0]) array([0, 0, 1, 0, 0]) array([0, 0, 1, 1, 0])\n"," array([0, 0, 1, 0, 0]) array([0, 0, 1, 1, 0]) array([0, 0, 1, 0, 0])\n"," array([0, 0, 1, 0, 0]) array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 0, 1]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 1, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([0, 0, 0, 1, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 0, 0, 0, 1])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 1, 0]) array([0, 0, 1, 0, 0]) array([0, 0, 1, 0, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 1]) array([1, 0, 0, 1, 0]) array([1, 0, 0, 1, 0])\n"," array([1, 0, 0, 1, 0]) array([1, 0, 0, 1, 0]) array([0, 0, 0, 1, 0])\n"," array([1, 0, 0, 1, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0]) array([0, 1, 0, 0, 0])\n"," array([0, 1, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0]) array([1, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 1]) array([0, 0, 0, 0, 1]) array([1, 0, 0, 0, 0])\n"," array([0, 0, 0, 0, 1])]\n"]}]},{"cell_type":"code","source":["test_dataset = TextClassificationDataset(test_text, test_label, tokenizer)\n","\n","# Measure inference time\n","start_time = time.time()\n","\n","# Predict on the test dataset\n","predictions = trainer.predict(test_dataset)\n","\n","# Calculate elapsed time\n","end_time = time.time()\n","inference_time = end_time - start_time\n","\n","# Compute metrics using the `compute_metrics` function\n","metrics = compute_metrics(predictions)\n","\n","print(\"<<==============================================>>\")\n","# Display metrics and inference time\n","print(\"<<=================Evaluation Metrics================>>\")\n","print(\"Evaluation Metrics:\", metrics)\n","print(\"<<==============================================>>\")\n","print(\"<<=================Inference Time================>>\")\n","print(f\"Inference Time: {inference_time:.2f} seconds\")\n","print(\"<<==============================================>>\")"],"metadata":{"id":"5euYrzC3HiU9","colab":{"base_uri":"https://localhost:8080/","height":211},"outputId":"1927deda-4b65-4651-aab0-74f2d6730bd3","executionInfo":{"status":"ok","timestamp":1733251192521,"user_tz":480,"elapsed":4651,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 406\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='50' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [24/24 00:57]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<<==============================================>>\n","<<=================Evaluation Metrics================>>\n","Evaluation Metrics: {'accuracy': 0.8379310344827586, 'precision': 0.6285414471170903, 'recall': 0.6055045871559633, 'f1': 0.6166531407624688}\n","<<==============================================>>\n","<<=================Inference Time================>>\n","Inference Time: 5.21 seconds\n","<<==============================================>>\n"]}]},{"cell_type":"code","source":["!zip -r best_model_roberta-large_python.zip './best_model_roberta-large_python'\n","!zip -r best_model_roberta-large_python_tokenizer.zip './best_model_roberta-large_python_tokenizer'"],"metadata":{"id":"WRp9UcCfGrfn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733251229621,"user_tz":480,"elapsed":37113,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"c2e2f3c1-280b-43c2-bdb2-893deb819caa"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: best_model_roberta-large_python/ (stored 0%)\n","  adding: best_model_roberta-large_python/pytorch_model.bin (deflated 15%)\n","  adding: best_model_roberta-large_python/training_args.bin (deflated 51%)\n","  adding: best_model_roberta-large_python/config.json (deflated 54%)\n","  adding: best_model_roberta-large_python_tokenizer/ (stored 0%)\n","  adding: best_model_roberta-large_python_tokenizer/tokenizer_config.json (deflated 80%)\n","  adding: best_model_roberta-large_python_tokenizer/special_tokens_map.json (deflated 84%)\n","  adding: best_model_roberta-large_python_tokenizer/merges.txt (deflated 53%)\n","  adding: best_model_roberta-large_python_tokenizer/vocab.json (deflated 63%)\n"]}]},{"cell_type":"code","source":["# Transfer the model to Google drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!cp best_model_roberta-large_python.zip \"/content/drive/MyDrive/FYP/Revised/Models/roberta-large_Python/\"\n","!cp best_model_roberta-large_python_tokenizer.zip \"/content/drive/MyDrive/FYP/Revised/Models/roberta-large_Python_Tokenizer/\""],"metadata":{"id":"k7FVxMA7KH9Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733252464088,"user_tz":480,"elapsed":41085,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"42c01dfd-c97b-4571-bc25-3b59110ebf6a"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# **Load and Test Model**"],"metadata":{"id":"x4H49PZzDpQd"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"c4WNjTO2qKMC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733252468110,"user_tz":480,"elapsed":4026,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"166bef6c-64e5-431c-db6e-b046d62fef55"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["from transformers import RobertaForSequenceClassification, RobertaTokenizer\n","\n","# Replace 'path/to/checkpoint-folder' with the actual path to your checkpoint folder.\n","model_folder = '/content/drive/MyDrive/FYP/Revised/Models/roberta-large_Python/'\n","tokenizer_folder = '/content/drive/MyDrive/FYP/Revised/Models/roberta-large_Python_Tokenizer/'\n","\n","!unzip '/content/drive/MyDrive/FYP/Revised/Models/roberta-large_Python/best_model_roberta-large_python.zip' -d './'\n","!unzip '/content/drive/MyDrive/FYP/Revised/Models/roberta-large_Python_Tokenizer/best_model_roberta-large_python_tokenizer.zip' -d './'"],"metadata":{"id":"uOAXyquCMPJ-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733252490168,"user_tz":480,"elapsed":22066,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"9cdb6731-1522-47fc-d81e-be12005cc96c"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/MyDrive/FYP/Revised/Models/roberta-large_Python/best_model_roberta-large_python.zip\n","replace ./best_model_roberta-large_python/pytorch_model.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n","  inflating: ./best_model_roberta-large_python/pytorch_model.bin  \n","  inflating: ./best_model_roberta-large_python/training_args.bin  \n","  inflating: ./best_model_roberta-large_python/config.json  \n","Archive:  /content/drive/MyDrive/FYP/Revised/Models/roberta-large_Python_Tokenizer/best_model_roberta-large_python_tokenizer.zip\n","replace ./best_model_roberta-large_python_tokenizer/tokenizer_config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n","  inflating: ./best_model_roberta-large_python_tokenizer/tokenizer_config.json  \n","  inflating: ./best_model_roberta-large_python_tokenizer/special_tokens_map.json  \n","  inflating: ./best_model_roberta-large_python_tokenizer/merges.txt  \n","  inflating: ./best_model_roberta-large_python_tokenizer/vocab.json  \n"]}]},{"cell_type":"code","source":["best_model_roberta_large_python = 'best_model_roberta-large_python'\n","best_model_roberta_large_python_tokenizer = 'best_model_roberta-large_python_tokenizer'"],"metadata":{"id":"6N76rCMSrrz5","executionInfo":{"status":"ok","timestamp":1733252533805,"user_tz":480,"elapsed":375,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# Load the model and tokenizer from the checkpoint\n","model = RobertaForSequenceClassification.from_pretrained(best_model_roberta_large_python)\n","tokenizer = RobertaTokenizer.from_pretrained(best_model_roberta_large_python_tokenizer)\n","\n","text = \"for detecting automatically generated fields.\"\n","encoded_input = tokenizer(text, return_tensors='pt')\n","output = model(**encoded_input)\n","output"],"metadata":{"id":"Bdm4d_X0pO3K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733252580361,"user_tz":480,"elapsed":2783,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"786433fa-9356-46fa-ce16-23251e404502"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file best_model_roberta-large_python/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file best_model_roberta-large_python/pytorch_model.bin\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:1439: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(resolved_archive_file, map_location=\"cpu\")\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at best_model_roberta-large_python.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n","Didn't find file best_model_roberta-large_python_tokenizer/added_tokens.json. We won't load it.\n","loading file best_model_roberta-large_python_tokenizer/vocab.json\n","loading file best_model_roberta-large_python_tokenizer/merges.txt\n","loading file None\n","loading file best_model_roberta-large_python_tokenizer/special_tokens_map.json\n","loading file best_model_roberta-large_python_tokenizer/tokenizer_config.json\n"]},{"output_type":"execute_result","data":{"text/plain":["SequenceClassifierOutput(loss=None, logits=tensor([[-4.8158, -6.0455,  0.8168, -6.3221, -4.5287]],\n","       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["logits = output.logits\n","\n","# Apply sigmoid to convert logits to probabilities\n","probabilities = torch.sigmoid(logits)\n","\n","# Define a threshold to determine if a class is positive\n","threshold = 0.5\n","predicted_indices = (probabilities > threshold).nonzero(as_tuple=True)[1]\n","\n","# Convert indices to a list for output\n","predicted_classes = (predicted_indices + 1).tolist()\n","\n","# Format the output to display classes\n","if len(predicted_classes) > 0:\n","    predicted_classes_str = \", \".join(map(str, predicted_classes))\n","    print(f\"Predicted class/es: {predicted_classes_str}\")\n","else:\n","    print(\"No positive classes predicted.\")"],"metadata":{"id":"e9YFZQfdts-W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733252585328,"user_tz":480,"elapsed":439,"user":{"displayName":"Pak Arab Fertilizers","userId":"14810401794988792997"}},"outputId":"6c31021c-9da2-4d70-9ac2-69603bc5a248"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class/es: 3\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4eea98cb69e348ebb7be176f806ecb72":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e67ac4c21bea4f79b61624b76b1b7f3a","IPY_MODEL_4bb733a9c8cd49689425f3018ffb56a3","IPY_MODEL_78616e4a5ee949d7800eb7a7b043bab3"],"layout":"IPY_MODEL_e9335132f9af4d618d76531cc5f47300"}},"e67ac4c21bea4f79b61624b76b1b7f3a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43b25bd8319f4774bdc294f1bab701f9","placeholder":"​","style":"IPY_MODEL_6889f2d376294a96b79d795a2c78b4ad","value":"Downloading: 100%"}},"4bb733a9c8cd49689425f3018ffb56a3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_51ce69ea5c9f492dbe6f090002f4f965","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0dd3a78fa9fc49aaa3b15a0b0f5daf56","value":898823}},"78616e4a5ee949d7800eb7a7b043bab3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea21c46c6a844d97a6e760b5ccdcca00","placeholder":"​","style":"IPY_MODEL_b38d93f192bd403cacbc2c73df9e65d9","value":" 878k/878k [00:00&lt;00:00, 9.03MB/s]"}},"e9335132f9af4d618d76531cc5f47300":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43b25bd8319f4774bdc294f1bab701f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6889f2d376294a96b79d795a2c78b4ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51ce69ea5c9f492dbe6f090002f4f965":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0dd3a78fa9fc49aaa3b15a0b0f5daf56":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ea21c46c6a844d97a6e760b5ccdcca00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b38d93f192bd403cacbc2c73df9e65d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4db42af9b52c40a08950bc72078d939b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4215040808734b669b35ae35b3a083dd","IPY_MODEL_101926200ced4faab847bfe07e782abf","IPY_MODEL_908edfe0cc1c4a7fb5c5cf6816779d33"],"layout":"IPY_MODEL_97c2a3925600434cb52d0940e5bddbc9"}},"4215040808734b669b35ae35b3a083dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7419aded3864868b8409bc8bad06d5d","placeholder":"​","style":"IPY_MODEL_b50f5b012d7548938a816b5dc7b381b3","value":"Downloading: 100%"}},"101926200ced4faab847bfe07e782abf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d461892f155a4907b3144e7f8d8cc395","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9a30f7f76ecc4590ba23f3a6f1020d9b","value":456318}},"908edfe0cc1c4a7fb5c5cf6816779d33":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_429fcb083ed54ce4962c57436ea115f0","placeholder":"​","style":"IPY_MODEL_53290cf276c141018b4919b0cd0de36e","value":" 446k/446k [00:00&lt;00:00, 5.51MB/s]"}},"97c2a3925600434cb52d0940e5bddbc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7419aded3864868b8409bc8bad06d5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b50f5b012d7548938a816b5dc7b381b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d461892f155a4907b3144e7f8d8cc395":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a30f7f76ecc4590ba23f3a6f1020d9b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"429fcb083ed54ce4962c57436ea115f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53290cf276c141018b4919b0cd0de36e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed3f86a3c48f491c9afc0de922b1450a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_652684cbea6c46249bc13fc205863275","IPY_MODEL_7fd5aaf4eceb408ca2f0d3be11db4b8a","IPY_MODEL_b6e2cbd292e9448e87e669d81b29a51e"],"layout":"IPY_MODEL_99a681eb91c74504b0fd76d2b4768304"}},"652684cbea6c46249bc13fc205863275":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_230ddac6564e47348ef69b82319c7527","placeholder":"​","style":"IPY_MODEL_c94588e3b36445a298331318668b6b64","value":"Downloading: 100%"}},"7fd5aaf4eceb408ca2f0d3be11db4b8a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc1272bef6b04f57865876847e5a6255","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6f6b8ddfa3674864848ec5b6ffe7ef55","value":25}},"b6e2cbd292e9448e87e669d81b29a51e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72fb81e0bc26498d88aac9f3fdc1ea15","placeholder":"​","style":"IPY_MODEL_be747aaaf11a490ab7d977eb70509660","value":" 25.0/25.0 [00:00&lt;00:00, 1.45kB/s]"}},"99a681eb91c74504b0fd76d2b4768304":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"230ddac6564e47348ef69b82319c7527":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c94588e3b36445a298331318668b6b64":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc1272bef6b04f57865876847e5a6255":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f6b8ddfa3674864848ec5b6ffe7ef55":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"72fb81e0bc26498d88aac9f3fdc1ea15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be747aaaf11a490ab7d977eb70509660":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ce2e5a043a84783a3351fe554f17740":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eeb11a6a170f4d659c65b38efa0f6865","IPY_MODEL_40396ed0e8a14a35911b68ba6ee1bbd3","IPY_MODEL_bb7fa9cab328430282673698b6429f2a"],"layout":"IPY_MODEL_52e7f19adb3946c7ab5480ab09f5a84c"}},"eeb11a6a170f4d659c65b38efa0f6865":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef5c32db54ad4bfaa7be666681052d61","placeholder":"​","style":"IPY_MODEL_093e6ed0e352454b9a4f2162599825d3","value":"Downloading: 100%"}},"40396ed0e8a14a35911b68ba6ee1bbd3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_80a57ca7356c40b9b170288add8b4438","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0a2f71013cd43e7a4b16aa6dd82d440","value":481}},"bb7fa9cab328430282673698b6429f2a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_138f98dc40a34074a08c871d9ab8dfb8","placeholder":"​","style":"IPY_MODEL_4608f1703df04279aafc3860754db6a9","value":" 481/481 [00:00&lt;00:00, 22.5kB/s]"}},"52e7f19adb3946c7ab5480ab09f5a84c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef5c32db54ad4bfaa7be666681052d61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"093e6ed0e352454b9a4f2162599825d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80a57ca7356c40b9b170288add8b4438":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0a2f71013cd43e7a4b16aa6dd82d440":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"138f98dc40a34074a08c871d9ab8dfb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4608f1703df04279aafc3860754db6a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31af92439d84422daaab2522aeb36b3f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9142f7fec1924a8b86483655799fac46","IPY_MODEL_5d8ad01ba7634fe29bbfb1d7a208fc37","IPY_MODEL_945137af87fd46698bf36ae53a4c3e49"],"layout":"IPY_MODEL_886175de49b647088ca4e55dcaf93dfa"}},"9142f7fec1924a8b86483655799fac46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d654c0a7c55547289ed29662eae56bfa","placeholder":"​","style":"IPY_MODEL_0b98732c7bed45c6be76676aed75ab90","value":"Downloading: 100%"}},"5d8ad01ba7634fe29bbfb1d7a208fc37":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0931bee84d5d46119aa200decd677511","max":501200538,"min":0,"orientation":"horizontal","style":"IPY_MODEL_68131eb5cdcd4f81ab1e457c233a0003","value":501200538}},"945137af87fd46698bf36ae53a4c3e49":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6900457844774643849d5edf89194f8d","placeholder":"​","style":"IPY_MODEL_875b344e82284214b34e97917dc89b46","value":" 478M/478M [00:19&lt;00:00, 17.3MB/s]"}},"886175de49b647088ca4e55dcaf93dfa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d654c0a7c55547289ed29662eae56bfa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b98732c7bed45c6be76676aed75ab90":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0931bee84d5d46119aa200decd677511":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68131eb5cdcd4f81ab1e457c233a0003":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6900457844774643849d5edf89194f8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"875b344e82284214b34e97917dc89b46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}